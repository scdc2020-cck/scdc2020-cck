{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "seed_value= 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython = get_ipython()\n",
    "\n",
    "def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,\n",
    "                      exception_only=False, running_compiled_code=False):\n",
    "       etype, value, tb = sys.exc_info()\n",
    "       return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
    "\n",
    "ipython.showtraceback = hide_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "master_path = os.path.join(os.getcwd(), '데이터SET', f\"{'[Track1_데이터2] samp_train'}.csv\")\n",
    "master = pd.read_csv(master_path)\n",
    "master.MRC_ID_DI[master.MRC_ID_DI > 0 ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_0 = master[master['MRC_ID_DI'] == 0].sample(frac=1)\n",
    "master_1 = master[master['MRC_ID_DI'] == 1].sample(frac=1)\n",
    "\n",
    "sample_size = len(master_0) if len(master_0) < len(master_1) else len(master_1)\n",
    "\n",
    "master = pd.concat([master_0.head(sample_size), master_1.head(sample_size)]).sample(frac=1)\n",
    "\n",
    "master_copy = master.copy()\n",
    "train_set = master_copy.sample(frac=0.9, random_state=42)\n",
    "test_set = master_copy.drop(train_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(os.getcwd(), 'image')\n",
    "\"\"\"\n",
    "y_train = []\n",
    "X_train_paths = []\n",
    "\n",
    "y_test = []\n",
    "X_test_paths = []\n",
    "\n",
    "for i in range(len(master)):\n",
    "    if master.iloc[i, 0] in train_set.cst_id_di.values:\n",
    "        X_train_paths.append( os.path.join(img_path, str(master.iloc[i, 0]) +'.png') )\n",
    "        y_train.append(master.iloc[i, 1])\n",
    "    else:\n",
    "        X_test_paths.append( os.path.join(img_path, str(master.iloc[i, 0]) +'.png') )\n",
    "        y_test.append(master.iloc[i, 1])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "\"\"\"\n",
    "y = []\n",
    "X_paths = []\n",
    "\n",
    "for i in range(len(master)):\n",
    "    if master.iloc[i, 0] in train_set.cst_id_di.values:\n",
    "        X_paths.append( os.path.join(img_path, str(master.iloc[i, 0]) +'.png') )\n",
    "        y.append(master.iloc[i, 1])\n",
    "\n",
    "y = np.array(y)\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "X_train_paths, X_test_paths, y_train, y_test = train_test_split(X_paths, y, test_size=0.1, random_state=1)\n",
    "\n",
    "X_train_paths, X_val_paths, y_train, y_val = train_test_split(X_train_paths, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for file_path in X_train_paths:\n",
    "    #read image\n",
    "    img = cv2.imread(file_path)\n",
    "    X_train.append(img)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "X_val = []\n",
    "for file_path in X_val_paths:\n",
    "    #read image\n",
    "    img = cv2.imread(file_path)\n",
    "    X_val.append(img)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "\n",
    "X_test = []\n",
    "for file_path in X_test_paths:\n",
    "    #read image\n",
    "    img = cv2.imread(file_path)\n",
    "    X_test.append(img)\n",
    "\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nval_split_num = int(round(0.1*len(y_train)))\\nimport random\\n\\nx_t = X_train[val_split_num:]\\ny_t = y_train[val_split_num:]\\nx_v = X_train[:val_split_num]\\ny_v = y_train[:val_split_num]\\n\\nprint('x_train', x_t.shape)\\nprint('y_train', y_t.shape)\\nprint('x_test', x_v.shape)\\nprint('y_test', y_v.shape)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "val_split_num = int(round(0.1*len(y_train)))\n",
    "import random\n",
    "\n",
    "x_t = X_train[val_split_num:]\n",
    "y_t = y_train[val_split_num:]\n",
    "x_v = X_train[:val_split_num]\n",
    "y_v = y_train[:val_split_num]\n",
    "\n",
    "print('x_train', x_t.shape)\n",
    "print('y_train', y_t.shape)\n",
    "print('x_test', x_v.shape)\n",
    "print('y_test', y_v.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "\n",
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 2)                 25693186  \n",
      "=================================================================\n",
      "Total params: 40,407,874\n",
      "Trainable params: 40,407,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "add_model = tf.keras.Sequential()\n",
    "add_model.add(tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:]))\n",
    "\n",
    "add_model.add(tf.keras.layers.Dense(units=1024, activation=tf.nn.relu))\n",
    "add_model.add(tf.keras.layers.Dense(units=2, activation=tf.nn.softmax))\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(lr=0.00001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-3f7f4e265e27>:24: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1402 steps, validate for 174 steps\n",
      "Epoch 1/50\n",
      "1402/1402 [==============================] - 81s 58ms/step - loss: 0.6967 - accuracy: 0.5218 - val_loss: 0.6816 - val_accuracy: 0.5850\n",
      "Epoch 2/50\n",
      "1402/1402 [==============================] - 77s 55ms/step - loss: 0.6889 - accuracy: 0.5332 - val_loss: 0.6779 - val_accuracy: 0.5937\n",
      "Epoch 3/50\n",
      "1402/1402 [==============================] - 77s 55ms/step - loss: 0.6845 - accuracy: 0.5424 - val_loss: 0.6754 - val_accuracy: 0.5994\n",
      "Epoch 4/50\n",
      "1402/1402 [==============================] - 78s 55ms/step - loss: 0.6819 - accuracy: 0.5646 - val_loss: 0.6713 - val_accuracy: 0.6023\n",
      "Epoch 5/50\n",
      "1402/1402 [==============================] - 78s 55ms/step - loss: 0.6753 - accuracy: 0.5760 - val_loss: 0.6960 - val_accuracy: 0.5130\n",
      "Epoch 6/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6720 - accuracy: 0.5924 - val_loss: 0.6645 - val_accuracy: 0.5908\n",
      "Epoch 7/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6694 - accuracy: 0.5899 - val_loss: 0.6596 - val_accuracy: 0.6138\n",
      "Epoch 8/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6639 - accuracy: 0.6020 - val_loss: 0.6555 - val_accuracy: 0.6282\n",
      "Epoch 9/50\n",
      "1402/1402 [==============================] - 79s 56ms/step - loss: 0.6600 - accuracy: 0.6049 - val_loss: 0.6560 - val_accuracy: 0.5908\n",
      "Epoch 10/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6559 - accuracy: 0.6155 - val_loss: 0.6474 - val_accuracy: 0.6744\n",
      "Epoch 11/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6517 - accuracy: 0.6120 - val_loss: 0.6380 - val_accuracy: 0.6340\n",
      "Epoch 12/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6464 - accuracy: 0.6159 - val_loss: 0.6447 - val_accuracy: 0.6398\n",
      "Epoch 13/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6481 - accuracy: 0.6155 - val_loss: 0.6361 - val_accuracy: 0.6542\n",
      "Epoch 14/50\n",
      "1402/1402 [==============================] - 79s 56ms/step - loss: 0.6397 - accuracy: 0.6362 - val_loss: 0.6328 - val_accuracy: 0.6369\n",
      "Epoch 15/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6329 - accuracy: 0.6352 - val_loss: 0.6205 - val_accuracy: 0.6455\n",
      "Epoch 16/50\n",
      "1402/1402 [==============================] - 79s 56ms/step - loss: 0.6297 - accuracy: 0.6352 - val_loss: 0.6231 - val_accuracy: 0.6686\n",
      "Epoch 17/50\n",
      "1402/1402 [==============================] - 79s 56ms/step - loss: 0.6255 - accuracy: 0.6516 - val_loss: 0.6285 - val_accuracy: 0.6369\n",
      "Epoch 18/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6215 - accuracy: 0.6519 - val_loss: 0.6513 - val_accuracy: 0.5850\n",
      "Epoch 19/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6192 - accuracy: 0.6601 - val_loss: 0.6037 - val_accuracy: 0.6916\n",
      "Epoch 20/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6097 - accuracy: 0.6665 - val_loss: 0.6140 - val_accuracy: 0.6657\n",
      "Epoch 21/50\n",
      "1402/1402 [==============================] - 78s 55ms/step - loss: 0.6085 - accuracy: 0.6748 - val_loss: 0.6147 - val_accuracy: 0.6628\n",
      "Epoch 22/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6062 - accuracy: 0.6673 - val_loss: 0.5874 - val_accuracy: 0.6974\n",
      "Epoch 23/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.6028 - accuracy: 0.6719 - val_loss: 0.5983 - val_accuracy: 0.6859\n",
      "Epoch 24/50\n",
      "1402/1402 [==============================] - 78s 56ms/step - loss: 0.5981 - accuracy: 0.6723 - val_loss: 0.5998 - val_accuracy: 0.6945\n",
      "Epoch 25/50\n",
      "1341/1402 [===========================>..] - ETA: 3s - loss: 0.5999 - accuracy: 0.6752 ETA: 4s"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "epochs = 50\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1/255.,\n",
    "        rotation_range=30, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=True)\n",
    "train_datagen.fit(X_train)\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1/255.,\n",
    "        rotation_range=30, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=True)\n",
    "val_datagen.fit(X_val)\n",
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_datagen.flow(X_test, y_test, batch_size=batch_size),\n",
    "    callbacks=[callback]\n",
    ")\n",
    "# callbacks=[tf.keras.callbacks.ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#24: acc71, val_acc47\n",
    "#24: acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1/255.,\n",
    "        rotation_range=30, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=True)\n",
    "test_datagen.fit(X_test)\n",
    "\n",
    "score = model.evaluate(test_datagen.flow(X_test, y_test, batch_size=batch_size), verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
