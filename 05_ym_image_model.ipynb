{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "#physical_devices = tf.config.list_physical_devices('GPU') \n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "seed_value= 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython = get_ipython()\n",
    "\n",
    "def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,\n",
    "                      exception_only=False, running_compiled_code=False):\n",
    "       etype, value, tb = sys.exc_info()\n",
    "       return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
    "\n",
    "ipython.showtraceback = hide_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "master_path = os.path.join(os.getcwd(), '데이터SET', f\"{'[Track1_데이터2] samp_train'}.csv\")\n",
    "master = pd.read_csv(master_path)\n",
    "master.MRC_ID_DI[master.MRC_ID_DI > 0 ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_0 = master[master['MRC_ID_DI'] == 0].sample(frac=1)\n",
    "master_1 = master[master['MRC_ID_DI'] == 1].sample(frac=1)\n",
    "\n",
    "sample_size = len(master_0) if len(master_0) < len(master_1) else len(master_1)\n",
    "\n",
    "master = pd.concat([master_0.head(sample_size), master_1.head(sample_size)]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img_path = os.path.join(os.getcwd(), 'image')\n",
    "\n",
    "y = []\n",
    "X = []\n",
    "\n",
    "for i in range(len(master)):\n",
    "    path = os.path.join(img_path, str(master.iloc[i, 0]) +'.png')\n",
    "    label = master.iloc[i, 1]\n",
    "    img = Image.open(path)\n",
    "    data = np.asarray(img)\n",
    "    X.append(data)\n",
    "    y.append(label)\n",
    "    \n",
    "    for ang in range(-20, 20, 5):\n",
    "        if ang != 0:\n",
    "            img2 = img.rotate(ang)\n",
    "            data = np.asarray(img2)\n",
    "            X.append(data)\n",
    "            y.append(label)\n",
    "        \n",
    "            img2 = img2.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            data = np.asarray(img2)\n",
    "            X.append(data)\n",
    "            y.append(label)\n",
    "        \n",
    "X = np.array(X)       \n",
    "y = np.array(y)\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "X_train = da.from_array(np.asarray(X_train), chunks=(1000, 1000, 1000, 1000))\n",
    "y_train = da.from_array(np.asarray(y_train), chunks=(1000, 1000))\n",
    "\n",
    "X_val = da.from_array(np.asarray(X_val), chunks=(1000, 1000, 1000, 1000))\n",
    "y_val = da.from_array(np.asarray(y_val), chunks=(1000, 1000))\n",
    "\n",
    "X_test = da.from_array(np.asarray(X_test), chunks=(1000, 1000, 1000, 1000))\n",
    "y_test = da.from_array(np.asarray(y_test), chunks=(1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "img_path = os.path.join(os.getcwd(), 'image')\n",
    "\n",
    "y = []\n",
    "X_paths = []\n",
    "\n",
    "for i in range(len(master)):\n",
    "    X_paths.append( os.path.join(img_path, str(master.iloc[i, 0]) +'.png') )\n",
    "    y.append(master.iloc[i, 1])\n",
    "\n",
    "y = np.array(y)\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "X_train_paths, X_test_paths, y_train, y_test = train_test_split(X_paths, y, test_size=0.1, random_state=1)\n",
    "\n",
    "X_train_paths, X_val_paths, y_train, y_val = train_test_split(X_train_paths, y_train, test_size=0.1, random_state=1)\n",
    "\n",
    "X_train = []\n",
    "for file_path in X_train_paths:\n",
    "    #read image\n",
    "    img = cv2.imread(file_path)\n",
    "    X_train.append(img)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "X_val = []\n",
    "for file_path in X_val_paths:\n",
    "    #read image\n",
    "    img = cv2.imread(file_path)\n",
    "    X_val.append(img)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "\n",
    "X_test = []\n",
    "for file_path in X_test_paths:\n",
    "    #read image\n",
    "    img = cv2.imread(file_path)\n",
    "    X_test.append(img)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_model = tf.keras.Sequential()\n",
    "add_model.add(tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:]))\n",
    "#add_model.add(tf.keras.layers.Dropout(rate = 0.5))\n",
    "#add_model.add(tf.keras.layers.Dropout(rate = 0.8))\n",
    "#add_model.add(tf.keras.layers.Dense(units=8, activation=tf.nn.relu))\n",
    "add_model.add(tf.keras.layers.Dense(units=2, activation=tf.nn.softmax))\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0000001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "epochs = 2000\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1/255.)#,\n",
    "        #rotation_range=30, \n",
    "        #width_shift_range=0.1,\n",
    "        #height_shift_range=0.1, \n",
    "        #horizontal_flip=True)\n",
    "train_datagen.fit(X_train)\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1/255.)#,\n",
    "        #rotation_range=30, \n",
    "        #width_shift_range=0.1,\n",
    "        #height_shift_range=0.1, \n",
    "        #horizontal_flip=True)\n",
    "val_datagen.fit(X_val)\n",
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_datagen.flow(X_val, y_val, batch_size=batch_size),\n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "# callbacks=[tf.keras.callbacks.ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1/255.)#,\n",
    "        #rotation_range=30, \n",
    "        #width_shift_range=0.1,\n",
    "        #height_shift_range=0.1, \n",
    "        #horizontal_flip=True)\n",
    "test_datagen.fit(X_test)\n",
    "\n",
    "score = model.evaluate(test_datagen.flow(X_test, y_test, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
