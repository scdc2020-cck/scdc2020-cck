{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "seed_value= 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython = get_ipython()\n",
    "\n",
    "def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,\n",
    "                      exception_only=False, running_compiled_code=False):\n",
    "       etype, value, tb = sys.exc_info()\n",
    "       return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
    "\n",
    "ipython.showtraceback = hide_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "def class_consistency_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Use the mean score of an image against all the samples from the same class to get a score per class for each image.\n",
    "    Then average again over all the samples to get a class_wise confusion matrix\n",
    "    \"\"\"\n",
    "    y_true = tf.math.divide_no_nan(y_true, tf.reduce_sum(y_true, axis=0))\n",
    "    class_mask = tf.reduce_sum(y_true, axis=0) > 0\n",
    "    confusion_matrix = tf.boolean_mask(\n",
    "        tf.matmul(y_true, tf.matmul(y_pred, y_true), transpose_a=True)[class_mask], class_mask, axis=1\n",
    "    )\n",
    "    identity_matrix = tf.eye(tf.shape(confusion_matrix)[0])\n",
    "    return K.binary_crossentropy(identity_matrix, confusion_matrix)\n",
    "\n",
    "class ClassConsistencyLoss(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        return class_consistency_loss(y_true, y_pred)\n",
    "\n",
    "class Classification(Layer):\n",
    "    \"\"\"\n",
    "    Uses the inner kernel to compute the score matrix between batch and support set, eventually returns\n",
    "    the average score per class\n",
    "    \"\"\"\n",
    "\n",
    "    support_tensors_shape = tf.TensorShape([None, None])\n",
    "    support_labels_one_hot_shape = tf.TensorShape([None, None])\n",
    "    support_labels_name_shape = tf.TensorShape([None])\n",
    "    support_tensors_spec = tf.TensorSpec(support_tensors_shape, tf.float32, name=\"support_tensors\")\n",
    "    support_labels_one_hot_spec = tf.TensorSpec(support_labels_one_hot_shape, tf.float32, name=\"support_labels_one_hot\")\n",
    "    support_labels_name_spec = tf.TensorSpec(support_labels_name_shape, tf.string, name=\"support_labels_name\")\n",
    "\n",
    "    def __init__(self, kernel, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            support_tensors (tf.Tensor): support set embeddings with shape (n, *embedding_shape)\n",
    "            support_labels (tf.Tensor): one-hot encoded support set labels with shape (n, n classes)\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.kernel = kernel\n",
    "        self.support_tensors = tf.Variable(\n",
    "            [[]], validate_shape=False, shape=self.support_tensors_shape, name=\"support_tensors\"\n",
    "        )\n",
    "        self.support_labels_name = tf.Variable(\n",
    "            [],\n",
    "            validate_shape=False,\n",
    "            shape=self.support_labels_name_shape,\n",
    "            name=\"support_labels_name\",\n",
    "            dtype=self.support_labels_name_spec.dtype,\n",
    "        )\n",
    "        self.support_labels_one_hot = tf.Variable(\n",
    "            [[]], validate_shape=False, shape=self.support_labels_one_hot_shape, name=\"support_labels_one_hot\"\n",
    "        )\n",
    "        self.columns = tf.Variable([], validate_shape=False, shape=[None], dtype=tf.string, name=\"columns\")\n",
    "        self.support_set_loss = tf.Variable(0.0, name=\"support_set_loss\")\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"kernel\": self.kernel.to_json()})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        kernel = tf.keras.models.model_from_json(config[\"kernel\"])\n",
    "        config[\"kernel\"] = kernel\n",
    "        return cls(**config)\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_support_set_shape(support_tensors, support_labels):\n",
    "        if support_tensors.shape[0] != support_labels.shape[0]:\n",
    "            raise AttributeError(\"Support tensors and support labels shape 0 should match\")\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=(support_tensors_spec, support_labels_name_spec, tf.TensorSpec(None, tf.bool, name=\"overwrite\"))\n",
    "    )\n",
    "    def set_support_set(self, support_tensors, support_labels_name, overwrite):\n",
    "        self._validate_support_set_shape(support_tensors, support_labels_name)\n",
    "        support_tensors = tf.cond(\n",
    "            overwrite, lambda: support_tensors, lambda: tf.concat([self.support_tensors, support_tensors], axis=0)\n",
    "        )\n",
    "        support_labels_name = tf.cond(\n",
    "            overwrite, lambda: support_labels_name, lambda: tf.concat([self.support_labels_name, support_labels_name], axis=0),\n",
    "        )\n",
    "        columns, codes = tf.unique(support_labels_name)\n",
    "        support_labels_one_hot = tf.one_hot(codes, depth=tf.size(columns))\n",
    "        support_set_size = tf.shape(support_tensors)[0]\n",
    "        pair_wise_scores = tf.reshape(\n",
    "            self.kernel(\n",
    "                [\n",
    "                    tf.repeat(support_tensors, tf.ones(support_set_size, dtype=tf.int32) * support_set_size, axis=0),\n",
    "                    tf.tile(support_tensors, [support_set_size, 1]),\n",
    "                ]\n",
    "            ),\n",
    "            [support_set_size, support_set_size],\n",
    "        )\n",
    "        self.support_set_loss.assign(class_consistency_loss(support_labels_one_hot, pair_wise_scores))\n",
    "\n",
    "        normalized_labels = tf.math.divide_no_nan(support_labels_one_hot, tf.reduce_sum(support_labels_one_hot, axis=0))\n",
    "        self.support_tensors.assign(support_tensors)\n",
    "        self.support_labels_name.assign(support_labels_name)\n",
    "        self.support_labels_one_hot.assign(normalized_labels)\n",
    "        self.columns.assign(columns)\n",
    "        return tf.expand_dims(self.support_set_loss, axis=0)\n",
    "\n",
    "    @tf.function(input_signature=())\n",
    "    def get_support_set(self):\n",
    "        return self.support_tensors, self.support_labels_one_hot, self.support_set_loss\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], tf.shape(self.support_labels_one_hot)[1]\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            if len(inputs) > 1:\n",
    "                raise ValueError(\"Layer should be called on a single tensor\")\n",
    "            inputs = inputs[0]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        support_set_size = tf.shape(self.support_tensors)[0]\n",
    "        pair_wise_scores = tf.reshape(\n",
    "            self.kernel(\n",
    "                [\n",
    "                    tf.repeat(inputs, tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * support_set_size, axis=0),\n",
    "                    tf.tile(self.support_tensors, [batch_size, 1]),\n",
    "                ]\n",
    "            ),\n",
    "            [batch_size, support_set_size],\n",
    "        )\n",
    "        return tf.linalg.matmul(pair_wise_scores, self.support_labels_one_hot)\n",
    "\n",
    "    \n",
    "def classification_accuracy(ascending=False):\n",
    "    \"\"\"\n",
    "    Use the top score of a sample against all the other sample to get a predicted label for each sample.\n",
    "    Then mean accuracy is returned.\n",
    "    \"Top\" is defined according to the ascending arg: like in pandas.sort, ascending=True means that the top score is the smallest while\n",
    "    ascending=False means that the top score is the greatest. Hence if a distance is used, ascending=True (pick closest sample) while\n",
    "    if a similarity is used, ascending=False (pick the greatest similarity).\n",
    "    Note: if there is no other sample of the same class, the sample will always be counted as failure\n",
    "    since it is not possible to find the right class in the other samples.\n",
    "    \"\"\"\n",
    "\n",
    "    def top_score_classification_accuracy(y_true, y_pred):\n",
    "        y_true = tf.dtypes.cast(y_true, y_pred.dtype)\n",
    "        if ascending:\n",
    "            y_pred = y_pred + tf.linalg.diag(tf.reduce_max(y_pred, axis=1) + K.epsilon())\n",
    "            y_pred = tf.map_fn(lambda x: y_true[x], tf.argmin(y_pred, axis=1), dtype=y_pred.dtype)\n",
    "        else:\n",
    "            y_pred = y_pred - tf.linalg.diag(tf.reduce_max(y_pred, axis=1) + K.epsilon())\n",
    "            y_pred = tf.map_fn(lambda x: y_true[x], tf.argmax(y_pred, axis=1), dtype=y_pred.dtype)\n",
    "        return tf.reduce_mean(tf.reduce_sum(y_true * y_pred, axis=1))\n",
    "\n",
    "    return top_score_classification_accuracy\n",
    "\n",
    "def min_eigenvalue(_, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the minimum eigenvalue of the y_pred tensor. If this value if non-negative (resp. positive) then the\n",
    "    similarity or distance learnt is a positive semi-definite (resp. positive definite) kernel.\n",
    "    See Also [Positive-definite kernel](https://en.wikipedia.org/wiki/Positive-definite_kernel)\n",
    "    \"\"\"\n",
    "    return tf.reduce_min(tf.linalg.svd(y_pred, compute_uv=False))\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def DenseSigmoid(input_shape, use_bias=True):\n",
    "    \"\"\"\n",
    "    Add a Dense layer on top of the coordinate-wise abs difference between the embeddings.\n",
    "    Similar to original [SiameseNets paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)\n",
    "    \"\"\"\n",
    "    query = Input(input_shape)\n",
    "    support = Input(input_shape)\n",
    "    output = Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([query, support])\n",
    "    output = Dense(1, activation=\"sigmoid\", use_bias=use_bias)(output)\n",
    "    return Model(inputs=[query, support], outputs=output)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Reshape,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def LearntNorms(input_shape, use_bias=True, activation=\"sigmoid\"):\n",
    "    \"\"\"\n",
    "    Learn the coordinate-wise comparison as opposed to the MixedNorms where they are provided as input\n",
    "    Args:\n",
    "        input_shape (tuple): arg to be passed to keras.layer.Input\n",
    "        use_bias (bool), whether to use bias in layers or not\n",
    "        activation: add an activation function as in other keras standard layers. Default to sigmoid to output a normalize score\n",
    "    \"\"\"\n",
    "    embedding_dimension = np.prod(input_shape)\n",
    "    query = Input(input_shape)\n",
    "    support = Input(input_shape)\n",
    "    inputs = [query, support]\n",
    "    output = Concatenate(axis=1)(inputs)\n",
    "    output = Reshape((len(inputs), embedding_dimension, 1), name=\"stack\")(output)\n",
    "\n",
    "    output = Conv2D(filters=32, kernel_size=(len(inputs), 1), activation=\"relu\", name=\"norms_creation\", use_bias=use_bias)(\n",
    "        output\n",
    "    )\n",
    "    output = Conv2D(filters=1, kernel_size=(1, 1), activation=\"linear\", name=\"norms_average\", use_bias=use_bias)(output)\n",
    "    output = Flatten()(output)\n",
    "\n",
    "    output = Dense(1, activation=activations.get(activation), name=\"output\", use_bias=use_bias)(output)\n",
    "    return Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_channel = 299, 299, 3\n",
    "\n",
    "base_model = tf.keras.applications.Xception(weights='imagenet', include_top=True, input_shape=(img_rows, img_cols, img_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "add_model = tf.keras.Sequential()\n",
    "add_model.add(tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:]))\n",
    "add_model.add(tf.keras.layers.Dropout(rate = 0.8))\n",
    "#add_model.add(tf.keras.layers.Dropout(rate = 0.8))\n",
    "\n",
    "#add_model.add(tf.keras.layers.Dropout(rate = 0.8))\n",
    "add_model.add(tf.keras.layers.Dense(units=256, activation=tf.nn.relu))\n",
    "add_model.add(tf.keras.layers.Dense(units=11, activation=tf.nn.softmax))\n",
    "\n",
    "en_model = tf.keras.Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "#en_model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "#en_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "encoder = en_model\n",
    "print('hi')\n",
    "support_layer = Classification(kernel=LearntNorms(input_shape=(11,), activation=\"sigmoid\"))\n",
    "print('hi')\n",
    "model = Sequential([encoder, support_layer])\n",
    "print('hi')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 11)           259083      predictions[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 23,169,563\n",
      "Trainable params: 23,115,035\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 3414\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Classification' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mAttributeError\u001b[0m\u001b[1;31m:\u001b[0m 'Classification' object has no attribute 'summary'\n"
     ]
    }
   ],
   "source": [
    "support_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Model)                (None, 11)                23169563  \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mTypeError\u001b[0m\u001b[1;31m:\u001b[0m unsupported operand type(s) for *: 'NoneType' and 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "Sequential([encoder, support_layer]).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Model)                (None, 11)                23169563  \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mTypeError\u001b[0m\u001b[1;31m:\u001b[0m unsupported operand type(s) for *: 'NoneType' and 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4742 images belonging to 11 classes.\n",
      "Found 527 images belonging to 11 classes.\n",
      "WARNING:tensorflow:From <ipython-input-8-40851cff6e18>:26: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 592 steps, validate for 65 steps\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.string\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.string\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['support_labels_name:0', 'columns:0', 'support_set_loss:0'] when minimizing the loss.\n",
      "  1/592 [..............................] - ETA: 9:14"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2440, in zeros\n",
      "    tensor_shape.TensorShape(shape))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 334, in _tensor_shape_tensor_conversion_function\n",
      "    \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n",
      "ValueError: Cannot convert a partially known TensorShape to a Tensor: (None, None)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-40851cff6e18>\", line 26, in <module>\n",
      "    validation_steps = 527 // batch_size,\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 324, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1306, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 615, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 497, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2703, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2593, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\", line 978, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 439, in wrapped_fn\n",
      "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 85, in distributed_function\n",
      "    per_replica_function, args=args)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 763, in experimental_run_v2\n",
      "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 1819, in call_for_each_replica\n",
      "    return self._call_for_each_replica(fn, args, kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2164, in _call_for_each_replica\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 292, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 433, in train_on_batch\n",
      "    output_loss_metrics=model._output_loss_metrics)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 312, in train_on_batch\n",
      "    output_loss_metrics=output_loss_metrics))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 273, in _process_single_batch\n",
      "    model.optimizer.apply_gradients(zip(grads, trainable_weights))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 434, in apply_gradients\n",
      "    self._create_slots(var_list)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\adam.py\", line 149, in _create_slots\n",
      "    self.add_slot(var, 'm')\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 599, in add_slot\n",
      "    initial_value=initial_value)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 260, in __call__\n",
      "    return cls._variable_v2_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 254, in _variable_v2_call\n",
      "    shape=shape)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2080, in creator\n",
      "    return next_creator(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2080, in creator\n",
      "    return next_creator(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2080, in creator\n",
      "    return next_creator(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 485, in variable_capturing_scope\n",
      "    lifted_initializer_graph=lifted_initializer_graph, **kwds)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 262, in __call__\n",
      "    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 178, in __init__\n",
      "    initial_value() if init_from_fn else initial_value,\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\", line 98, in __call__\n",
      "    return array_ops.zeros(shape, dtype)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2443, in zeros\n",
      "    shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1314, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 334, in _tensor_shape_tensor_conversion_function\n",
      "    \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n",
      "ValueError: Cannot convert a partially known TensorShape to a Tensor: (None, None)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2440, in zeros\n",
      "    tensor_shape.TensorShape(shape))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 334, in _tensor_shape_tensor_conversion_function\n",
      "    \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n",
      "ValueError: Cannot convert a partially known TensorShape to a Tensor: (None, None)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-40851cff6e18>\", line 26, in <module>\n",
      "    validation_steps = 527 // batch_size,\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 324, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1306, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 615, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 497, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2703, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2593, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\", line 978, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 439, in wrapped_fn\n",
      "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 85, in distributed_function\n",
      "    per_replica_function, args=args)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 763, in experimental_run_v2\n",
      "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 1819, in call_for_each_replica\n",
      "    return self._call_for_each_replica(fn, args, kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2164, in _call_for_each_replica\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 292, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 433, in train_on_batch\n",
      "    output_loss_metrics=model._output_loss_metrics)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 312, in train_on_batch\n",
      "    output_loss_metrics=output_loss_metrics))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 273, in _process_single_batch\n",
      "    model.optimizer.apply_gradients(zip(grads, trainable_weights))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 434, in apply_gradients\n",
      "    self._create_slots(var_list)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\adam.py\", line 149, in _create_slots\n",
      "    self.add_slot(var, 'm')\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 599, in add_slot\n",
      "    initial_value=initial_value)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 260, in __call__\n",
      "    return cls._variable_v2_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 254, in _variable_v2_call\n",
      "    shape=shape)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2080, in creator\n",
      "    return next_creator(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2080, in creator\n",
      "    return next_creator(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2080, in creator\n",
      "    return next_creator(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 485, in variable_capturing_scope\n",
      "    lifted_initializer_graph=lifted_initializer_graph, **kwds)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 262, in __call__\n",
      "    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 178, in __init__\n",
      "    initial_value() if init_from_fn else initial_value,\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\", line 98, in __call__\n",
      "    return array_ops.zeros(shape, dtype)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2443, in zeros\n",
      "    shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1314, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 334, in _tensor_shape_tensor_conversion_function\n",
      "    \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n",
      "ValueError: Cannot convert a partially known TensorShape to a Tensor: (None, None)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3434, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"<ipython-input-2-22b089780bea>\", line 7, in hide_traceback\n",
      "    return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 823, in get_exception_only\n",
      "    return ListTB.structured_traceback(self, etype, value)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 702, in structured_traceback\n",
      "    + out_list)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2440, in zeros\n",
      "    tensor_shape.TensorShape(shape))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 334, in _tensor_shape_tensor_conversion_function\n",
      "    \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n",
      "ValueError: Cannot convert a partially known TensorShape to a Tensor: (None, None)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-40851cff6e18>\", line 26, in <module>\n",
      "    validation_steps = 527 // batch_size,\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 324, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1306, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 615, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 497, in _initialize\n",
      "    *args, **kwds))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2703, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2593, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\", line 978, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 439, in wrapped_fn\n",
      "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 85, in distributed_function\n",
      "    per_replica_function, args=args)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 763, in experimental_run_v2\n",
      "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 1819, in call_for_each_replica\n",
      "    return self._call_for_each_replica(fn, args, kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2164, in _call_for_each_replica\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 292, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 433, in train_on_batch\n",
      "    output_loss_metrics=model._output_loss_metrics)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 312, in train_on_batch\n",
      "    output_loss_metrics=output_loss_metrics))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 273, in _process_single_batch\n",
      "    model.optimizer.apply_gradients(zip(grads, trainable_weights))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 434, in apply_gradients\n",
      "    self._create_slots(var_list)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\adam.py\", line 149, in _create_slots\n",
      "    self.add_slot(var, 'm')\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 599, in add_slot\n",
      "    initial_value=initial_value)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 260, in __call__\n",
      "    return cls._variable_v2_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 254, in _variable_v2_call\n",
      "    shape=shape)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2080, in creator\n",
      "    return next_creator(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2080, in creator\n",
      "    return next_creator(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2080, in creator\n",
      "    return next_creator(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 65, in getter\n",
      "    return captured_getter(captured_previous, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 485, in variable_capturing_scope\n",
      "    lifted_initializer_graph=lifted_initializer_graph, **kwds)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\", line 262, in __call__\n",
      "    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 178, in __init__\n",
      "    initial_value() if init_from_fn else initial_value,\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\", line 98, in __call__\n",
      "    return array_ops.zeros(shape, dtype)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 2443, in zeros\n",
      "    shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1314, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 334, in _tensor_shape_tensor_conversion_function\n",
      "    \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n",
      "ValueError: Cannot convert a partially known TensorShape to a Tensor: (None, None)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3434, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"<ipython-input-2-22b089780bea>\", line 7, in hide_traceback\n",
      "    return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 823, in get_exception_only\n",
      "    return ListTB.structured_traceback(self, etype, value)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 702, in structured_traceback\n",
      "    + out_list)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2922, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3356, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"<ipython-input-2-22b089780bea>\", line 7, in hide_traceback\n",
      "    return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 823, in get_exception_only\n",
      "    return ListTB.structured_traceback(self, etype, value)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 702, in structured_traceback\n",
      "    + out_list)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\A\\anaconda3\\envs\\tf_gpu\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "epochs = 2\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.)\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('image8/train',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "val_set = val_datagen.flow_from_directory('image8/val',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_set,\n",
    "    steps_per_epoch= 4742 // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_set,\n",
    "    validation_steps = 527 // batch_size,\n",
    ")\n",
    "\n",
    "# callbacks=[tf.keras.callbacks.ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model auc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_datagen.flow_from_directory('image8/test',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical')\n",
    "score = model.evaluate(test_set, steps = 28501 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_datagen.flow_from_directory('image8/test',\n",
    "                                                 target_size = (299, 299),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                shuffle=False)\n",
    "preds = model.predict(test_set, steps = 28501 // batch_size)\n",
    "a = test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.zeros((a.size, a.max()+1))\n",
    "y_test[np.arange(a.size),a] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test[:-(28501%batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIFT(preds, y_test, cls): # >=2.5\n",
    "    condition = y_test.astype(bool) #preds에 정답인 예측 score만 남긴다.\n",
    "    c = np.extract(condition, preds)\n",
    "    b = np.argsort(-c)[:len(c)//5] #예측 score 상위 20%\n",
    "    \n",
    "    lift_20 = preds[b] \n",
    "    \n",
    "    lift_20_flat = np.argmax(lift_20, axis=1) #값을 확률에서 0, 1값으로 바꾼다. \n",
    "    y_test_flat = np.argmax(y_test, axis=1)\n",
    "    lift_20_1 = lift_20_flat[lift_20_flat == cls] #1인 경우만 남긴다. \n",
    "    y_1 = y_test_flat[y_test_flat == cls]\n",
    "    \n",
    "    lift_score = (len(lift_20_1)/len(lift_20_flat))/(len(y_1)/len(y_test_flat))\n",
    "    print('LIFT Accuracy: ',  lift_score)\n",
    "    return lift_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_score = [0, 0, 0]\n",
    "lift_score[0] = LIFT(preds, y_test, 3)\n",
    "lift_score[1] = LIFT(preds, y_test, 4)\n",
    "lift_score[2] = LIFT(preds, y_test, 7)\n",
    "avg_lift = sum(lift_score) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in [3, 4, 7]:\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(y_test, preds)\n",
    "auroc_score = m.result().numpy()\n",
    "print(auroc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = (lift_score/5)*0.7 + (auroc_score)*0.3\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
