{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_name = os.path.join(os.getcwd(), '데이터SET', f\"{'[Track1_데이터3] samp_cst_feat'}.csv\")\n",
    "df_x = pd.read_csv(x_name, index_col=0)\n",
    "\n",
    "y_name = os.path.join(os.getcwd(), '데이터SET', f\"{'[Track1_데이터2] samp_train'}.csv\")\n",
    "df_y = pd.read_csv(y_name, index_col=0)\n",
    "\n",
    "df = pd.merge(df_x, df_y, on='cst_id_di')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.MRC_ID_DI[df.MRC_ID_DI > 0 ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_name = os.path.join(os.getcwd(), '데이터SET', f\"{'[Track1_데이터4] variable_dtype'}.xlsx\")\n",
    "nc = pd.read_excel(nc_name, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "#gpu있는 경우 사용\n",
    "#physical_devices = tf.config.list_physical_devices('GPU') \n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "seed_value= 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_random_seed(seed_value) #set_seed -> set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython = get_ipython()\n",
    "\n",
    "def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,\n",
    "                      exception_only=False, running_compiled_code=False):\n",
    "       etype, value, tb = sys.exc_info()\n",
    "       return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
    "\n",
    "ipython.showtraceback = hide_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['MRC_ID_DI'] == 0].sample(frac=1)\n",
    "df_1 = df[df['MRC_ID_DI'] == 1].sample(frac=1)\n",
    "\n",
    "sample_size = len(df_0) if len(df_0) < len(df_1) else len(df_1)\n",
    "\n",
    "#이게 내가 말했던 합쳐서 중복시킨 부분이야\n",
    "df_h = pd.concat([df_0.head(sample_size), df_1.head(sample_size)]).sample(frac=1)\n",
    "df_t = pd.concat([df_0.tail(sample_size), df_1.head(sample_size)]).sample(frac=1)\n",
    "df_f = pd.concat([df_h, df_t]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_f.drop(columns = ['MRC_ID_DI'], axis=1)\n",
    "y = tf.keras.utils.to_categorical(df_f['MRC_ID_DI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10124, 226) (10124,)\n"
     ]
    }
   ],
   "source": [
    "X=df.loc[:,'VAR002':'VAR227']\n",
    "y=df.loc[:,'MRC_ID_DI']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_ = tf.keras.Input(dtype = tf.float32, shape = (len(X.columns),))\n",
    "\n",
    "dense_layer_1_1 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(input_)\n",
    "dense_layer_1_2 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_1)\n",
    "dense_layer_1_3 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_2)\n",
    "dense_layer_1_4 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_3)\n",
    "\n",
    "dropout_1_5 = tf.keras.layers.Dropout(rate = 0.2)(dense_layer_1_1)\n",
    "\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.softmax)(dropout_1_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=input_, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 226)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2270      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 2,292\n",
      "Trainable params: 2,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.00005), metrics=['acc'])\n",
    "# CategoricalCrossentropy-> sparse_categorical_crossentropy\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8199 samples, validate on 912 samples\n",
      "Epoch 1/10000\n",
      "8199/8199 [==============================] - 0s 37us/sample - loss: 0.6197 - acc: 0.7290 - val_loss: 0.5549 - val_acc: 0.8092\n",
      "Epoch 2/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.5105 - acc: 0.8058 - val_loss: 0.4785 - val_acc: 0.8081\n",
      "Epoch 3/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.4626 - acc: 0.8101 - val_loss: 0.4477 - val_acc: 0.8114\n",
      "Epoch 4/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.4412 - acc: 0.8095 - val_loss: 0.4342 - val_acc: 0.8158\n",
      "Epoch 5/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.4334 - acc: 0.8140 - val_loss: 0.4269 - val_acc: 0.8202\n",
      "Epoch 6/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.4238 - acc: 0.8149 - val_loss: 0.4215 - val_acc: 0.8202\n",
      "Epoch 7/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.4196 - acc: 0.8141 - val_loss: 0.4168 - val_acc: 0.8191\n",
      "Epoch 8/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.4165 - acc: 0.8125 - val_loss: 0.4129 - val_acc: 0.8235\n",
      "Epoch 9/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.4104 - acc: 0.8167 - val_loss: 0.4093 - val_acc: 0.8257\n",
      "Epoch 10/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.4057 - acc: 0.8188 - val_loss: 0.4058 - val_acc: 0.8257\n",
      "Epoch 11/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.4011 - acc: 0.8194 - val_loss: 0.4027 - val_acc: 0.8268\n",
      "Epoch 12/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.4003 - acc: 0.8207 - val_loss: 0.3999 - val_acc: 0.8311\n",
      "Epoch 13/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3959 - acc: 0.8210 - val_loss: 0.3972 - val_acc: 0.8344\n",
      "Epoch 14/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3942 - acc: 0.8201 - val_loss: 0.3947 - val_acc: 0.8344\n",
      "Epoch 15/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3919 - acc: 0.8192 - val_loss: 0.3926 - val_acc: 0.8355\n",
      "Epoch 16/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3890 - acc: 0.8214 - val_loss: 0.3905 - val_acc: 0.8377\n",
      "Epoch 17/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3887 - acc: 0.8202 - val_loss: 0.3886 - val_acc: 0.8388\n",
      "Epoch 18/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3865 - acc: 0.8238 - val_loss: 0.3868 - val_acc: 0.8366\n",
      "Epoch 19/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3840 - acc: 0.8211 - val_loss: 0.3848 - val_acc: 0.8377\n",
      "Epoch 20/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3835 - acc: 0.8195 - val_loss: 0.3832 - val_acc: 0.8377\n",
      "Epoch 21/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3823 - acc: 0.8242 - val_loss: 0.3820 - val_acc: 0.8355\n",
      "Epoch 22/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3805 - acc: 0.8253 - val_loss: 0.3804 - val_acc: 0.8300\n",
      "Epoch 23/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3776 - acc: 0.8263 - val_loss: 0.3792 - val_acc: 0.8300\n",
      "Epoch 24/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3763 - acc: 0.8275 - val_loss: 0.3777 - val_acc: 0.8279\n",
      "Epoch 25/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3753 - acc: 0.8266 - val_loss: 0.3763 - val_acc: 0.8279\n",
      "Epoch 26/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3750 - acc: 0.8290 - val_loss: 0.3751 - val_acc: 0.8257\n",
      "Epoch 27/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3733 - acc: 0.8258 - val_loss: 0.3736 - val_acc: 0.8279\n",
      "Epoch 28/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3737 - acc: 0.8294 - val_loss: 0.3725 - val_acc: 0.8268\n",
      "Epoch 29/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3704 - acc: 0.8268 - val_loss: 0.3716 - val_acc: 0.8268\n",
      "Epoch 30/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3706 - acc: 0.8288 - val_loss: 0.3705 - val_acc: 0.8268\n",
      "Epoch 31/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3711 - acc: 0.8264 - val_loss: 0.3699 - val_acc: 0.8268\n",
      "Epoch 32/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3671 - acc: 0.8272 - val_loss: 0.3688 - val_acc: 0.8300\n",
      "Epoch 33/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3676 - acc: 0.8284 - val_loss: 0.3678 - val_acc: 0.8300\n",
      "Epoch 34/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3668 - acc: 0.8322 - val_loss: 0.3670 - val_acc: 0.8322\n",
      "Epoch 35/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3660 - acc: 0.8316 - val_loss: 0.3661 - val_acc: 0.8322\n",
      "Epoch 36/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3657 - acc: 0.8306 - val_loss: 0.3652 - val_acc: 0.8322\n",
      "Epoch 37/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3654 - acc: 0.8316 - val_loss: 0.3645 - val_acc: 0.8322\n",
      "Epoch 38/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3614 - acc: 0.8334 - val_loss: 0.3637 - val_acc: 0.8322\n",
      "Epoch 39/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3620 - acc: 0.8322 - val_loss: 0.3630 - val_acc: 0.8322\n",
      "Epoch 40/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3635 - acc: 0.8300 - val_loss: 0.3622 - val_acc: 0.8311\n",
      "Epoch 41/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3606 - acc: 0.8347 - val_loss: 0.3618 - val_acc: 0.8300\n",
      "Epoch 42/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3624 - acc: 0.8296 - val_loss: 0.3612 - val_acc: 0.8311\n",
      "Epoch 43/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3608 - acc: 0.8324 - val_loss: 0.3605 - val_acc: 0.8311\n",
      "Epoch 44/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3599 - acc: 0.8318 - val_loss: 0.3604 - val_acc: 0.8311\n",
      "Epoch 45/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3616 - acc: 0.8319 - val_loss: 0.3593 - val_acc: 0.8333\n",
      "Epoch 46/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3592 - acc: 0.8347 - val_loss: 0.3585 - val_acc: 0.8355\n",
      "Epoch 47/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3581 - acc: 0.8342 - val_loss: 0.3581 - val_acc: 0.8355\n",
      "Epoch 48/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3579 - acc: 0.8333 - val_loss: 0.3578 - val_acc: 0.8366\n",
      "Epoch 49/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3564 - acc: 0.8352 - val_loss: 0.3571 - val_acc: 0.8355\n",
      "Epoch 50/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3560 - acc: 0.8349 - val_loss: 0.3564 - val_acc: 0.8377\n",
      "Epoch 51/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3541 - acc: 0.8351 - val_loss: 0.3559 - val_acc: 0.8366\n",
      "Epoch 52/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3562 - acc: 0.8342 - val_loss: 0.3554 - val_acc: 0.8388\n",
      "Epoch 53/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3565 - acc: 0.8355 - val_loss: 0.3549 - val_acc: 0.8366\n",
      "Epoch 54/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3544 - acc: 0.8351 - val_loss: 0.3543 - val_acc: 0.8377\n",
      "Epoch 55/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3546 - acc: 0.8386 - val_loss: 0.3540 - val_acc: 0.8399\n",
      "Epoch 56/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3557 - acc: 0.8339 - val_loss: 0.3534 - val_acc: 0.8377\n",
      "Epoch 57/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3535 - acc: 0.8364 - val_loss: 0.3532 - val_acc: 0.8388\n",
      "Epoch 58/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3508 - acc: 0.8363 - val_loss: 0.3527 - val_acc: 0.8388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3521 - acc: 0.8378 - val_loss: 0.3523 - val_acc: 0.8366\n",
      "Epoch 60/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3522 - acc: 0.8375 - val_loss: 0.3518 - val_acc: 0.8388\n",
      "Epoch 61/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3509 - acc: 0.8332 - val_loss: 0.3513 - val_acc: 0.8388\n",
      "Epoch 62/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3490 - acc: 0.8397 - val_loss: 0.3509 - val_acc: 0.8421\n",
      "Epoch 63/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3503 - acc: 0.8367 - val_loss: 0.3503 - val_acc: 0.8432\n",
      "Epoch 64/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3512 - acc: 0.8403 - val_loss: 0.3501 - val_acc: 0.8421\n",
      "Epoch 65/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3487 - acc: 0.8394 - val_loss: 0.3497 - val_acc: 0.8410\n",
      "Epoch 66/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3490 - acc: 0.8416 - val_loss: 0.3493 - val_acc: 0.8399\n",
      "Epoch 67/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3478 - acc: 0.8411 - val_loss: 0.3487 - val_acc: 0.8399\n",
      "Epoch 68/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3499 - acc: 0.8357 - val_loss: 0.3483 - val_acc: 0.8410\n",
      "Epoch 69/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3461 - acc: 0.8389 - val_loss: 0.3479 - val_acc: 0.8399\n",
      "Epoch 70/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3484 - acc: 0.8390 - val_loss: 0.3480 - val_acc: 0.8410\n",
      "Epoch 71/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3475 - acc: 0.8385 - val_loss: 0.3474 - val_acc: 0.8399\n",
      "Epoch 72/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3457 - acc: 0.8416 - val_loss: 0.3468 - val_acc: 0.8410\n",
      "Epoch 73/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3434 - acc: 0.8417 - val_loss: 0.3467 - val_acc: 0.8399\n",
      "Epoch 74/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3456 - acc: 0.8392 - val_loss: 0.3463 - val_acc: 0.8388\n",
      "Epoch 75/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3465 - acc: 0.8421 - val_loss: 0.3459 - val_acc: 0.8399\n",
      "Epoch 76/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3456 - acc: 0.8423 - val_loss: 0.3457 - val_acc: 0.8388\n",
      "Epoch 77/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3452 - acc: 0.8407 - val_loss: 0.3455 - val_acc: 0.8399\n",
      "Epoch 78/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3445 - acc: 0.8411 - val_loss: 0.3452 - val_acc: 0.8399\n",
      "Epoch 79/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3434 - acc: 0.8386 - val_loss: 0.3450 - val_acc: 0.8421\n",
      "Epoch 80/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3433 - acc: 0.8424 - val_loss: 0.3448 - val_acc: 0.8421\n",
      "Epoch 81/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3414 - acc: 0.8438 - val_loss: 0.3447 - val_acc: 0.8454\n",
      "Epoch 82/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3414 - acc: 0.8410 - val_loss: 0.3444 - val_acc: 0.8454\n",
      "Epoch 83/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3431 - acc: 0.8424 - val_loss: 0.3442 - val_acc: 0.8454\n",
      "Epoch 84/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3416 - acc: 0.8428 - val_loss: 0.3437 - val_acc: 0.8454\n",
      "Epoch 85/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3411 - acc: 0.8403 - val_loss: 0.3438 - val_acc: 0.8443\n",
      "Epoch 86/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3433 - acc: 0.8424 - val_loss: 0.3434 - val_acc: 0.8465\n",
      "Epoch 87/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3417 - acc: 0.8430 - val_loss: 0.3433 - val_acc: 0.8465\n",
      "Epoch 88/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3407 - acc: 0.8425 - val_loss: 0.3429 - val_acc: 0.8476\n",
      "Epoch 89/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3404 - acc: 0.8446 - val_loss: 0.3428 - val_acc: 0.8421\n",
      "Epoch 90/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3423 - acc: 0.8418 - val_loss: 0.3425 - val_acc: 0.8476\n",
      "Epoch 91/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3412 - acc: 0.8450 - val_loss: 0.3423 - val_acc: 0.8465\n",
      "Epoch 92/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3396 - acc: 0.8432 - val_loss: 0.3419 - val_acc: 0.8454\n",
      "Epoch 93/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3418 - acc: 0.8418 - val_loss: 0.3416 - val_acc: 0.8443\n",
      "Epoch 94/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3395 - acc: 0.8436 - val_loss: 0.3414 - val_acc: 0.8454\n",
      "Epoch 95/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3374 - acc: 0.8436 - val_loss: 0.3413 - val_acc: 0.8421\n",
      "Epoch 96/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3383 - acc: 0.8446 - val_loss: 0.3409 - val_acc: 0.8421\n",
      "Epoch 97/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3372 - acc: 0.8450 - val_loss: 0.3409 - val_acc: 0.8432\n",
      "Epoch 98/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3382 - acc: 0.8442 - val_loss: 0.3410 - val_acc: 0.8410\n",
      "Epoch 99/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3388 - acc: 0.8417 - val_loss: 0.3409 - val_acc: 0.8388\n",
      "Epoch 100/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3371 - acc: 0.8446 - val_loss: 0.3405 - val_acc: 0.8377\n",
      "Epoch 101/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3370 - acc: 0.8447 - val_loss: 0.3405 - val_acc: 0.8388\n",
      "Epoch 102/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3378 - acc: 0.8458 - val_loss: 0.3402 - val_acc: 0.8388\n",
      "Epoch 103/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3353 - acc: 0.8453 - val_loss: 0.3399 - val_acc: 0.8388\n",
      "Epoch 104/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3364 - acc: 0.8451 - val_loss: 0.3397 - val_acc: 0.8355\n",
      "Epoch 105/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3357 - acc: 0.8430 - val_loss: 0.3395 - val_acc: 0.8377\n",
      "Epoch 106/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3365 - acc: 0.8457 - val_loss: 0.3394 - val_acc: 0.8388\n",
      "Epoch 107/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3360 - acc: 0.8474 - val_loss: 0.3393 - val_acc: 0.8388\n",
      "Epoch 108/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3351 - acc: 0.8433 - val_loss: 0.3389 - val_acc: 0.8344\n",
      "Epoch 109/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3336 - acc: 0.8478 - val_loss: 0.3388 - val_acc: 0.8366\n",
      "Epoch 110/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3338 - acc: 0.8507 - val_loss: 0.3387 - val_acc: 0.8355\n",
      "Epoch 111/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3352 - acc: 0.8492 - val_loss: 0.3386 - val_acc: 0.8355\n",
      "Epoch 112/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3370 - acc: 0.8464 - val_loss: 0.3385 - val_acc: 0.8366\n",
      "Epoch 113/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3339 - acc: 0.8453 - val_loss: 0.3385 - val_acc: 0.8333\n",
      "Epoch 114/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3336 - acc: 0.8484 - val_loss: 0.3379 - val_acc: 0.8366\n",
      "Epoch 115/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3353 - acc: 0.8473 - val_loss: 0.3381 - val_acc: 0.8333\n",
      "Epoch 116/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3338 - acc: 0.8486 - val_loss: 0.3380 - val_acc: 0.8377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3322 - acc: 0.8449 - val_loss: 0.3378 - val_acc: 0.8377\n",
      "Epoch 118/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3327 - acc: 0.8482 - val_loss: 0.3376 - val_acc: 0.8377\n",
      "Epoch 119/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3326 - acc: 0.8445 - val_loss: 0.3375 - val_acc: 0.8366\n",
      "Epoch 120/10000\n",
      "8199/8199 [==============================] - ETA: 0s - loss: 0.3329 - acc: 0.845 - 0s 28us/sample - loss: 0.3317 - acc: 0.8457 - val_loss: 0.3373 - val_acc: 0.8377\n",
      "Epoch 121/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3307 - acc: 0.8521 - val_loss: 0.3372 - val_acc: 0.8388\n",
      "Epoch 122/10000\n",
      "8199/8199 [==============================] - 0s 28us/sample - loss: 0.3311 - acc: 0.8490 - val_loss: 0.3371 - val_acc: 0.8388\n",
      "Epoch 123/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3334 - acc: 0.8474 - val_loss: 0.3371 - val_acc: 0.8377\n",
      "Epoch 124/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3322 - acc: 0.8479 - val_loss: 0.3371 - val_acc: 0.8388\n",
      "Epoch 125/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3321 - acc: 0.8464 - val_loss: 0.3371 - val_acc: 0.8377\n",
      "Epoch 126/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3322 - acc: 0.8471 - val_loss: 0.3367 - val_acc: 0.8377\n",
      "Epoch 127/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3295 - acc: 0.8466 - val_loss: 0.3367 - val_acc: 0.8388\n",
      "Epoch 128/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3293 - acc: 0.8475 - val_loss: 0.3368 - val_acc: 0.8377\n",
      "Epoch 129/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3273 - acc: 0.8485 - val_loss: 0.3364 - val_acc: 0.8399\n",
      "Epoch 130/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3315 - acc: 0.8489 - val_loss: 0.3363 - val_acc: 0.8421\n",
      "Epoch 131/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3305 - acc: 0.8482 - val_loss: 0.3364 - val_acc: 0.8410\n",
      "Epoch 132/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3294 - acc: 0.8467 - val_loss: 0.3362 - val_acc: 0.8344\n",
      "Epoch 133/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3279 - acc: 0.8511 - val_loss: 0.3361 - val_acc: 0.8399\n",
      "Epoch 134/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3322 - acc: 0.8457 - val_loss: 0.3361 - val_acc: 0.8399\n",
      "Epoch 135/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3268 - acc: 0.8514 - val_loss: 0.3359 - val_acc: 0.8399\n",
      "Epoch 136/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3283 - acc: 0.8468 - val_loss: 0.3357 - val_acc: 0.8377\n",
      "Epoch 137/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3286 - acc: 0.8491 - val_loss: 0.3359 - val_acc: 0.8388\n",
      "Epoch 138/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3268 - acc: 0.8521 - val_loss: 0.3354 - val_acc: 0.8399\n",
      "Epoch 139/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3294 - acc: 0.8485 - val_loss: 0.3351 - val_acc: 0.8388\n",
      "Epoch 140/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3281 - acc: 0.8499 - val_loss: 0.3353 - val_acc: 0.8388\n",
      "Epoch 141/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3285 - acc: 0.8475 - val_loss: 0.3352 - val_acc: 0.8377\n",
      "Epoch 142/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3299 - acc: 0.8486 - val_loss: 0.3348 - val_acc: 0.8388\n",
      "Epoch 143/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3302 - acc: 0.8483 - val_loss: 0.3351 - val_acc: 0.8366\n",
      "Epoch 144/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3272 - acc: 0.8524 - val_loss: 0.3347 - val_acc: 0.8388\n",
      "Epoch 145/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3261 - acc: 0.8492 - val_loss: 0.3347 - val_acc: 0.8377\n",
      "Epoch 146/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3284 - acc: 0.8495 - val_loss: 0.3347 - val_acc: 0.8377\n",
      "Epoch 147/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3269 - acc: 0.8497 - val_loss: 0.3350 - val_acc: 0.8399\n",
      "Epoch 148/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3287 - acc: 0.8536 - val_loss: 0.3345 - val_acc: 0.8377\n",
      "Epoch 149/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3274 - acc: 0.8516 - val_loss: 0.3346 - val_acc: 0.8388\n",
      "Epoch 150/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3268 - acc: 0.8505 - val_loss: 0.3344 - val_acc: 0.8366\n",
      "Epoch 151/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3276 - acc: 0.8485 - val_loss: 0.3344 - val_acc: 0.8432\n",
      "Epoch 152/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3270 - acc: 0.8497 - val_loss: 0.3345 - val_acc: 0.8366\n",
      "Epoch 153/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3280 - acc: 0.8458 - val_loss: 0.3343 - val_acc: 0.8399\n",
      "Epoch 154/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3253 - acc: 0.8532 - val_loss: 0.3344 - val_acc: 0.8355\n",
      "Epoch 155/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3270 - acc: 0.8510 - val_loss: 0.3341 - val_acc: 0.8388\n",
      "Epoch 156/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3268 - acc: 0.8525 - val_loss: 0.3340 - val_acc: 0.8388\n",
      "Epoch 157/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3284 - acc: 0.8484 - val_loss: 0.3340 - val_acc: 0.8388\n",
      "Epoch 158/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3233 - acc: 0.8527 - val_loss: 0.3339 - val_acc: 0.8388\n",
      "Epoch 159/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3262 - acc: 0.8510 - val_loss: 0.3338 - val_acc: 0.8399\n",
      "Epoch 160/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3278 - acc: 0.8507 - val_loss: 0.3336 - val_acc: 0.8399\n",
      "Epoch 161/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3253 - acc: 0.8535 - val_loss: 0.3333 - val_acc: 0.8410\n",
      "Epoch 162/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3257 - acc: 0.8480 - val_loss: 0.3336 - val_acc: 0.8388\n",
      "Epoch 163/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3246 - acc: 0.8518 - val_loss: 0.3333 - val_acc: 0.8399\n",
      "Epoch 164/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3247 - acc: 0.8519 - val_loss: 0.3333 - val_acc: 0.8399\n",
      "Epoch 165/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3235 - acc: 0.8521 - val_loss: 0.3332 - val_acc: 0.8399\n",
      "Epoch 166/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3251 - acc: 0.8507 - val_loss: 0.3330 - val_acc: 0.8410\n",
      "Epoch 167/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3247 - acc: 0.8475 - val_loss: 0.3330 - val_acc: 0.8410\n",
      "Epoch 168/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3247 - acc: 0.8503 - val_loss: 0.3330 - val_acc: 0.8410\n",
      "Epoch 169/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3249 - acc: 0.8507 - val_loss: 0.3327 - val_acc: 0.8399\n",
      "Epoch 170/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3241 - acc: 0.8535 - val_loss: 0.3329 - val_acc: 0.8410\n",
      "Epoch 171/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3244 - acc: 0.8519 - val_loss: 0.3328 - val_acc: 0.8410\n",
      "Epoch 172/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3257 - acc: 0.8484 - val_loss: 0.3328 - val_acc: 0.8421\n",
      "Epoch 173/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3233 - acc: 0.8483 - val_loss: 0.3326 - val_acc: 0.8421\n",
      "Epoch 174/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3239 - acc: 0.8511 - val_loss: 0.3326 - val_acc: 0.8410\n",
      "Epoch 175/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3224 - acc: 0.8551 - val_loss: 0.3324 - val_acc: 0.8432\n",
      "Epoch 176/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3264 - acc: 0.8489 - val_loss: 0.3322 - val_acc: 0.8410\n",
      "Epoch 177/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3234 - acc: 0.8525 - val_loss: 0.3324 - val_acc: 0.8399\n",
      "Epoch 178/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3205 - acc: 0.8529 - val_loss: 0.3324 - val_acc: 0.8410\n",
      "Epoch 179/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3221 - acc: 0.8500 - val_loss: 0.3324 - val_acc: 0.8421\n",
      "Epoch 180/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3251 - acc: 0.8485 - val_loss: 0.3320 - val_acc: 0.8432\n",
      "Epoch 181/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3225 - acc: 0.8540 - val_loss: 0.3320 - val_acc: 0.8432\n",
      "Epoch 182/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3209 - acc: 0.8539 - val_loss: 0.3318 - val_acc: 0.8432\n",
      "Epoch 183/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3236 - acc: 0.8543 - val_loss: 0.3317 - val_acc: 0.8443\n",
      "Epoch 184/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3217 - acc: 0.8519 - val_loss: 0.3318 - val_acc: 0.8421\n",
      "Epoch 185/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3211 - acc: 0.8512 - val_loss: 0.3318 - val_acc: 0.8421\n",
      "Epoch 186/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3228 - acc: 0.8539 - val_loss: 0.3316 - val_acc: 0.8443\n",
      "Epoch 187/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3240 - acc: 0.8500 - val_loss: 0.3315 - val_acc: 0.8443\n",
      "Epoch 188/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3219 - acc: 0.8530 - val_loss: 0.3317 - val_acc: 0.8432\n",
      "Epoch 189/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3205 - acc: 0.8540 - val_loss: 0.3313 - val_acc: 0.8443\n",
      "Epoch 190/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3228 - acc: 0.8524 - val_loss: 0.3315 - val_acc: 0.8432\n",
      "Epoch 191/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3221 - acc: 0.8530 - val_loss: 0.3313 - val_acc: 0.8443\n",
      "Epoch 192/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3203 - acc: 0.8552 - val_loss: 0.3315 - val_acc: 0.8443\n",
      "Epoch 193/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3196 - acc: 0.8512 - val_loss: 0.3312 - val_acc: 0.8454\n",
      "Epoch 194/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3204 - acc: 0.8519 - val_loss: 0.3314 - val_acc: 0.8432\n",
      "Epoch 195/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3199 - acc: 0.8499 - val_loss: 0.3310 - val_acc: 0.8432\n",
      "Epoch 196/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3183 - acc: 0.8555 - val_loss: 0.3311 - val_acc: 0.8443\n",
      "Epoch 197/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3219 - acc: 0.8517 - val_loss: 0.3308 - val_acc: 0.8443\n",
      "Epoch 198/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3213 - acc: 0.8538 - val_loss: 0.3309 - val_acc: 0.8443\n",
      "Epoch 199/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3201 - acc: 0.8557 - val_loss: 0.3309 - val_acc: 0.8454\n",
      "Epoch 200/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3212 - acc: 0.8503 - val_loss: 0.3308 - val_acc: 0.8465\n",
      "Epoch 201/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3180 - acc: 0.8529 - val_loss: 0.3306 - val_acc: 0.8443\n",
      "Epoch 202/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3202 - acc: 0.8530 - val_loss: 0.3307 - val_acc: 0.8432\n",
      "Epoch 203/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3204 - acc: 0.8546 - val_loss: 0.3305 - val_acc: 0.8443\n",
      "Epoch 204/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3199 - acc: 0.8546 - val_loss: 0.3304 - val_acc: 0.8454\n",
      "Epoch 205/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3202 - acc: 0.8555 - val_loss: 0.3305 - val_acc: 0.8454\n",
      "Epoch 206/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3173 - acc: 0.8588 - val_loss: 0.3304 - val_acc: 0.8454\n",
      "Epoch 207/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3194 - acc: 0.8534 - val_loss: 0.3304 - val_acc: 0.8465\n",
      "Epoch 208/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3190 - acc: 0.8536 - val_loss: 0.3303 - val_acc: 0.8443\n",
      "Epoch 209/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3202 - acc: 0.8549 - val_loss: 0.3301 - val_acc: 0.8465\n",
      "Epoch 210/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3189 - acc: 0.8563 - val_loss: 0.3302 - val_acc: 0.8465\n",
      "Epoch 211/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3185 - acc: 0.8580 - val_loss: 0.3301 - val_acc: 0.8454\n",
      "Epoch 212/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3183 - acc: 0.8552 - val_loss: 0.3301 - val_acc: 0.8465\n",
      "Epoch 213/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3178 - acc: 0.8544 - val_loss: 0.3301 - val_acc: 0.8476\n",
      "Epoch 214/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3193 - acc: 0.8543 - val_loss: 0.3299 - val_acc: 0.8465\n",
      "Epoch 215/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3167 - acc: 0.8544 - val_loss: 0.3298 - val_acc: 0.8476\n",
      "Epoch 216/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3186 - acc: 0.8562 - val_loss: 0.3298 - val_acc: 0.8487\n",
      "Epoch 217/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3190 - acc: 0.8533 - val_loss: 0.3299 - val_acc: 0.8465\n",
      "Epoch 218/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3165 - acc: 0.8574 - val_loss: 0.3298 - val_acc: 0.8465\n",
      "Epoch 219/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3185 - acc: 0.8557 - val_loss: 0.3297 - val_acc: 0.8476\n",
      "Epoch 220/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3148 - acc: 0.8571 - val_loss: 0.3296 - val_acc: 0.8454\n",
      "Epoch 221/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3197 - acc: 0.8550 - val_loss: 0.3293 - val_acc: 0.8454\n",
      "Epoch 222/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3182 - acc: 0.8563 - val_loss: 0.3293 - val_acc: 0.8465\n",
      "Epoch 223/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3167 - acc: 0.8552 - val_loss: 0.3292 - val_acc: 0.8487\n",
      "Epoch 224/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3177 - acc: 0.8557 - val_loss: 0.3292 - val_acc: 0.8454\n",
      "Epoch 225/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3181 - acc: 0.8550 - val_loss: 0.3291 - val_acc: 0.8487\n",
      "Epoch 226/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3146 - acc: 0.8540 - val_loss: 0.3294 - val_acc: 0.8487\n",
      "Epoch 227/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3176 - acc: 0.8551 - val_loss: 0.3290 - val_acc: 0.8476\n",
      "Epoch 228/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3150 - acc: 0.8575 - val_loss: 0.3287 - val_acc: 0.8454\n",
      "Epoch 229/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3173 - acc: 0.8522 - val_loss: 0.3286 - val_acc: 0.8454\n",
      "Epoch 230/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3156 - acc: 0.8564 - val_loss: 0.3290 - val_acc: 0.8487\n",
      "Epoch 231/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3186 - acc: 0.8550 - val_loss: 0.3288 - val_acc: 0.8498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3154 - acc: 0.8574 - val_loss: 0.3288 - val_acc: 0.8465\n",
      "Epoch 233/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3159 - acc: 0.8574 - val_loss: 0.3288 - val_acc: 0.8476\n",
      "Epoch 234/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3178 - acc: 0.8536 - val_loss: 0.3288 - val_acc: 0.8487\n",
      "Epoch 235/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3155 - acc: 0.8573 - val_loss: 0.3285 - val_acc: 0.8498\n",
      "Epoch 236/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3191 - acc: 0.8528 - val_loss: 0.3284 - val_acc: 0.8454\n",
      "Epoch 237/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3170 - acc: 0.8574 - val_loss: 0.3282 - val_acc: 0.8476\n",
      "Epoch 238/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3164 - acc: 0.8573 - val_loss: 0.3284 - val_acc: 0.8476\n",
      "Epoch 239/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3143 - acc: 0.8574 - val_loss: 0.3284 - val_acc: 0.8487\n",
      "Epoch 240/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3129 - acc: 0.8547 - val_loss: 0.3282 - val_acc: 0.8476\n",
      "Epoch 241/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3156 - acc: 0.8524 - val_loss: 0.3282 - val_acc: 0.8465\n",
      "Epoch 242/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3160 - acc: 0.8571 - val_loss: 0.3282 - val_acc: 0.8487\n",
      "Epoch 243/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3147 - acc: 0.8578 - val_loss: 0.3281 - val_acc: 0.8465\n",
      "Epoch 244/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3144 - acc: 0.8589 - val_loss: 0.3282 - val_acc: 0.8498\n",
      "Epoch 245/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3161 - acc: 0.8541 - val_loss: 0.3282 - val_acc: 0.8487\n",
      "Epoch 246/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3143 - acc: 0.8577 - val_loss: 0.3279 - val_acc: 0.8476\n",
      "Epoch 247/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3149 - acc: 0.8575 - val_loss: 0.3278 - val_acc: 0.8476\n",
      "Epoch 248/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3148 - acc: 0.8555 - val_loss: 0.3278 - val_acc: 0.8476\n",
      "Epoch 249/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3131 - acc: 0.8557 - val_loss: 0.3278 - val_acc: 0.8498\n",
      "Epoch 250/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3136 - acc: 0.8546 - val_loss: 0.3280 - val_acc: 0.8498\n",
      "Epoch 251/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3153 - acc: 0.8558 - val_loss: 0.3278 - val_acc: 0.8487\n",
      "Epoch 252/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3137 - acc: 0.8547 - val_loss: 0.3277 - val_acc: 0.8487\n",
      "Epoch 253/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3129 - acc: 0.8560 - val_loss: 0.3275 - val_acc: 0.8509\n",
      "Epoch 254/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3153 - acc: 0.8540 - val_loss: 0.3276 - val_acc: 0.8487\n",
      "Epoch 255/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3165 - acc: 0.8568 - val_loss: 0.3275 - val_acc: 0.8487\n",
      "Epoch 256/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3147 - acc: 0.8547 - val_loss: 0.3273 - val_acc: 0.8498\n",
      "Epoch 257/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3143 - acc: 0.8569 - val_loss: 0.3276 - val_acc: 0.8476\n",
      "Epoch 258/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3137 - acc: 0.8556 - val_loss: 0.3274 - val_acc: 0.8487\n",
      "Epoch 259/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3138 - acc: 0.8560 - val_loss: 0.3273 - val_acc: 0.8509\n",
      "Epoch 260/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3153 - acc: 0.8580 - val_loss: 0.3268 - val_acc: 0.8498\n",
      "Epoch 261/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3146 - acc: 0.8582 - val_loss: 0.3268 - val_acc: 0.8498\n",
      "Epoch 262/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3129 - acc: 0.8563 - val_loss: 0.3271 - val_acc: 0.8498\n",
      "Epoch 263/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3131 - acc: 0.8589 - val_loss: 0.3270 - val_acc: 0.8509\n",
      "Epoch 264/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3155 - acc: 0.8566 - val_loss: 0.3269 - val_acc: 0.8476\n",
      "Epoch 265/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3128 - acc: 0.8584 - val_loss: 0.3270 - val_acc: 0.8509\n",
      "Epoch 266/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3158 - acc: 0.8585 - val_loss: 0.3266 - val_acc: 0.8498\n",
      "Epoch 267/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3123 - acc: 0.8577 - val_loss: 0.3266 - val_acc: 0.8487\n",
      "Epoch 268/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3126 - acc: 0.8567 - val_loss: 0.3265 - val_acc: 0.8509\n",
      "Epoch 269/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3130 - acc: 0.8580 - val_loss: 0.3266 - val_acc: 0.8487\n",
      "Epoch 270/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3122 - acc: 0.8600 - val_loss: 0.3266 - val_acc: 0.8487\n",
      "Epoch 271/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3116 - acc: 0.8597 - val_loss: 0.3265 - val_acc: 0.8498\n",
      "Epoch 272/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3134 - acc: 0.8596 - val_loss: 0.3262 - val_acc: 0.8509\n",
      "Epoch 273/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3106 - acc: 0.8601 - val_loss: 0.3263 - val_acc: 0.8509\n",
      "Epoch 274/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3117 - acc: 0.8567 - val_loss: 0.3262 - val_acc: 0.8498\n",
      "Epoch 275/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3109 - acc: 0.8591 - val_loss: 0.3262 - val_acc: 0.8498\n",
      "Epoch 276/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3111 - acc: 0.8607 - val_loss: 0.3262 - val_acc: 0.8498\n",
      "Epoch 277/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3112 - acc: 0.8595 - val_loss: 0.3262 - val_acc: 0.8498\n",
      "Epoch 278/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3120 - acc: 0.8571 - val_loss: 0.3261 - val_acc: 0.8487\n",
      "Epoch 279/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3116 - acc: 0.8549 - val_loss: 0.3258 - val_acc: 0.8509\n",
      "Epoch 280/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3122 - acc: 0.8580 - val_loss: 0.3259 - val_acc: 0.8498\n",
      "Epoch 281/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3115 - acc: 0.8551 - val_loss: 0.3256 - val_acc: 0.8509\n",
      "Epoch 282/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3087 - acc: 0.8594 - val_loss: 0.3259 - val_acc: 0.8498\n",
      "Epoch 283/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3106 - acc: 0.8569 - val_loss: 0.3257 - val_acc: 0.8509\n",
      "Epoch 284/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3106 - acc: 0.8589 - val_loss: 0.3259 - val_acc: 0.8509\n",
      "Epoch 285/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3078 - acc: 0.8602 - val_loss: 0.3259 - val_acc: 0.8498\n",
      "Epoch 286/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3117 - acc: 0.8563 - val_loss: 0.3255 - val_acc: 0.8509\n",
      "Epoch 287/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3130 - acc: 0.8535 - val_loss: 0.3253 - val_acc: 0.8498\n",
      "Epoch 288/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3112 - acc: 0.8572 - val_loss: 0.3254 - val_acc: 0.8498\n",
      "Epoch 289/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3118 - acc: 0.8582 - val_loss: 0.3251 - val_acc: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3101 - acc: 0.8580 - val_loss: 0.3253 - val_acc: 0.8487\n",
      "Epoch 291/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3103 - acc: 0.8606 - val_loss: 0.3251 - val_acc: 0.8487\n",
      "Epoch 292/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3079 - acc: 0.8624 - val_loss: 0.3249 - val_acc: 0.8520\n",
      "Epoch 293/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3108 - acc: 0.8588 - val_loss: 0.3249 - val_acc: 0.8509\n",
      "Epoch 294/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3086 - acc: 0.8616 - val_loss: 0.3249 - val_acc: 0.8509\n",
      "Epoch 295/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3095 - acc: 0.8599 - val_loss: 0.3249 - val_acc: 0.8487\n",
      "Epoch 296/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3102 - acc: 0.8607 - val_loss: 0.3251 - val_acc: 0.8509\n",
      "Epoch 297/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3098 - acc: 0.8590 - val_loss: 0.3251 - val_acc: 0.8509\n",
      "Epoch 298/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3085 - acc: 0.8564 - val_loss: 0.3247 - val_acc: 0.8509\n",
      "Epoch 299/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3087 - acc: 0.8594 - val_loss: 0.3246 - val_acc: 0.8520\n",
      "Epoch 300/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3105 - acc: 0.8582 - val_loss: 0.3245 - val_acc: 0.8498\n",
      "Epoch 301/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3088 - acc: 0.8588 - val_loss: 0.3244 - val_acc: 0.8465\n",
      "Epoch 302/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3083 - acc: 0.8613 - val_loss: 0.3244 - val_acc: 0.8520\n",
      "Epoch 303/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3105 - acc: 0.8590 - val_loss: 0.3244 - val_acc: 0.8498\n",
      "Epoch 304/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3098 - acc: 0.8594 - val_loss: 0.3244 - val_acc: 0.8520\n",
      "Epoch 305/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3092 - acc: 0.8574 - val_loss: 0.3244 - val_acc: 0.8487\n",
      "Epoch 306/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3092 - acc: 0.8623 - val_loss: 0.3241 - val_acc: 0.8520\n",
      "Epoch 307/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3073 - acc: 0.8594 - val_loss: 0.3242 - val_acc: 0.8509\n",
      "Epoch 308/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3101 - acc: 0.8568 - val_loss: 0.3241 - val_acc: 0.8520\n",
      "Epoch 309/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3094 - acc: 0.8589 - val_loss: 0.3239 - val_acc: 0.8509\n",
      "Epoch 310/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3085 - acc: 0.8595 - val_loss: 0.3244 - val_acc: 0.8487\n",
      "Epoch 311/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3092 - acc: 0.8589 - val_loss: 0.3240 - val_acc: 0.8520\n",
      "Epoch 312/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3084 - acc: 0.8597 - val_loss: 0.3238 - val_acc: 0.8509\n",
      "Epoch 313/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3099 - acc: 0.8595 - val_loss: 0.3236 - val_acc: 0.8520\n",
      "Epoch 314/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3072 - acc: 0.8589 - val_loss: 0.3235 - val_acc: 0.8520\n",
      "Epoch 315/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3087 - acc: 0.8578 - val_loss: 0.3237 - val_acc: 0.8520\n",
      "Epoch 316/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3083 - acc: 0.8584 - val_loss: 0.3238 - val_acc: 0.8520\n",
      "Epoch 317/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3085 - acc: 0.8618 - val_loss: 0.3237 - val_acc: 0.8498\n",
      "Epoch 318/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3058 - acc: 0.8608 - val_loss: 0.3235 - val_acc: 0.8509\n",
      "Epoch 319/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3083 - acc: 0.8590 - val_loss: 0.3240 - val_acc: 0.8487\n",
      "Epoch 320/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3090 - acc: 0.8596 - val_loss: 0.3238 - val_acc: 0.8509\n",
      "Epoch 321/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3109 - acc: 0.8591 - val_loss: 0.3236 - val_acc: 0.8520\n",
      "Epoch 322/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3057 - acc: 0.8590 - val_loss: 0.3238 - val_acc: 0.8509\n",
      "Epoch 323/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3073 - acc: 0.8549 - val_loss: 0.3237 - val_acc: 0.8509\n",
      "Epoch 324/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3068 - acc: 0.8601 - val_loss: 0.3235 - val_acc: 0.8509\n",
      "Epoch 325/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3058 - acc: 0.8618 - val_loss: 0.3235 - val_acc: 0.8509\n",
      "Epoch 326/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3096 - acc: 0.8591 - val_loss: 0.3234 - val_acc: 0.8509\n",
      "Epoch 327/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3099 - acc: 0.8640 - val_loss: 0.3232 - val_acc: 0.8487\n",
      "Epoch 328/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3093 - acc: 0.8588 - val_loss: 0.3232 - val_acc: 0.8509\n",
      "Epoch 329/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3054 - acc: 0.8611 - val_loss: 0.3234 - val_acc: 0.8487\n",
      "Epoch 330/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3085 - acc: 0.8595 - val_loss: 0.3232 - val_acc: 0.8509\n",
      "Epoch 331/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3089 - acc: 0.8607 - val_loss: 0.3230 - val_acc: 0.8509\n",
      "Epoch 332/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3071 - acc: 0.8583 - val_loss: 0.3231 - val_acc: 0.8520\n",
      "Epoch 333/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3064 - acc: 0.8607 - val_loss: 0.3232 - val_acc: 0.8509\n",
      "Epoch 334/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3071 - acc: 0.8625 - val_loss: 0.3229 - val_acc: 0.8520\n",
      "Epoch 335/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3042 - acc: 0.8602 - val_loss: 0.3229 - val_acc: 0.8509\n",
      "Epoch 336/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3059 - acc: 0.8600 - val_loss: 0.3228 - val_acc: 0.8531\n",
      "Epoch 337/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3079 - acc: 0.8612 - val_loss: 0.3227 - val_acc: 0.8509\n",
      "Epoch 338/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3059 - acc: 0.8612 - val_loss: 0.3226 - val_acc: 0.8520\n",
      "Epoch 339/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3062 - acc: 0.8625 - val_loss: 0.3226 - val_acc: 0.8520\n",
      "Epoch 340/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3082 - acc: 0.8590 - val_loss: 0.3227 - val_acc: 0.8498\n",
      "Epoch 341/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3077 - acc: 0.8614 - val_loss: 0.3223 - val_acc: 0.8531\n",
      "Epoch 342/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3078 - acc: 0.8625 - val_loss: 0.3223 - val_acc: 0.8520\n",
      "Epoch 343/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3077 - acc: 0.8616 - val_loss: 0.3224 - val_acc: 0.8542\n",
      "Epoch 344/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3057 - acc: 0.8636 - val_loss: 0.3224 - val_acc: 0.8542\n",
      "Epoch 345/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3049 - acc: 0.8597 - val_loss: 0.3224 - val_acc: 0.8531\n",
      "Epoch 346/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3059 - acc: 0.8601 - val_loss: 0.3224 - val_acc: 0.8542\n",
      "Epoch 347/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3058 - acc: 0.8589 - val_loss: 0.3224 - val_acc: 0.8531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3050 - acc: 0.8619 - val_loss: 0.3225 - val_acc: 0.8487\n",
      "Epoch 349/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3059 - acc: 0.8603 - val_loss: 0.3224 - val_acc: 0.8553\n",
      "Epoch 350/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3054 - acc: 0.8599 - val_loss: 0.3219 - val_acc: 0.8553\n",
      "Epoch 351/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3064 - acc: 0.8614 - val_loss: 0.3220 - val_acc: 0.8564\n",
      "Epoch 352/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3053 - acc: 0.8600 - val_loss: 0.3221 - val_acc: 0.8542\n",
      "Epoch 353/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3026 - acc: 0.8632 - val_loss: 0.3222 - val_acc: 0.8542\n",
      "Epoch 354/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3036 - acc: 0.8623 - val_loss: 0.3219 - val_acc: 0.8509\n",
      "Epoch 355/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3047 - acc: 0.8618 - val_loss: 0.3221 - val_acc: 0.8520\n",
      "Epoch 356/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3057 - acc: 0.8612 - val_loss: 0.3218 - val_acc: 0.8564\n",
      "Epoch 357/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3052 - acc: 0.8608 - val_loss: 0.3217 - val_acc: 0.8531\n",
      "Epoch 358/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3044 - acc: 0.8614 - val_loss: 0.3218 - val_acc: 0.8564\n",
      "Epoch 359/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3045 - acc: 0.8617 - val_loss: 0.3221 - val_acc: 0.8542\n",
      "Epoch 360/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3066 - acc: 0.8599 - val_loss: 0.3220 - val_acc: 0.8586\n",
      "Epoch 361/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3042 - acc: 0.8601 - val_loss: 0.3217 - val_acc: 0.8564\n",
      "Epoch 362/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3056 - acc: 0.8601 - val_loss: 0.3219 - val_acc: 0.8520\n",
      "Epoch 363/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3020 - acc: 0.8630 - val_loss: 0.3220 - val_acc: 0.8575\n",
      "Epoch 364/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3054 - acc: 0.8591 - val_loss: 0.3219 - val_acc: 0.8564\n",
      "Epoch 365/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3028 - acc: 0.8621 - val_loss: 0.3219 - val_acc: 0.8542\n",
      "Epoch 366/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3016 - acc: 0.8594 - val_loss: 0.3220 - val_acc: 0.8531\n",
      "Epoch 367/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3043 - acc: 0.8635 - val_loss: 0.3216 - val_acc: 0.8575\n",
      "Epoch 368/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3035 - acc: 0.8628 - val_loss: 0.3216 - val_acc: 0.8586\n",
      "Epoch 369/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3046 - acc: 0.8596 - val_loss: 0.3217 - val_acc: 0.8531\n",
      "Epoch 370/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3013 - acc: 0.8629 - val_loss: 0.3216 - val_acc: 0.8553\n",
      "Epoch 371/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3032 - acc: 0.8597 - val_loss: 0.3216 - val_acc: 0.8575\n",
      "Epoch 372/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3056 - acc: 0.8589 - val_loss: 0.3215 - val_acc: 0.8564\n",
      "Epoch 373/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3024 - acc: 0.8645 - val_loss: 0.3217 - val_acc: 0.8542\n",
      "Epoch 374/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3039 - acc: 0.8601 - val_loss: 0.3217 - val_acc: 0.8564\n",
      "Epoch 375/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3060 - acc: 0.8618 - val_loss: 0.3215 - val_acc: 0.8542\n",
      "Epoch 376/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3035 - acc: 0.8639 - val_loss: 0.3215 - val_acc: 0.8553\n",
      "Epoch 377/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3015 - acc: 0.8625 - val_loss: 0.3214 - val_acc: 0.8564\n",
      "Epoch 378/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3010 - acc: 0.8662 - val_loss: 0.3213 - val_acc: 0.8564\n",
      "Epoch 379/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3056 - acc: 0.8611 - val_loss: 0.3211 - val_acc: 0.8542\n",
      "Epoch 380/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3016 - acc: 0.8614 - val_loss: 0.3213 - val_acc: 0.8531\n",
      "Epoch 381/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3060 - acc: 0.8608 - val_loss: 0.3211 - val_acc: 0.8553\n",
      "Epoch 382/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3030 - acc: 0.8623 - val_loss: 0.3212 - val_acc: 0.8553\n",
      "Epoch 383/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3017 - acc: 0.8623 - val_loss: 0.3210 - val_acc: 0.8564\n",
      "Epoch 384/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2999 - acc: 0.8643 - val_loss: 0.3213 - val_acc: 0.8553\n",
      "Epoch 385/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3029 - acc: 0.8627 - val_loss: 0.3211 - val_acc: 0.8564\n",
      "Epoch 386/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3034 - acc: 0.8633 - val_loss: 0.3206 - val_acc: 0.8575\n",
      "Epoch 387/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3024 - acc: 0.8630 - val_loss: 0.3208 - val_acc: 0.8564\n",
      "Epoch 388/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3028 - acc: 0.8613 - val_loss: 0.3208 - val_acc: 0.8575\n",
      "Epoch 389/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3027 - acc: 0.8595 - val_loss: 0.3210 - val_acc: 0.8575\n",
      "Epoch 390/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3033 - acc: 0.8652 - val_loss: 0.3211 - val_acc: 0.8542\n",
      "Epoch 391/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3025 - acc: 0.8600 - val_loss: 0.3209 - val_acc: 0.8564\n",
      "Epoch 392/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3014 - acc: 0.8629 - val_loss: 0.3210 - val_acc: 0.8575\n",
      "Epoch 393/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3029 - acc: 0.8622 - val_loss: 0.3208 - val_acc: 0.8564\n",
      "Epoch 394/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3014 - acc: 0.8640 - val_loss: 0.3209 - val_acc: 0.8553\n",
      "Epoch 395/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3021 - acc: 0.8629 - val_loss: 0.3208 - val_acc: 0.8564\n",
      "Epoch 396/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3008 - acc: 0.8643 - val_loss: 0.3204 - val_acc: 0.8553\n",
      "Epoch 397/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3036 - acc: 0.8603 - val_loss: 0.3209 - val_acc: 0.8564\n",
      "Epoch 398/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3025 - acc: 0.8621 - val_loss: 0.3211 - val_acc: 0.8575\n",
      "Epoch 399/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3009 - acc: 0.8645 - val_loss: 0.3207 - val_acc: 0.8564\n",
      "Epoch 400/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3005 - acc: 0.8649 - val_loss: 0.3205 - val_acc: 0.8564\n",
      "Epoch 401/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3015 - acc: 0.8635 - val_loss: 0.3204 - val_acc: 0.8553\n",
      "Epoch 402/10000\n",
      "8199/8199 [==============================] - 0s 28us/sample - loss: 0.2996 - acc: 0.8616 - val_loss: 0.3209 - val_acc: 0.8553\n",
      "Epoch 403/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3010 - acc: 0.8645 - val_loss: 0.3206 - val_acc: 0.8575\n",
      "Epoch 404/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3014 - acc: 0.8602 - val_loss: 0.3208 - val_acc: 0.8575\n",
      "Epoch 405/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3008 - acc: 0.8629 - val_loss: 0.3203 - val_acc: 0.8564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3019 - acc: 0.8632 - val_loss: 0.3204 - val_acc: 0.8564\n",
      "Epoch 407/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3018 - acc: 0.8613 - val_loss: 0.3205 - val_acc: 0.8575\n",
      "Epoch 408/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3020 - acc: 0.8635 - val_loss: 0.3201 - val_acc: 0.8575\n",
      "Epoch 409/10000\n",
      "8199/8199 [==============================] - 0s 29us/sample - loss: 0.2989 - acc: 0.8623 - val_loss: 0.3202 - val_acc: 0.8575\n",
      "Epoch 410/10000\n",
      "8199/8199 [==============================] - 0s 29us/sample - loss: 0.3019 - acc: 0.8652 - val_loss: 0.3201 - val_acc: 0.8586\n",
      "Epoch 411/10000\n",
      "8199/8199 [==============================] - 0s 28us/sample - loss: 0.2996 - acc: 0.8639 - val_loss: 0.3204 - val_acc: 0.8575\n",
      "Epoch 412/10000\n",
      "8199/8199 [==============================] - 0s 28us/sample - loss: 0.3017 - acc: 0.8617 - val_loss: 0.3206 - val_acc: 0.8575\n",
      "Epoch 413/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2993 - acc: 0.8636 - val_loss: 0.3205 - val_acc: 0.8564\n",
      "Epoch 414/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2975 - acc: 0.8629 - val_loss: 0.3203 - val_acc: 0.8575\n",
      "Epoch 415/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3022 - acc: 0.8630 - val_loss: 0.3201 - val_acc: 0.8575\n",
      "Epoch 416/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3018 - acc: 0.8625 - val_loss: 0.3204 - val_acc: 0.8596\n",
      "Epoch 417/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2991 - acc: 0.8627 - val_loss: 0.3202 - val_acc: 0.8575\n",
      "Epoch 418/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2994 - acc: 0.8658 - val_loss: 0.3198 - val_acc: 0.8575\n",
      "Epoch 419/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3008 - acc: 0.8652 - val_loss: 0.3199 - val_acc: 0.8575\n",
      "Epoch 420/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3023 - acc: 0.8627 - val_loss: 0.3200 - val_acc: 0.8564\n",
      "Epoch 421/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3024 - acc: 0.8593 - val_loss: 0.3200 - val_acc: 0.8564\n",
      "Epoch 422/10000\n",
      "8199/8199 [==============================] - 0s 28us/sample - loss: 0.3006 - acc: 0.8660 - val_loss: 0.3200 - val_acc: 0.8564\n",
      "Epoch 423/10000\n",
      "8199/8199 [==============================] - 0s 29us/sample - loss: 0.2992 - acc: 0.8621 - val_loss: 0.3200 - val_acc: 0.8575\n",
      "Epoch 424/10000\n",
      "8199/8199 [==============================] - 0s 28us/sample - loss: 0.3009 - acc: 0.8662 - val_loss: 0.3200 - val_acc: 0.8564\n",
      "Epoch 425/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2987 - acc: 0.8645 - val_loss: 0.3200 - val_acc: 0.8575\n",
      "Epoch 426/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2997 - acc: 0.8651 - val_loss: 0.3200 - val_acc: 0.8553\n",
      "Epoch 427/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3021 - acc: 0.8623 - val_loss: 0.3200 - val_acc: 0.8575\n",
      "Epoch 428/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2990 - acc: 0.8651 - val_loss: 0.3197 - val_acc: 0.8553\n",
      "Epoch 429/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2991 - acc: 0.8656 - val_loss: 0.3198 - val_acc: 0.8564\n",
      "Epoch 430/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3016 - acc: 0.8634 - val_loss: 0.3194 - val_acc: 0.8564\n",
      "Epoch 431/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2990 - acc: 0.8645 - val_loss: 0.3197 - val_acc: 0.8575\n",
      "Epoch 432/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3007 - acc: 0.8627 - val_loss: 0.3198 - val_acc: 0.8564\n",
      "Epoch 433/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3026 - acc: 0.8608 - val_loss: 0.3200 - val_acc: 0.8586\n",
      "Epoch 434/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2995 - acc: 0.8663 - val_loss: 0.3198 - val_acc: 0.8586\n",
      "Epoch 435/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2988 - acc: 0.8629 - val_loss: 0.3199 - val_acc: 0.8575\n",
      "Epoch 436/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2991 - acc: 0.8621 - val_loss: 0.3197 - val_acc: 0.8575\n",
      "Epoch 437/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2977 - acc: 0.8636 - val_loss: 0.3200 - val_acc: 0.8575\n",
      "Epoch 438/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2997 - acc: 0.8639 - val_loss: 0.3199 - val_acc: 0.8564\n",
      "Epoch 439/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2986 - acc: 0.8625 - val_loss: 0.3198 - val_acc: 0.8575\n",
      "Epoch 440/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2973 - acc: 0.8661 - val_loss: 0.3202 - val_acc: 0.8575\n",
      "Epoch 441/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2988 - acc: 0.8650 - val_loss: 0.3198 - val_acc: 0.8575\n",
      "Epoch 442/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3007 - acc: 0.8634 - val_loss: 0.3196 - val_acc: 0.8575\n",
      "Epoch 443/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2994 - acc: 0.8644 - val_loss: 0.3193 - val_acc: 0.8553\n",
      "Epoch 444/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2985 - acc: 0.8655 - val_loss: 0.3198 - val_acc: 0.8575\n",
      "Epoch 445/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2997 - acc: 0.8641 - val_loss: 0.3198 - val_acc: 0.8553\n",
      "Epoch 446/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3002 - acc: 0.8651 - val_loss: 0.3198 - val_acc: 0.8564\n",
      "Epoch 447/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3000 - acc: 0.8640 - val_loss: 0.3199 - val_acc: 0.8575\n",
      "Epoch 448/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2991 - acc: 0.8649 - val_loss: 0.3201 - val_acc: 0.8575\n",
      "Epoch 449/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2981 - acc: 0.8688 - val_loss: 0.3195 - val_acc: 0.8564\n",
      "Epoch 450/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2979 - acc: 0.8649 - val_loss: 0.3197 - val_acc: 0.8564\n",
      "Epoch 451/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2967 - acc: 0.8656 - val_loss: 0.3199 - val_acc: 0.8564\n",
      "Epoch 452/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2989 - acc: 0.8621 - val_loss: 0.3197 - val_acc: 0.8564\n",
      "Epoch 453/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3020 - acc: 0.8649 - val_loss: 0.3195 - val_acc: 0.8564\n",
      "Epoch 454/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2982 - acc: 0.8653 - val_loss: 0.3194 - val_acc: 0.8564\n",
      "Epoch 455/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2980 - acc: 0.8644 - val_loss: 0.3198 - val_acc: 0.8564\n",
      "Epoch 456/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3006 - acc: 0.8647 - val_loss: 0.3194 - val_acc: 0.8553\n",
      "Epoch 457/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2995 - acc: 0.8647 - val_loss: 0.3194 - val_acc: 0.8564\n",
      "Epoch 458/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2958 - acc: 0.8640 - val_loss: 0.3195 - val_acc: 0.8575\n",
      "Epoch 459/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2948 - acc: 0.8671 - val_loss: 0.3191 - val_acc: 0.8564\n",
      "Epoch 460/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2962 - acc: 0.8640 - val_loss: 0.3196 - val_acc: 0.8564\n",
      "Epoch 461/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2980 - acc: 0.8668 - val_loss: 0.3197 - val_acc: 0.8575\n",
      "Epoch 462/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.3007 - acc: 0.8683 - val_loss: 0.3191 - val_acc: 0.8564\n",
      "Epoch 463/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2992 - acc: 0.8645 - val_loss: 0.3189 - val_acc: 0.8564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2978 - acc: 0.8649 - val_loss: 0.3189 - val_acc: 0.8564\n",
      "Epoch 465/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2979 - acc: 0.8645 - val_loss: 0.3194 - val_acc: 0.8564\n",
      "Epoch 466/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2953 - acc: 0.8669 - val_loss: 0.3191 - val_acc: 0.8575\n",
      "Epoch 467/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2983 - acc: 0.8660 - val_loss: 0.3191 - val_acc: 0.8564\n",
      "Epoch 468/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2998 - acc: 0.8625 - val_loss: 0.3193 - val_acc: 0.8564\n",
      "Epoch 469/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2995 - acc: 0.8647 - val_loss: 0.3195 - val_acc: 0.8542\n",
      "Epoch 470/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2976 - acc: 0.8640 - val_loss: 0.3191 - val_acc: 0.8564\n",
      "Epoch 471/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2992 - acc: 0.8666 - val_loss: 0.3194 - val_acc: 0.8575\n",
      "Epoch 472/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2966 - acc: 0.8700 - val_loss: 0.3194 - val_acc: 0.8564\n",
      "Epoch 473/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2957 - acc: 0.8677 - val_loss: 0.3195 - val_acc: 0.8586\n",
      "Epoch 474/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2975 - acc: 0.8649 - val_loss: 0.3194 - val_acc: 0.8575\n",
      "Epoch 475/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2950 - acc: 0.8664 - val_loss: 0.3190 - val_acc: 0.8553\n",
      "Epoch 476/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2972 - acc: 0.8664 - val_loss: 0.3191 - val_acc: 0.8553\n",
      "Epoch 477/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2962 - acc: 0.8625 - val_loss: 0.3193 - val_acc: 0.8553\n",
      "Epoch 478/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2932 - acc: 0.8671 - val_loss: 0.3192 - val_acc: 0.8542\n",
      "Epoch 479/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2972 - acc: 0.8630 - val_loss: 0.3191 - val_acc: 0.8564\n",
      "Epoch 480/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2974 - acc: 0.8651 - val_loss: 0.3192 - val_acc: 0.8553\n",
      "Epoch 481/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2987 - acc: 0.8651 - val_loss: 0.3193 - val_acc: 0.8564\n",
      "Epoch 482/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2973 - acc: 0.8646 - val_loss: 0.3192 - val_acc: 0.8564\n",
      "Epoch 483/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2938 - acc: 0.8686 - val_loss: 0.3195 - val_acc: 0.8575\n",
      "Epoch 484/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2975 - acc: 0.8638 - val_loss: 0.3192 - val_acc: 0.8564\n",
      "Epoch 485/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2967 - acc: 0.8658 - val_loss: 0.3197 - val_acc: 0.8553\n",
      "Epoch 486/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2969 - acc: 0.8636 - val_loss: 0.3193 - val_acc: 0.8542\n",
      "Epoch 487/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2985 - acc: 0.8635 - val_loss: 0.3192 - val_acc: 0.8553\n",
      "Epoch 488/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2960 - acc: 0.8672 - val_loss: 0.3193 - val_acc: 0.8553\n",
      "Epoch 489/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2957 - acc: 0.8671 - val_loss: 0.3189 - val_acc: 0.8542\n",
      "Epoch 490/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2950 - acc: 0.8662 - val_loss: 0.3193 - val_acc: 0.8542\n",
      "Epoch 491/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2939 - acc: 0.8674 - val_loss: 0.3190 - val_acc: 0.8564\n",
      "Epoch 492/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2975 - acc: 0.8632 - val_loss: 0.3194 - val_acc: 0.8553\n",
      "Epoch 493/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2963 - acc: 0.8668 - val_loss: 0.3194 - val_acc: 0.8542\n",
      "Epoch 494/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2951 - acc: 0.8675 - val_loss: 0.3193 - val_acc: 0.8531\n",
      "Epoch 495/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2991 - acc: 0.8656 - val_loss: 0.3196 - val_acc: 0.8553\n",
      "Epoch 496/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2956 - acc: 0.8644 - val_loss: 0.3200 - val_acc: 0.8553\n",
      "Epoch 497/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2920 - acc: 0.8711 - val_loss: 0.3201 - val_acc: 0.8553\n",
      "Epoch 498/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2963 - acc: 0.8678 - val_loss: 0.3197 - val_acc: 0.8531\n",
      "Epoch 499/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2978 - acc: 0.8636 - val_loss: 0.3194 - val_acc: 0.8542\n",
      "Epoch 500/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2976 - acc: 0.8657 - val_loss: 0.3198 - val_acc: 0.8553\n",
      "Epoch 501/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2959 - acc: 0.8706 - val_loss: 0.3194 - val_acc: 0.8542\n",
      "Epoch 502/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2938 - acc: 0.8661 - val_loss: 0.3199 - val_acc: 0.8553\n",
      "Epoch 503/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2969 - acc: 0.8666 - val_loss: 0.3198 - val_acc: 0.8542\n",
      "Epoch 504/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2957 - acc: 0.8686 - val_loss: 0.3196 - val_acc: 0.8564\n",
      "Epoch 505/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2949 - acc: 0.8650 - val_loss: 0.3196 - val_acc: 0.8542\n",
      "Epoch 506/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.3004 - acc: 0.8624 - val_loss: 0.3194 - val_acc: 0.8542\n",
      "Epoch 507/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2922 - acc: 0.8690 - val_loss: 0.3196 - val_acc: 0.8542\n",
      "Epoch 508/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2934 - acc: 0.8673 - val_loss: 0.3195 - val_acc: 0.8553\n",
      "Epoch 509/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2970 - acc: 0.8657 - val_loss: 0.3197 - val_acc: 0.8531\n",
      "Epoch 510/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2920 - acc: 0.8668 - val_loss: 0.3196 - val_acc: 0.8542\n",
      "Epoch 511/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2953 - acc: 0.8696 - val_loss: 0.3196 - val_acc: 0.8531\n",
      "Epoch 512/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2960 - acc: 0.8680 - val_loss: 0.3196 - val_acc: 0.8531\n",
      "Epoch 513/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2945 - acc: 0.8668 - val_loss: 0.3195 - val_acc: 0.8520\n",
      "Epoch 514/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2943 - acc: 0.8661 - val_loss: 0.3195 - val_acc: 0.8542\n",
      "Epoch 515/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2956 - acc: 0.8622 - val_loss: 0.3198 - val_acc: 0.8542\n",
      "Epoch 516/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2958 - acc: 0.8649 - val_loss: 0.3195 - val_acc: 0.8542\n",
      "Epoch 517/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2959 - acc: 0.8657 - val_loss: 0.3197 - val_acc: 0.8553\n",
      "Epoch 518/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2945 - acc: 0.8669 - val_loss: 0.3197 - val_acc: 0.8542\n",
      "Epoch 519/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2925 - acc: 0.8722 - val_loss: 0.3194 - val_acc: 0.8531\n",
      "Epoch 520/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2910 - acc: 0.8707 - val_loss: 0.3196 - val_acc: 0.8542\n",
      "Epoch 521/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2956 - acc: 0.8671 - val_loss: 0.3200 - val_acc: 0.8520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2954 - acc: 0.8657 - val_loss: 0.3198 - val_acc: 0.8520\n",
      "Epoch 523/10000\n",
      "8199/8199 [==============================] - ETA: 0s - loss: 0.2915 - acc: 0.865 - 0s 27us/sample - loss: 0.2926 - acc: 0.8674 - val_loss: 0.3198 - val_acc: 0.8520\n",
      "Epoch 524/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2937 - acc: 0.8669 - val_loss: 0.3196 - val_acc: 0.8542\n",
      "Epoch 525/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2930 - acc: 0.8673 - val_loss: 0.3201 - val_acc: 0.8542\n",
      "Epoch 526/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2909 - acc: 0.8689 - val_loss: 0.3198 - val_acc: 0.8542\n",
      "Epoch 527/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2923 - acc: 0.8699 - val_loss: 0.3194 - val_acc: 0.8531\n",
      "Epoch 528/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2931 - acc: 0.8683 - val_loss: 0.3196 - val_acc: 0.8531\n",
      "Epoch 529/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2941 - acc: 0.8701 - val_loss: 0.3196 - val_acc: 0.8509\n",
      "Epoch 530/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2943 - acc: 0.8689 - val_loss: 0.3194 - val_acc: 0.8531\n",
      "Epoch 531/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2949 - acc: 0.8678 - val_loss: 0.3195 - val_acc: 0.8531\n",
      "Epoch 532/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2911 - acc: 0.8669 - val_loss: 0.3195 - val_acc: 0.8531\n",
      "Epoch 533/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2929 - acc: 0.8694 - val_loss: 0.3197 - val_acc: 0.8531\n",
      "Epoch 534/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2941 - acc: 0.8675 - val_loss: 0.3199 - val_acc: 0.8531\n",
      "Epoch 535/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2921 - acc: 0.8678 - val_loss: 0.3197 - val_acc: 0.8531\n",
      "Epoch 536/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2908 - acc: 0.8673 - val_loss: 0.3198 - val_acc: 0.8553\n",
      "Epoch 537/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2924 - acc: 0.8685 - val_loss: 0.3195 - val_acc: 0.8520\n",
      "Epoch 538/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2929 - acc: 0.8701 - val_loss: 0.3197 - val_acc: 0.8509\n",
      "Epoch 539/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2939 - acc: 0.8697 - val_loss: 0.3200 - val_acc: 0.8542\n",
      "Epoch 540/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2921 - acc: 0.8668 - val_loss: 0.3198 - val_acc: 0.8542\n",
      "Epoch 541/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2923 - acc: 0.8675 - val_loss: 0.3198 - val_acc: 0.8542\n",
      "Epoch 542/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2906 - acc: 0.8673 - val_loss: 0.3193 - val_acc: 0.8509\n",
      "Epoch 543/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2919 - acc: 0.8671 - val_loss: 0.3195 - val_acc: 0.8531\n",
      "Epoch 544/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2911 - acc: 0.8695 - val_loss: 0.3197 - val_acc: 0.8509\n",
      "Epoch 545/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2928 - acc: 0.8661 - val_loss: 0.3199 - val_acc: 0.8520\n",
      "Epoch 546/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2927 - acc: 0.8677 - val_loss: 0.3201 - val_acc: 0.8542\n",
      "Epoch 547/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2939 - acc: 0.8662 - val_loss: 0.3198 - val_acc: 0.8564\n",
      "Epoch 548/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2940 - acc: 0.8643 - val_loss: 0.3197 - val_acc: 0.8542\n",
      "Epoch 549/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2904 - acc: 0.8685 - val_loss: 0.3199 - val_acc: 0.8531\n",
      "Epoch 550/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2940 - acc: 0.8655 - val_loss: 0.3196 - val_acc: 0.8542\n",
      "Epoch 551/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2930 - acc: 0.8663 - val_loss: 0.3194 - val_acc: 0.8520\n",
      "Epoch 552/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2910 - acc: 0.8696 - val_loss: 0.3195 - val_acc: 0.8520\n",
      "Epoch 553/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2932 - acc: 0.8683 - val_loss: 0.3195 - val_acc: 0.8520\n",
      "Epoch 554/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2909 - acc: 0.8680 - val_loss: 0.3194 - val_acc: 0.8531\n",
      "Epoch 555/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2899 - acc: 0.8696 - val_loss: 0.3199 - val_acc: 0.8520\n",
      "Epoch 556/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2935 - acc: 0.8666 - val_loss: 0.3198 - val_acc: 0.8531\n",
      "Epoch 557/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2927 - acc: 0.8686 - val_loss: 0.3196 - val_acc: 0.8531\n",
      "Epoch 558/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2930 - acc: 0.8660 - val_loss: 0.3195 - val_acc: 0.8542\n",
      "Epoch 559/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2925 - acc: 0.8695 - val_loss: 0.3195 - val_acc: 0.8553\n",
      "Epoch 560/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2929 - acc: 0.8662 - val_loss: 0.3195 - val_acc: 0.8531\n",
      "Epoch 561/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2907 - acc: 0.8668 - val_loss: 0.3197 - val_acc: 0.8531\n",
      "Epoch 562/10000\n",
      "8199/8199 [==============================] - 0s 26us/sample - loss: 0.2913 - acc: 0.8696 - val_loss: 0.3198 - val_acc: 0.8520\n",
      "Epoch 563/10000\n",
      "8199/8199 [==============================] - 0s 27us/sample - loss: 0.2907 - acc: 0.8675 - val_loss: 0.3199 - val_acc: 0.8509\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)\n",
    "history = model.fit(x=X_train, y=y_train, batch_size=32, epochs=10000, verbose=1, validation_split=0.1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 0s 16us/sample - loss: 0.3186 - acc: 0.8509\n",
      "Test Score: 0.31859378000355426\n",
      "Test ACC: 0.8509378\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x=X_test, y=y_test, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test ACC:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cst_id_di</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90000000089</th>\n",
       "      <td>-0.06610</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>-0.13607</td>\n",
       "      <td>0.10945</td>\n",
       "      <td>0.06557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>-0.18965</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.24149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19113</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>0.09471</td>\n",
       "      <td>0.27091</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0.02938</td>\n",
       "      <td>0.17105</td>\n",
       "      <td>0.12537</td>\n",
       "      <td>0.22197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000176</th>\n",
       "      <td>-0.09537</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>-0.13541</td>\n",
       "      <td>0.17331</td>\n",
       "      <td>-0.19657</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>-0.23104</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>-0.39476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19437</td>\n",
       "      <td>0.06538</td>\n",
       "      <td>0.16309</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>-0.01107</td>\n",
       "      <td>0.12413</td>\n",
       "      <td>0.29702</td>\n",
       "      <td>-0.31717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000210</th>\n",
       "      <td>-0.01048</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.37797</td>\n",
       "      <td>-0.10970</td>\n",
       "      <td>0.52032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.32632</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.73494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.52084</td>\n",
       "      <td>-0.18568</td>\n",
       "      <td>-0.09755</td>\n",
       "      <td>-0.56565</td>\n",
       "      <td>-0.17840</td>\n",
       "      <td>-0.06314</td>\n",
       "      <td>-0.17111</td>\n",
       "      <td>-0.32239</td>\n",
       "      <td>0.33962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000212</th>\n",
       "      <td>0.05194</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.04611</td>\n",
       "      <td>-0.16512</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.26845</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.32617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01934</td>\n",
       "      <td>-0.05172</td>\n",
       "      <td>-0.13245</td>\n",
       "      <td>-0.16357</td>\n",
       "      <td>-0.05697</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>-0.04022</td>\n",
       "      <td>0.31213</td>\n",
       "      <td>-0.00559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000213</th>\n",
       "      <td>-0.08536</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>-0.12288</td>\n",
       "      <td>0.10023</td>\n",
       "      <td>-0.43414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>-0.25575</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>-0.52948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23122</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.09206</td>\n",
       "      <td>0.46971</td>\n",
       "      <td>0.07964</td>\n",
       "      <td>-0.04698</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.22588</td>\n",
       "      <td>-0.34868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460112</th>\n",
       "      <td>-0.06606</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>-0.09743</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.10111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>-0.02041</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.06993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33881</td>\n",
       "      <td>-0.01692</td>\n",
       "      <td>-0.01823</td>\n",
       "      <td>0.21720</td>\n",
       "      <td>-0.08346</td>\n",
       "      <td>-0.07835</td>\n",
       "      <td>0.02321</td>\n",
       "      <td>0.32967</td>\n",
       "      <td>-0.25995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460117</th>\n",
       "      <td>-0.03031</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.07041</td>\n",
       "      <td>-0.02519</td>\n",
       "      <td>0.58013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.06676</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.68992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19384</td>\n",
       "      <td>-0.02383</td>\n",
       "      <td>-0.02448</td>\n",
       "      <td>-0.05019</td>\n",
       "      <td>-0.02869</td>\n",
       "      <td>-0.05401</td>\n",
       "      <td>0.01670</td>\n",
       "      <td>-0.15880</td>\n",
       "      <td>0.48301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460233</th>\n",
       "      <td>-0.05351</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.36925</td>\n",
       "      <td>-0.10039</td>\n",
       "      <td>0.51159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.35016</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.68799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.45312</td>\n",
       "      <td>-0.17163</td>\n",
       "      <td>-0.08674</td>\n",
       "      <td>-0.40260</td>\n",
       "      <td>-0.15903</td>\n",
       "      <td>-0.10292</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.31895</td>\n",
       "      <td>0.40357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460310</th>\n",
       "      <td>-0.00562</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.04581</td>\n",
       "      <td>-0.05390</td>\n",
       "      <td>0.20481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.11319</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>0.42924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01754</td>\n",
       "      <td>-0.01479</td>\n",
       "      <td>-0.03898</td>\n",
       "      <td>-0.01363</td>\n",
       "      <td>0.06974</td>\n",
       "      <td>-0.03815</td>\n",
       "      <td>-0.04371</td>\n",
       "      <td>0.11433</td>\n",
       "      <td>-0.01931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460313</th>\n",
       "      <td>-0.06814</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>-0.04318</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>-0.08842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>-0.02036</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>0.13615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08257</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.08881</td>\n",
       "      <td>0.01272</td>\n",
       "      <td>-0.01391</td>\n",
       "      <td>-0.05940</td>\n",
       "      <td>0.44214</td>\n",
       "      <td>0.22888</td>\n",
       "      <td>-0.09918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10124 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008  \\\n",
       "cst_id_di                                                                 \n",
       "90000000089 -0.06610  0.5280 -0.13607  0.10945  0.06557       0  0.7702   \n",
       "90000000176 -0.09537  0.1347 -0.13541  0.17331 -0.19657       0  0.0616   \n",
       "90000000210 -0.01048  0.8360  0.37797 -0.10970  0.52032       1  0.3257   \n",
       "90000000212  0.05194  0.7505  0.04611 -0.16512  0.07413       0  0.5322   \n",
       "90000000213 -0.08536  0.3767 -0.12288  0.10023 -0.43414       0  0.5468   \n",
       "...              ...     ...      ...      ...      ...     ...     ...   \n",
       "90000460112 -0.06606  0.6615 -0.09743 -0.03240  0.10111       0  0.9722   \n",
       "90000460117 -0.03031  0.0143  0.07041 -0.02519  0.58013       0  0.0330   \n",
       "90000460233 -0.05351  0.3121  0.36925 -0.10039  0.51159       0  0.2582   \n",
       "90000460310 -0.00562  0.2286  0.04581 -0.05390  0.20481       0  0.5957   \n",
       "90000460313 -0.06814  0.6968 -0.04318  0.11340 -0.08842       0  0.1151   \n",
       "\n",
       "              VAR009  VAR010   VAR011  ...   VAR219   VAR220   VAR221  \\\n",
       "cst_id_di                              ...                              \n",
       "90000000089 -0.18965  0.1981  0.24149  ...  0.19113  0.05449  0.09471   \n",
       "90000000176 -0.23104  0.4940 -0.39476  ...  0.19437  0.06538  0.16309   \n",
       "90000000210  0.32632  0.7343  0.73494  ... -0.52084 -0.18568 -0.09755   \n",
       "90000000212  0.26845  0.7327  0.32617  ... -0.01934 -0.05172 -0.13245   \n",
       "90000000213 -0.25575  0.9644 -0.52948  ...  0.23122  0.07913  0.09206   \n",
       "...              ...     ...      ...  ...      ...      ...      ...   \n",
       "90000460112 -0.02041  0.6966  0.06993  ...  0.33881 -0.01692 -0.01823   \n",
       "90000460117  0.06676  0.8251  0.68992  ... -0.19384 -0.02383 -0.02448   \n",
       "90000460233  0.35016  0.4638  0.68799  ... -0.45312 -0.17163 -0.08674   \n",
       "90000460310  0.11319  0.2527  0.42924  ...  0.01754 -0.01479 -0.03898   \n",
       "90000460313 -0.02036  0.8465  0.13615  ...  0.08257  0.00120  0.08881   \n",
       "\n",
       "              VAR222   VAR223   VAR224   VAR225   VAR226   VAR227  MRC_ID_DI  \n",
       "cst_id_di                                                                     \n",
       "90000000089  0.27091  0.01931  0.02938  0.17105  0.12537  0.22197          0  \n",
       "90000000176  0.30207  0.06053 -0.01107  0.12413  0.29702 -0.31717          1  \n",
       "90000000210 -0.56565 -0.17840 -0.06314 -0.17111 -0.32239  0.33962          0  \n",
       "90000000212 -0.16357 -0.05697  0.01587 -0.04022  0.31213 -0.00559          1  \n",
       "90000000213  0.46971  0.07964 -0.04698  0.03581  0.22588 -0.34868          1  \n",
       "...              ...      ...      ...      ...      ...      ...        ...  \n",
       "90000460112  0.21720 -0.08346 -0.07835  0.02321  0.32967 -0.25995          1  \n",
       "90000460117 -0.05019 -0.02869 -0.05401  0.01670 -0.15880  0.48301          0  \n",
       "90000460233 -0.40260 -0.15903 -0.10292 -0.11742 -0.31895  0.40357          0  \n",
       "90000460310 -0.01363  0.06974 -0.03815 -0.04371  0.11433 -0.01931          0  \n",
       "90000460313  0.01272 -0.01391 -0.05940  0.44214  0.22888 -0.09918          0  \n",
       "\n",
       "[10124 rows x 227 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    8200\n",
      "1    1924\n",
      "Name: MRC_ID_DI, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['MRC_ID_DI'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cst_id_di</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90000000089</th>\n",
       "      <td>-0.06610</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>-0.13607</td>\n",
       "      <td>0.10945</td>\n",
       "      <td>0.06557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>-0.18965</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.24149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19113</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>0.09471</td>\n",
       "      <td>0.27091</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0.02938</td>\n",
       "      <td>0.17105</td>\n",
       "      <td>0.12537</td>\n",
       "      <td>0.22197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000210</th>\n",
       "      <td>-0.01048</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.37797</td>\n",
       "      <td>-0.10970</td>\n",
       "      <td>0.52032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.32632</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.73494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.52084</td>\n",
       "      <td>-0.18568</td>\n",
       "      <td>-0.09755</td>\n",
       "      <td>-0.56565</td>\n",
       "      <td>-0.17840</td>\n",
       "      <td>-0.06314</td>\n",
       "      <td>-0.17111</td>\n",
       "      <td>-0.32239</td>\n",
       "      <td>0.33962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000263</th>\n",
       "      <td>-0.10778</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>-0.12917</td>\n",
       "      <td>0.06835</td>\n",
       "      <td>-0.40939</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>-0.13009</td>\n",
       "      <td>0.7291</td>\n",
       "      <td>-0.39929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27452</td>\n",
       "      <td>0.04098</td>\n",
       "      <td>0.06074</td>\n",
       "      <td>0.49646</td>\n",
       "      <td>-0.02204</td>\n",
       "      <td>-0.06996</td>\n",
       "      <td>0.01552</td>\n",
       "      <td>0.20518</td>\n",
       "      <td>-0.09952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000322</th>\n",
       "      <td>0.02596</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.09658</td>\n",
       "      <td>-0.21836</td>\n",
       "      <td>0.47897</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>0.39811</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.45440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.44143</td>\n",
       "      <td>-0.15050</td>\n",
       "      <td>-0.19061</td>\n",
       "      <td>-0.52859</td>\n",
       "      <td>-0.19092</td>\n",
       "      <td>-0.03939</td>\n",
       "      <td>-0.11918</td>\n",
       "      <td>-0.29188</td>\n",
       "      <td>0.21474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000354</th>\n",
       "      <td>0.03735</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>-0.07106</td>\n",
       "      <td>0.05682</td>\n",
       "      <td>0.51936</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>-0.11848</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>0.20183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12450</td>\n",
       "      <td>0.09082</td>\n",
       "      <td>0.03790</td>\n",
       "      <td>-0.01301</td>\n",
       "      <td>0.11605</td>\n",
       "      <td>0.41329</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>-0.13191</td>\n",
       "      <td>0.10532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000459958</th>\n",
       "      <td>-0.00925</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>0.25466</td>\n",
       "      <td>-0.19329</td>\n",
       "      <td>0.43215</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>0.44652</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>0.68210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42943</td>\n",
       "      <td>-0.13345</td>\n",
       "      <td>-0.16509</td>\n",
       "      <td>-0.57853</td>\n",
       "      <td>-0.16135</td>\n",
       "      <td>-0.09230</td>\n",
       "      <td>-0.05164</td>\n",
       "      <td>-0.14484</td>\n",
       "      <td>0.26366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460117</th>\n",
       "      <td>-0.03031</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.07041</td>\n",
       "      <td>-0.02519</td>\n",
       "      <td>0.58013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.06676</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.68992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19384</td>\n",
       "      <td>-0.02383</td>\n",
       "      <td>-0.02448</td>\n",
       "      <td>-0.05019</td>\n",
       "      <td>-0.02869</td>\n",
       "      <td>-0.05401</td>\n",
       "      <td>0.01670</td>\n",
       "      <td>-0.15880</td>\n",
       "      <td>0.48301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460233</th>\n",
       "      <td>-0.05351</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.36925</td>\n",
       "      <td>-0.10039</td>\n",
       "      <td>0.51159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.35016</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.68799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.45312</td>\n",
       "      <td>-0.17163</td>\n",
       "      <td>-0.08674</td>\n",
       "      <td>-0.40260</td>\n",
       "      <td>-0.15903</td>\n",
       "      <td>-0.10292</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.31895</td>\n",
       "      <td>0.40357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460310</th>\n",
       "      <td>-0.00562</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.04581</td>\n",
       "      <td>-0.05390</td>\n",
       "      <td>0.20481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.11319</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>0.42924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01754</td>\n",
       "      <td>-0.01479</td>\n",
       "      <td>-0.03898</td>\n",
       "      <td>-0.01363</td>\n",
       "      <td>0.06974</td>\n",
       "      <td>-0.03815</td>\n",
       "      <td>-0.04371</td>\n",
       "      <td>0.11433</td>\n",
       "      <td>-0.01931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460313</th>\n",
       "      <td>-0.06814</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>-0.04318</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>-0.08842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>-0.02036</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>0.13615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08257</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.08881</td>\n",
       "      <td>0.01272</td>\n",
       "      <td>-0.01391</td>\n",
       "      <td>-0.05940</td>\n",
       "      <td>0.44214</td>\n",
       "      <td>0.22888</td>\n",
       "      <td>-0.09918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8200 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008  \\\n",
       "cst_id_di                                                                 \n",
       "90000000089 -0.06610  0.5280 -0.13607  0.10945  0.06557       0  0.7702   \n",
       "90000000210 -0.01048  0.8360  0.37797 -0.10970  0.52032       1  0.3257   \n",
       "90000000263 -0.10778  0.0810 -0.12917  0.06835 -0.40939       0  0.7128   \n",
       "90000000322  0.02596  0.2279  0.09658 -0.21836  0.47897       0  0.1961   \n",
       "90000000354  0.03735  0.3486 -0.07106  0.05682  0.51936       1  0.6283   \n",
       "...              ...     ...      ...      ...      ...     ...     ...   \n",
       "90000459958 -0.00925  0.7706  0.25466 -0.19329  0.43215       1  0.6892   \n",
       "90000460117 -0.03031  0.0143  0.07041 -0.02519  0.58013       0  0.0330   \n",
       "90000460233 -0.05351  0.3121  0.36925 -0.10039  0.51159       0  0.2582   \n",
       "90000460310 -0.00562  0.2286  0.04581 -0.05390  0.20481       0  0.5957   \n",
       "90000460313 -0.06814  0.6968 -0.04318  0.11340 -0.08842       0  0.1151   \n",
       "\n",
       "              VAR009  VAR010   VAR011  ...   VAR219   VAR220   VAR221  \\\n",
       "cst_id_di                              ...                              \n",
       "90000000089 -0.18965  0.1981  0.24149  ...  0.19113  0.05449  0.09471   \n",
       "90000000210  0.32632  0.7343  0.73494  ... -0.52084 -0.18568 -0.09755   \n",
       "90000000263 -0.13009  0.7291 -0.39929  ...  0.27452  0.04098  0.06074   \n",
       "90000000322  0.39811  0.2458  0.45440  ... -0.44143 -0.15050 -0.19061   \n",
       "90000000354 -0.11848  0.2781  0.20183  ...  0.12450  0.09082  0.03790   \n",
       "...              ...     ...      ...  ...      ...      ...      ...   \n",
       "90000459958  0.44652  0.3488  0.68210  ... -0.42943 -0.13345 -0.16509   \n",
       "90000460117  0.06676  0.8251  0.68992  ... -0.19384 -0.02383 -0.02448   \n",
       "90000460233  0.35016  0.4638  0.68799  ... -0.45312 -0.17163 -0.08674   \n",
       "90000460310  0.11319  0.2527  0.42924  ...  0.01754 -0.01479 -0.03898   \n",
       "90000460313 -0.02036  0.8465  0.13615  ...  0.08257  0.00120  0.08881   \n",
       "\n",
       "              VAR222   VAR223   VAR224   VAR225   VAR226   VAR227  MRC_ID_DI  \n",
       "cst_id_di                                                                     \n",
       "90000000089  0.27091  0.01931  0.02938  0.17105  0.12537  0.22197          0  \n",
       "90000000210 -0.56565 -0.17840 -0.06314 -0.17111 -0.32239  0.33962          0  \n",
       "90000000263  0.49646 -0.02204 -0.06996  0.01552  0.20518 -0.09952          0  \n",
       "90000000322 -0.52859 -0.19092 -0.03939 -0.11918 -0.29188  0.21474          0  \n",
       "90000000354 -0.01301  0.11605  0.41329  0.01658 -0.13191  0.10532          0  \n",
       "...              ...      ...      ...      ...      ...      ...        ...  \n",
       "90000459958 -0.57853 -0.16135 -0.09230 -0.05164 -0.14484  0.26366          0  \n",
       "90000460117 -0.05019 -0.02869 -0.05401  0.01670 -0.15880  0.48301          0  \n",
       "90000460233 -0.40260 -0.15903 -0.10292 -0.11742 -0.31895  0.40357          0  \n",
       "90000460310 -0.01363  0.06974 -0.03815 -0.04371  0.11433 -0.01931          0  \n",
       "90000460313  0.01272 -0.01391 -0.05940  0.44214  0.22888 -0.09918          0  \n",
       "\n",
       "[8200 rows x 227 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0=df[df['MRC_ID_DI']==0]\n",
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cst_id_di</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90000000176</th>\n",
       "      <td>-0.09537</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>-0.13541</td>\n",
       "      <td>0.17331</td>\n",
       "      <td>-0.19657</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>-0.23104</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>-0.39476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19437</td>\n",
       "      <td>0.06538</td>\n",
       "      <td>0.16309</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>-0.01107</td>\n",
       "      <td>0.12413</td>\n",
       "      <td>0.29702</td>\n",
       "      <td>-0.31717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000212</th>\n",
       "      <td>0.05194</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.04611</td>\n",
       "      <td>-0.16512</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.26845</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.32617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01934</td>\n",
       "      <td>-0.05172</td>\n",
       "      <td>-0.13245</td>\n",
       "      <td>-0.16357</td>\n",
       "      <td>-0.05697</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>-0.04022</td>\n",
       "      <td>0.31213</td>\n",
       "      <td>-0.00559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000213</th>\n",
       "      <td>-0.08536</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>-0.12288</td>\n",
       "      <td>0.10023</td>\n",
       "      <td>-0.43414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>-0.25575</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>-0.52948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23122</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.09206</td>\n",
       "      <td>0.46971</td>\n",
       "      <td>0.07964</td>\n",
       "      <td>-0.04698</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.22588</td>\n",
       "      <td>-0.34868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000506</th>\n",
       "      <td>-0.02536</td>\n",
       "      <td>0.3364</td>\n",
       "      <td>-0.17063</td>\n",
       "      <td>0.10209</td>\n",
       "      <td>0.12635</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>-0.16467</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.19010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24960</td>\n",
       "      <td>0.07146</td>\n",
       "      <td>0.10167</td>\n",
       "      <td>0.33884</td>\n",
       "      <td>0.06834</td>\n",
       "      <td>0.07124</td>\n",
       "      <td>0.03493</td>\n",
       "      <td>0.36701</td>\n",
       "      <td>-0.03924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000648</th>\n",
       "      <td>-0.02030</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.26428</td>\n",
       "      <td>-0.07925</td>\n",
       "      <td>0.02531</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>0.24348</td>\n",
       "      <td>0.7742</td>\n",
       "      <td>0.19419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16400</td>\n",
       "      <td>-0.10595</td>\n",
       "      <td>-0.06875</td>\n",
       "      <td>-0.11385</td>\n",
       "      <td>-0.11020</td>\n",
       "      <td>-0.05687</td>\n",
       "      <td>-0.10309</td>\n",
       "      <td>0.07512</td>\n",
       "      <td>-0.17489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000459007</th>\n",
       "      <td>-0.01883</td>\n",
       "      <td>0.3512</td>\n",
       "      <td>-0.10303</td>\n",
       "      <td>-0.04250</td>\n",
       "      <td>0.15866</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>-0.05495</td>\n",
       "      <td>0.8638</td>\n",
       "      <td>0.30206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13235</td>\n",
       "      <td>0.00600</td>\n",
       "      <td>-0.02330</td>\n",
       "      <td>0.27080</td>\n",
       "      <td>-0.04149</td>\n",
       "      <td>-0.04106</td>\n",
       "      <td>0.02244</td>\n",
       "      <td>0.21820</td>\n",
       "      <td>0.20226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000459530</th>\n",
       "      <td>-0.06234</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>-0.13051</td>\n",
       "      <td>0.12851</td>\n",
       "      <td>-0.16615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>-0.29344</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>-0.37332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39212</td>\n",
       "      <td>0.14349</td>\n",
       "      <td>0.10692</td>\n",
       "      <td>0.40572</td>\n",
       "      <td>0.25386</td>\n",
       "      <td>-0.00157</td>\n",
       "      <td>0.16095</td>\n",
       "      <td>0.14094</td>\n",
       "      <td>-0.32806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000459697</th>\n",
       "      <td>-0.06025</td>\n",
       "      <td>0.4614</td>\n",
       "      <td>-0.04993</td>\n",
       "      <td>0.11152</td>\n",
       "      <td>0.09355</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5997</td>\n",
       "      <td>-0.04970</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.27737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17515</td>\n",
       "      <td>0.01051</td>\n",
       "      <td>0.11757</td>\n",
       "      <td>0.01791</td>\n",
       "      <td>0.03313</td>\n",
       "      <td>-0.02205</td>\n",
       "      <td>-0.01690</td>\n",
       "      <td>0.04556</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000459949</th>\n",
       "      <td>-0.04418</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>-0.06455</td>\n",
       "      <td>-0.03327</td>\n",
       "      <td>0.10294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4098</td>\n",
       "      <td>-0.05159</td>\n",
       "      <td>0.3559</td>\n",
       "      <td>0.01855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23804</td>\n",
       "      <td>-0.00045</td>\n",
       "      <td>-0.02709</td>\n",
       "      <td>0.26656</td>\n",
       "      <td>-0.01436</td>\n",
       "      <td>-0.03660</td>\n",
       "      <td>0.03311</td>\n",
       "      <td>0.19563</td>\n",
       "      <td>-0.11591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460112</th>\n",
       "      <td>-0.06606</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>-0.09743</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.10111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>-0.02041</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.06993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33881</td>\n",
       "      <td>-0.01692</td>\n",
       "      <td>-0.01823</td>\n",
       "      <td>0.21720</td>\n",
       "      <td>-0.08346</td>\n",
       "      <td>-0.07835</td>\n",
       "      <td>0.02321</td>\n",
       "      <td>0.32967</td>\n",
       "      <td>-0.25995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1924 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008  \\\n",
       "cst_id_di                                                                 \n",
       "90000000176 -0.09537  0.1347 -0.13541  0.17331 -0.19657       0  0.0616   \n",
       "90000000212  0.05194  0.7505  0.04611 -0.16512  0.07413       0  0.5322   \n",
       "90000000213 -0.08536  0.3767 -0.12288  0.10023 -0.43414       0  0.5468   \n",
       "90000000506 -0.02536  0.3364 -0.17063  0.10209  0.12635       0  0.2136   \n",
       "90000000648 -0.02030  0.7619  0.26428 -0.07925  0.02531       0  0.8683   \n",
       "...              ...     ...      ...      ...      ...     ...     ...   \n",
       "90000459007 -0.01883  0.3512 -0.10303 -0.04250  0.15866       0  0.1080   \n",
       "90000459530 -0.06234  0.1051 -0.13051  0.12851 -0.16615       0  0.2067   \n",
       "90000459697 -0.06025  0.4614 -0.04993  0.11152  0.09355       0  0.5997   \n",
       "90000459949 -0.04418  0.0679 -0.06455 -0.03327  0.10294       0  0.4098   \n",
       "90000460112 -0.06606  0.6615 -0.09743 -0.03240  0.10111       0  0.9722   \n",
       "\n",
       "              VAR009  VAR010   VAR011  ...   VAR219   VAR220   VAR221  \\\n",
       "cst_id_di                              ...                              \n",
       "90000000176 -0.23104  0.4940 -0.39476  ...  0.19437  0.06538  0.16309   \n",
       "90000000212  0.26845  0.7327  0.32617  ... -0.01934 -0.05172 -0.13245   \n",
       "90000000213 -0.25575  0.9644 -0.52948  ...  0.23122  0.07913  0.09206   \n",
       "90000000506 -0.16467  0.8193  0.19010  ...  0.24960  0.07146  0.10167   \n",
       "90000000648  0.24348  0.7742  0.19419  ... -0.16400 -0.10595 -0.06875   \n",
       "...              ...     ...      ...  ...      ...      ...      ...   \n",
       "90000459007 -0.05495  0.8638  0.30206  ...  0.13235  0.00600 -0.02330   \n",
       "90000459530 -0.29344  0.0498 -0.37332  ...  0.39212  0.14349  0.10692   \n",
       "90000459697 -0.04970  0.6416  0.27737  ...  0.17515  0.01051  0.11757   \n",
       "90000459949 -0.05159  0.3559  0.01855  ...  0.23804 -0.00045 -0.02709   \n",
       "90000460112 -0.02041  0.6966  0.06993  ...  0.33881 -0.01692 -0.01823   \n",
       "\n",
       "              VAR222   VAR223   VAR224   VAR225   VAR226   VAR227  MRC_ID_DI  \n",
       "cst_id_di                                                                     \n",
       "90000000176  0.30207  0.06053 -0.01107  0.12413  0.29702 -0.31717          1  \n",
       "90000000212 -0.16357 -0.05697  0.01587 -0.04022  0.31213 -0.00559          1  \n",
       "90000000213  0.46971  0.07964 -0.04698  0.03581  0.22588 -0.34868          1  \n",
       "90000000506  0.33884  0.06834  0.07124  0.03493  0.36701 -0.03924          1  \n",
       "90000000648 -0.11385 -0.11020 -0.05687 -0.10309  0.07512 -0.17489          1  \n",
       "...              ...      ...      ...      ...      ...      ...        ...  \n",
       "90000459007  0.27080 -0.04149 -0.04106  0.02244  0.21820  0.20226          1  \n",
       "90000459530  0.40572  0.25386 -0.00157  0.16095  0.14094 -0.32806          1  \n",
       "90000459697  0.01791  0.03313 -0.02205 -0.01690  0.04556  0.06141          1  \n",
       "90000459949  0.26656 -0.01436 -0.03660  0.03311  0.19563 -0.11591          1  \n",
       "90000460112  0.21720 -0.08346 -0.07835  0.02321  0.32967 -0.25995          1  \n",
       "\n",
       "[1924 rows x 227 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1=df[df['MRC_ID_DI']==1]\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cst_id_di</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90000000176</th>\n",
       "      <td>-0.09537</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>-0.13541</td>\n",
       "      <td>0.17331</td>\n",
       "      <td>-0.19657</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>-0.23104</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>-0.39476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19437</td>\n",
       "      <td>0.06538</td>\n",
       "      <td>0.16309</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>-0.01107</td>\n",
       "      <td>0.12413</td>\n",
       "      <td>0.29702</td>\n",
       "      <td>-0.31717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000212</th>\n",
       "      <td>0.05194</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.04611</td>\n",
       "      <td>-0.16512</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.26845</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.32617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01934</td>\n",
       "      <td>-0.05172</td>\n",
       "      <td>-0.13245</td>\n",
       "      <td>-0.16357</td>\n",
       "      <td>-0.05697</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>-0.04022</td>\n",
       "      <td>0.31213</td>\n",
       "      <td>-0.00559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000213</th>\n",
       "      <td>-0.08536</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>-0.12288</td>\n",
       "      <td>0.10023</td>\n",
       "      <td>-0.43414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>-0.25575</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>-0.52948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23122</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.09206</td>\n",
       "      <td>0.46971</td>\n",
       "      <td>0.07964</td>\n",
       "      <td>-0.04698</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.22588</td>\n",
       "      <td>-0.34868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000506</th>\n",
       "      <td>-0.02536</td>\n",
       "      <td>0.3364</td>\n",
       "      <td>-0.17063</td>\n",
       "      <td>0.10209</td>\n",
       "      <td>0.12635</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>-0.16467</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.19010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24960</td>\n",
       "      <td>0.07146</td>\n",
       "      <td>0.10167</td>\n",
       "      <td>0.33884</td>\n",
       "      <td>0.06834</td>\n",
       "      <td>0.07124</td>\n",
       "      <td>0.03493</td>\n",
       "      <td>0.36701</td>\n",
       "      <td>-0.03924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000000648</th>\n",
       "      <td>-0.02030</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.26428</td>\n",
       "      <td>-0.07925</td>\n",
       "      <td>0.02531</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>0.24348</td>\n",
       "      <td>0.7742</td>\n",
       "      <td>0.19419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16400</td>\n",
       "      <td>-0.10595</td>\n",
       "      <td>-0.06875</td>\n",
       "      <td>-0.11385</td>\n",
       "      <td>-0.11020</td>\n",
       "      <td>-0.05687</td>\n",
       "      <td>-0.10309</td>\n",
       "      <td>0.07512</td>\n",
       "      <td>-0.17489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000459007</th>\n",
       "      <td>-0.01883</td>\n",
       "      <td>0.3512</td>\n",
       "      <td>-0.10303</td>\n",
       "      <td>-0.04250</td>\n",
       "      <td>0.15866</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>-0.05495</td>\n",
       "      <td>0.8638</td>\n",
       "      <td>0.30206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13235</td>\n",
       "      <td>0.00600</td>\n",
       "      <td>-0.02330</td>\n",
       "      <td>0.27080</td>\n",
       "      <td>-0.04149</td>\n",
       "      <td>-0.04106</td>\n",
       "      <td>0.02244</td>\n",
       "      <td>0.21820</td>\n",
       "      <td>0.20226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000459530</th>\n",
       "      <td>-0.06234</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>-0.13051</td>\n",
       "      <td>0.12851</td>\n",
       "      <td>-0.16615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>-0.29344</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>-0.37332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39212</td>\n",
       "      <td>0.14349</td>\n",
       "      <td>0.10692</td>\n",
       "      <td>0.40572</td>\n",
       "      <td>0.25386</td>\n",
       "      <td>-0.00157</td>\n",
       "      <td>0.16095</td>\n",
       "      <td>0.14094</td>\n",
       "      <td>-0.32806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000459697</th>\n",
       "      <td>-0.06025</td>\n",
       "      <td>0.4614</td>\n",
       "      <td>-0.04993</td>\n",
       "      <td>0.11152</td>\n",
       "      <td>0.09355</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5997</td>\n",
       "      <td>-0.04970</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.27737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17515</td>\n",
       "      <td>0.01051</td>\n",
       "      <td>0.11757</td>\n",
       "      <td>0.01791</td>\n",
       "      <td>0.03313</td>\n",
       "      <td>-0.02205</td>\n",
       "      <td>-0.01690</td>\n",
       "      <td>0.04556</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000459949</th>\n",
       "      <td>-0.04418</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>-0.06455</td>\n",
       "      <td>-0.03327</td>\n",
       "      <td>0.10294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4098</td>\n",
       "      <td>-0.05159</td>\n",
       "      <td>0.3559</td>\n",
       "      <td>0.01855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23804</td>\n",
       "      <td>-0.00045</td>\n",
       "      <td>-0.02709</td>\n",
       "      <td>0.26656</td>\n",
       "      <td>-0.01436</td>\n",
       "      <td>-0.03660</td>\n",
       "      <td>0.03311</td>\n",
       "      <td>0.19563</td>\n",
       "      <td>-0.11591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000460112</th>\n",
       "      <td>-0.06606</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>-0.09743</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.10111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>-0.02041</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.06993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33881</td>\n",
       "      <td>-0.01692</td>\n",
       "      <td>-0.01823</td>\n",
       "      <td>0.21720</td>\n",
       "      <td>-0.08346</td>\n",
       "      <td>-0.07835</td>\n",
       "      <td>0.02321</td>\n",
       "      <td>0.32967</td>\n",
       "      <td>-0.25995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9620 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008  \\\n",
       "cst_id_di                                                                 \n",
       "90000000176 -0.09537  0.1347 -0.13541  0.17331 -0.19657       0  0.0616   \n",
       "90000000212  0.05194  0.7505  0.04611 -0.16512  0.07413       0  0.5322   \n",
       "90000000213 -0.08536  0.3767 -0.12288  0.10023 -0.43414       0  0.5468   \n",
       "90000000506 -0.02536  0.3364 -0.17063  0.10209  0.12635       0  0.2136   \n",
       "90000000648 -0.02030  0.7619  0.26428 -0.07925  0.02531       0  0.8683   \n",
       "...              ...     ...      ...      ...      ...     ...     ...   \n",
       "90000459007 -0.01883  0.3512 -0.10303 -0.04250  0.15866       0  0.1080   \n",
       "90000459530 -0.06234  0.1051 -0.13051  0.12851 -0.16615       0  0.2067   \n",
       "90000459697 -0.06025  0.4614 -0.04993  0.11152  0.09355       0  0.5997   \n",
       "90000459949 -0.04418  0.0679 -0.06455 -0.03327  0.10294       0  0.4098   \n",
       "90000460112 -0.06606  0.6615 -0.09743 -0.03240  0.10111       0  0.9722   \n",
       "\n",
       "              VAR009  VAR010   VAR011  ...   VAR219   VAR220   VAR221  \\\n",
       "cst_id_di                              ...                              \n",
       "90000000176 -0.23104  0.4940 -0.39476  ...  0.19437  0.06538  0.16309   \n",
       "90000000212  0.26845  0.7327  0.32617  ... -0.01934 -0.05172 -0.13245   \n",
       "90000000213 -0.25575  0.9644 -0.52948  ...  0.23122  0.07913  0.09206   \n",
       "90000000506 -0.16467  0.8193  0.19010  ...  0.24960  0.07146  0.10167   \n",
       "90000000648  0.24348  0.7742  0.19419  ... -0.16400 -0.10595 -0.06875   \n",
       "...              ...     ...      ...  ...      ...      ...      ...   \n",
       "90000459007 -0.05495  0.8638  0.30206  ...  0.13235  0.00600 -0.02330   \n",
       "90000459530 -0.29344  0.0498 -0.37332  ...  0.39212  0.14349  0.10692   \n",
       "90000459697 -0.04970  0.6416  0.27737  ...  0.17515  0.01051  0.11757   \n",
       "90000459949 -0.05159  0.3559  0.01855  ...  0.23804 -0.00045 -0.02709   \n",
       "90000460112 -0.02041  0.6966  0.06993  ...  0.33881 -0.01692 -0.01823   \n",
       "\n",
       "              VAR222   VAR223   VAR224   VAR225   VAR226   VAR227  MRC_ID_DI  \n",
       "cst_id_di                                                                     \n",
       "90000000176  0.30207  0.06053 -0.01107  0.12413  0.29702 -0.31717          1  \n",
       "90000000212 -0.16357 -0.05697  0.01587 -0.04022  0.31213 -0.00559          1  \n",
       "90000000213  0.46971  0.07964 -0.04698  0.03581  0.22588 -0.34868          1  \n",
       "90000000506  0.33884  0.06834  0.07124  0.03493  0.36701 -0.03924          1  \n",
       "90000000648 -0.11385 -0.11020 -0.05687 -0.10309  0.07512 -0.17489          1  \n",
       "...              ...      ...      ...      ...      ...      ...        ...  \n",
       "90000459007  0.27080 -0.04149 -0.04106  0.02244  0.21820  0.20226          1  \n",
       "90000459530  0.40572  0.25386 -0.00157  0.16095  0.14094 -0.32806          1  \n",
       "90000459697  0.01791  0.03313 -0.02205 -0.01690  0.04556  0.06141          1  \n",
       "90000459949  0.26656 -0.01436 -0.03660  0.03311  0.19563 -0.11591          1  \n",
       "90000460112  0.21720 -0.08346 -0.07835  0.02321  0.32967 -0.25995          1  \n",
       "\n",
       "[9620 rows x 227 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_11 =pd.concat([df_1,df_1,df_1,df_1,df_1])\n",
    "df_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cst_id_di</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90000138543</th>\n",
       "      <td>-0.05707</td>\n",
       "      <td>0.7809</td>\n",
       "      <td>-0.09640</td>\n",
       "      <td>0.05528</td>\n",
       "      <td>0.29243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>-0.11143</td>\n",
       "      <td>0.7847</td>\n",
       "      <td>0.34544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07247</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.26140</td>\n",
       "      <td>0.01412</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>-0.00446</td>\n",
       "      <td>0.08452</td>\n",
       "      <td>0.18305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000058691</th>\n",
       "      <td>0.00438</td>\n",
       "      <td>0.3794</td>\n",
       "      <td>-0.08417</td>\n",
       "      <td>-0.10951</td>\n",
       "      <td>0.12776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.04914</td>\n",
       "      <td>0.5354</td>\n",
       "      <td>0.26070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17580</td>\n",
       "      <td>-0.01488</td>\n",
       "      <td>-0.09483</td>\n",
       "      <td>0.01161</td>\n",
       "      <td>-0.04020</td>\n",
       "      <td>-0.02060</td>\n",
       "      <td>0.02884</td>\n",
       "      <td>0.33536</td>\n",
       "      <td>-0.02879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000228018</th>\n",
       "      <td>-0.04362</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>-0.11864</td>\n",
       "      <td>-0.00827</td>\n",
       "      <td>-0.05949</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>-0.04902</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.08414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19105</td>\n",
       "      <td>0.02031</td>\n",
       "      <td>-0.01443</td>\n",
       "      <td>0.23493</td>\n",
       "      <td>-0.01941</td>\n",
       "      <td>-0.02903</td>\n",
       "      <td>0.05296</td>\n",
       "      <td>0.12320</td>\n",
       "      <td>-0.17762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000195962</th>\n",
       "      <td>-0.12213</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>-0.25815</td>\n",
       "      <td>0.12334</td>\n",
       "      <td>-0.32039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>-0.29627</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>-0.37510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42732</td>\n",
       "      <td>0.09565</td>\n",
       "      <td>0.10743</td>\n",
       "      <td>0.51942</td>\n",
       "      <td>0.01226</td>\n",
       "      <td>-0.07426</td>\n",
       "      <td>0.08066</td>\n",
       "      <td>0.35450</td>\n",
       "      <td>-0.28390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000363034</th>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>-0.07645</td>\n",
       "      <td>0.16927</td>\n",
       "      <td>0.08840</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>-0.16675</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.05660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22693</td>\n",
       "      <td>0.04848</td>\n",
       "      <td>0.13515</td>\n",
       "      <td>0.35230</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>-0.00834</td>\n",
       "      <td>-0.01082</td>\n",
       "      <td>-0.07433</td>\n",
       "      <td>0.02008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000104308</th>\n",
       "      <td>0.04954</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>-0.09717</td>\n",
       "      <td>0.13902</td>\n",
       "      <td>-0.05856</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1863</td>\n",
       "      <td>-0.27069</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>-0.43402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35694</td>\n",
       "      <td>0.11572</td>\n",
       "      <td>0.12421</td>\n",
       "      <td>0.52959</td>\n",
       "      <td>0.12216</td>\n",
       "      <td>0.13512</td>\n",
       "      <td>0.03952</td>\n",
       "      <td>0.25200</td>\n",
       "      <td>-0.29966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000337650</th>\n",
       "      <td>-0.03988</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.01790</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>-0.00977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>-0.13541</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.05965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19639</td>\n",
       "      <td>0.06247</td>\n",
       "      <td>0.00795</td>\n",
       "      <td>0.16291</td>\n",
       "      <td>0.08199</td>\n",
       "      <td>-0.00331</td>\n",
       "      <td>0.07528</td>\n",
       "      <td>0.05504</td>\n",
       "      <td>-0.09038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000175456</th>\n",
       "      <td>0.03394</td>\n",
       "      <td>0.3114</td>\n",
       "      <td>-0.19321</td>\n",
       "      <td>0.08249</td>\n",
       "      <td>-0.20538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>-0.14570</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-0.22156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33759</td>\n",
       "      <td>0.04529</td>\n",
       "      <td>0.05248</td>\n",
       "      <td>0.53876</td>\n",
       "      <td>0.00255</td>\n",
       "      <td>0.08623</td>\n",
       "      <td>0.13505</td>\n",
       "      <td>0.29015</td>\n",
       "      <td>-0.09754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000446335</th>\n",
       "      <td>-0.03258</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>-0.10352</td>\n",
       "      <td>0.06348</td>\n",
       "      <td>-0.06814</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3371</td>\n",
       "      <td>-0.13971</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>-0.04281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22597</td>\n",
       "      <td>0.07904</td>\n",
       "      <td>0.06329</td>\n",
       "      <td>0.22195</td>\n",
       "      <td>0.04186</td>\n",
       "      <td>0.01555</td>\n",
       "      <td>0.05280</td>\n",
       "      <td>0.10649</td>\n",
       "      <td>-0.01839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000201646</th>\n",
       "      <td>-0.07840</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.15209</td>\n",
       "      <td>0.09510</td>\n",
       "      <td>-0.10355</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>-0.19101</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.05482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25602</td>\n",
       "      <td>0.01754</td>\n",
       "      <td>0.06568</td>\n",
       "      <td>0.50519</td>\n",
       "      <td>-0.02274</td>\n",
       "      <td>-0.05164</td>\n",
       "      <td>0.02385</td>\n",
       "      <td>0.15533</td>\n",
       "      <td>-0.05593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8200 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008  \\\n",
       "cst_id_di                                                                 \n",
       "90000138543 -0.05707  0.7809 -0.09640  0.05528  0.29243       0  0.0242   \n",
       "90000058691  0.00438  0.3794 -0.08417 -0.10951  0.12776       1  0.6962   \n",
       "90000228018 -0.04362  0.0105 -0.11864 -0.00827 -0.05949       0  0.7420   \n",
       "90000195962 -0.12213  0.0274 -0.25815  0.12334 -0.32039       0  0.6847   \n",
       "90000363034 -0.03646  0.3398 -0.07645  0.16927  0.08840       0  0.1690   \n",
       "...              ...     ...      ...      ...      ...     ...     ...   \n",
       "90000104308  0.04954  0.1347 -0.09717  0.13902 -0.05856       0  0.1863   \n",
       "90000337650 -0.03988  0.1477  0.01790  0.01505 -0.00977       0  0.2395   \n",
       "90000175456  0.03394  0.3114 -0.19321  0.08249 -0.20538       0  0.0535   \n",
       "90000446335 -0.03258  0.4102 -0.10352  0.06348 -0.06814       0  0.3371   \n",
       "90000201646 -0.07840  0.0019 -0.15209  0.09510 -0.10355       0  0.5652   \n",
       "\n",
       "              VAR009  VAR010   VAR011  ...   VAR219   VAR220   VAR221  \\\n",
       "cst_id_di                              ...                              \n",
       "90000138543 -0.11143  0.7847  0.34544  ...  0.07247  0.00200  0.09968   \n",
       "90000058691  0.04914  0.5354  0.26070  ...  0.17580 -0.01488 -0.09483   \n",
       "90000228018 -0.04902  0.4499  0.08414  ...  0.19105  0.02031 -0.01443   \n",
       "90000195962 -0.29627  0.0228 -0.37510  ...  0.42732  0.09565  0.10743   \n",
       "90000363034 -0.16675  0.3168  0.05660  ...  0.22693  0.04848  0.13515   \n",
       "...              ...     ...      ...  ...      ...      ...      ...   \n",
       "90000104308 -0.27069  0.8395 -0.43402  ...  0.35694  0.11572  0.12421   \n",
       "90000337650 -0.13541  0.7972  0.05965  ...  0.19639  0.06247  0.00795   \n",
       "90000175456 -0.14570  0.9375 -0.22156  ...  0.33759  0.04529  0.05248   \n",
       "90000446335 -0.13971  0.7739 -0.04281  ...  0.22597  0.07904  0.06329   \n",
       "90000201646 -0.19101  0.5435  0.05482  ...  0.25602  0.01754  0.06568   \n",
       "\n",
       "              VAR222   VAR223   VAR224   VAR225   VAR226   VAR227  MRC_ID_DI  \n",
       "cst_id_di                                                                     \n",
       "90000138543  0.26140  0.01412 -0.04200 -0.00446  0.08452  0.18305          1  \n",
       "90000058691  0.01161 -0.04020 -0.02060  0.02884  0.33536 -0.02879          1  \n",
       "90000228018  0.23493 -0.01941 -0.02903  0.05296  0.12320 -0.17762          1  \n",
       "90000195962  0.51942  0.01226 -0.07426  0.08066  0.35450 -0.28390          1  \n",
       "90000363034  0.35230  0.03987 -0.00834 -0.01082 -0.07433  0.02008          1  \n",
       "...              ...      ...      ...      ...      ...      ...        ...  \n",
       "90000104308  0.52959  0.12216  0.13512  0.03952  0.25200 -0.29966          1  \n",
       "90000337650  0.16291  0.08199 -0.00331  0.07528  0.05504 -0.09038          1  \n",
       "90000175456  0.53876  0.00255  0.08623  0.13505  0.29015 -0.09754          1  \n",
       "90000446335  0.22195  0.04186  0.01555  0.05280  0.10649 -0.01839          1  \n",
       "90000201646  0.50519 -0.02274 -0.05164  0.02385  0.15533 -0.05593          1  \n",
       "\n",
       "[8200 rows x 227 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_11=df_11.sample(n=8200)\n",
    "df_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.06610</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>-0.13607</td>\n",
       "      <td>0.10945</td>\n",
       "      <td>0.06557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>-0.18965</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.24149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19113</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>0.09471</td>\n",
       "      <td>0.27091</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0.02938</td>\n",
       "      <td>0.17105</td>\n",
       "      <td>0.12537</td>\n",
       "      <td>0.22197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.01048</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.37797</td>\n",
       "      <td>-0.10970</td>\n",
       "      <td>0.52032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.32632</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.73494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.52084</td>\n",
       "      <td>-0.18568</td>\n",
       "      <td>-0.09755</td>\n",
       "      <td>-0.56565</td>\n",
       "      <td>-0.17840</td>\n",
       "      <td>-0.06314</td>\n",
       "      <td>-0.17111</td>\n",
       "      <td>-0.32239</td>\n",
       "      <td>0.33962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.10778</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>-0.12917</td>\n",
       "      <td>0.06835</td>\n",
       "      <td>-0.40939</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>-0.13009</td>\n",
       "      <td>0.7291</td>\n",
       "      <td>-0.39929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27452</td>\n",
       "      <td>0.04098</td>\n",
       "      <td>0.06074</td>\n",
       "      <td>0.49646</td>\n",
       "      <td>-0.02204</td>\n",
       "      <td>-0.06996</td>\n",
       "      <td>0.01552</td>\n",
       "      <td>0.20518</td>\n",
       "      <td>-0.09952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02596</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.09658</td>\n",
       "      <td>-0.21836</td>\n",
       "      <td>0.47897</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>0.39811</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.45440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.44143</td>\n",
       "      <td>-0.15050</td>\n",
       "      <td>-0.19061</td>\n",
       "      <td>-0.52859</td>\n",
       "      <td>-0.19092</td>\n",
       "      <td>-0.03939</td>\n",
       "      <td>-0.11918</td>\n",
       "      <td>-0.29188</td>\n",
       "      <td>0.21474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03735</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>-0.07106</td>\n",
       "      <td>0.05682</td>\n",
       "      <td>0.51936</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>-0.11848</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>0.20183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12450</td>\n",
       "      <td>0.09082</td>\n",
       "      <td>0.03790</td>\n",
       "      <td>-0.01301</td>\n",
       "      <td>0.11605</td>\n",
       "      <td>0.41329</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>-0.13191</td>\n",
       "      <td>0.10532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16395</th>\n",
       "      <td>-0.04333</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>-0.09883</td>\n",
       "      <td>0.10387</td>\n",
       "      <td>-0.28672</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>-0.21343</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>-0.36820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35487</td>\n",
       "      <td>0.11576</td>\n",
       "      <td>0.09007</td>\n",
       "      <td>0.60444</td>\n",
       "      <td>0.17611</td>\n",
       "      <td>-0.01544</td>\n",
       "      <td>0.17696</td>\n",
       "      <td>0.23089</td>\n",
       "      <td>-0.14242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16396</th>\n",
       "      <td>-0.04333</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>-0.09883</td>\n",
       "      <td>0.10387</td>\n",
       "      <td>-0.28672</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>-0.21343</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>-0.36820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35487</td>\n",
       "      <td>0.11576</td>\n",
       "      <td>0.09007</td>\n",
       "      <td>0.60444</td>\n",
       "      <td>0.17611</td>\n",
       "      <td>-0.01544</td>\n",
       "      <td>0.17696</td>\n",
       "      <td>0.23089</td>\n",
       "      <td>-0.14242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16397</th>\n",
       "      <td>-0.04333</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>-0.09883</td>\n",
       "      <td>0.10387</td>\n",
       "      <td>-0.28672</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>-0.21343</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>-0.36820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35487</td>\n",
       "      <td>0.11576</td>\n",
       "      <td>0.09007</td>\n",
       "      <td>0.60444</td>\n",
       "      <td>0.17611</td>\n",
       "      <td>-0.01544</td>\n",
       "      <td>0.17696</td>\n",
       "      <td>0.23089</td>\n",
       "      <td>-0.14242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>0.01582</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>-0.01433</td>\n",
       "      <td>-0.05258</td>\n",
       "      <td>0.29836</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5827</td>\n",
       "      <td>0.03621</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.42721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.06714</td>\n",
       "      <td>0.01031</td>\n",
       "      <td>-0.04328</td>\n",
       "      <td>-0.13777</td>\n",
       "      <td>0.04718</td>\n",
       "      <td>-0.00704</td>\n",
       "      <td>-0.01033</td>\n",
       "      <td>-0.05327</td>\n",
       "      <td>0.04590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16399</th>\n",
       "      <td>-0.03922</td>\n",
       "      <td>0.1574</td>\n",
       "      <td>-0.16061</td>\n",
       "      <td>0.32858</td>\n",
       "      <td>-0.15058</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3127</td>\n",
       "      <td>-0.17936</td>\n",
       "      <td>0.6309</td>\n",
       "      <td>-0.35850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40832</td>\n",
       "      <td>0.08524</td>\n",
       "      <td>0.10626</td>\n",
       "      <td>0.50266</td>\n",
       "      <td>0.04975</td>\n",
       "      <td>0.08238</td>\n",
       "      <td>0.00061</td>\n",
       "      <td>0.25631</td>\n",
       "      <td>-0.35084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16400 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008   VAR009  \\\n",
       "0     -0.06610  0.5280 -0.13607  0.10945  0.06557       0  0.7702 -0.18965   \n",
       "1     -0.01048  0.8360  0.37797 -0.10970  0.52032       1  0.3257  0.32632   \n",
       "2     -0.10778  0.0810 -0.12917  0.06835 -0.40939       0  0.7128 -0.13009   \n",
       "3      0.02596  0.2279  0.09658 -0.21836  0.47897       0  0.1961  0.39811   \n",
       "4      0.03735  0.3486 -0.07106  0.05682  0.51936       1  0.6283 -0.11848   \n",
       "...        ...     ...      ...      ...      ...     ...     ...      ...   \n",
       "16395 -0.04333  0.0141 -0.09883  0.10387 -0.28672       0  0.0138 -0.21343   \n",
       "16396 -0.04333  0.0141 -0.09883  0.10387 -0.28672       0  0.0138 -0.21343   \n",
       "16397 -0.04333  0.0141 -0.09883  0.10387 -0.28672       0  0.0138 -0.21343   \n",
       "16398  0.01582  0.2878 -0.01433 -0.05258  0.29836       0  0.5827  0.03621   \n",
       "16399 -0.03922  0.1574 -0.16061  0.32858 -0.15058       0  0.3127 -0.17936   \n",
       "\n",
       "       VAR010   VAR011  ...   VAR219   VAR220   VAR221   VAR222   VAR223  \\\n",
       "0      0.1981  0.24149  ...  0.19113  0.05449  0.09471  0.27091  0.01931   \n",
       "1      0.7343  0.73494  ... -0.52084 -0.18568 -0.09755 -0.56565 -0.17840   \n",
       "2      0.7291 -0.39929  ...  0.27452  0.04098  0.06074  0.49646 -0.02204   \n",
       "3      0.2458  0.45440  ... -0.44143 -0.15050 -0.19061 -0.52859 -0.19092   \n",
       "4      0.2781  0.20183  ...  0.12450  0.09082  0.03790 -0.01301  0.11605   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "16395  0.8414 -0.36820  ...  0.35487  0.11576  0.09007  0.60444  0.17611   \n",
       "16396  0.8414 -0.36820  ...  0.35487  0.11576  0.09007  0.60444  0.17611   \n",
       "16397  0.8414 -0.36820  ...  0.35487  0.11576  0.09007  0.60444  0.17611   \n",
       "16398  0.2206  0.42721  ... -0.06714  0.01031 -0.04328 -0.13777  0.04718   \n",
       "16399  0.6309 -0.35850  ...  0.40832  0.08524  0.10626  0.50266  0.04975   \n",
       "\n",
       "        VAR224   VAR225   VAR226   VAR227  MRC_ID_DI  \n",
       "0      0.02938  0.17105  0.12537  0.22197          0  \n",
       "1     -0.06314 -0.17111 -0.32239  0.33962          0  \n",
       "2     -0.06996  0.01552  0.20518 -0.09952          0  \n",
       "3     -0.03939 -0.11918 -0.29188  0.21474          0  \n",
       "4      0.41329  0.01658 -0.13191  0.10532          0  \n",
       "...        ...      ...      ...      ...        ...  \n",
       "16395 -0.01544  0.17696  0.23089 -0.14242          1  \n",
       "16396 -0.01544  0.17696  0.23089 -0.14242          1  \n",
       "16397 -0.01544  0.17696  0.23089 -0.14242          1  \n",
       "16398 -0.00704 -0.01033 -0.05327  0.04590          1  \n",
       "16399  0.08238  0.00061  0.25631 -0.35084          1  \n",
       "\n",
       "[16400 rows x 227 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.merge(df_0,df_11,how='outer')\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13746</th>\n",
       "      <td>-0.06089</td>\n",
       "      <td>0.3584</td>\n",
       "      <td>-0.14236</td>\n",
       "      <td>0.08314</td>\n",
       "      <td>-0.00841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>-0.18202</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>-0.05455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23922</td>\n",
       "      <td>0.13177</td>\n",
       "      <td>0.08977</td>\n",
       "      <td>0.41950</td>\n",
       "      <td>0.27230</td>\n",
       "      <td>-0.04413</td>\n",
       "      <td>0.02582</td>\n",
       "      <td>0.17679</td>\n",
       "      <td>-0.24452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>-0.03367</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.33054</td>\n",
       "      <td>-0.18907</td>\n",
       "      <td>0.50606</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.31240</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.55700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.45100</td>\n",
       "      <td>-0.16388</td>\n",
       "      <td>-0.16951</td>\n",
       "      <td>-0.57495</td>\n",
       "      <td>-0.18113</td>\n",
       "      <td>-0.10811</td>\n",
       "      <td>-0.10341</td>\n",
       "      <td>-0.36850</td>\n",
       "      <td>0.29112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-0.03627</td>\n",
       "      <td>0.8279</td>\n",
       "      <td>0.13692</td>\n",
       "      <td>0.00587</td>\n",
       "      <td>0.47595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9115</td>\n",
       "      <td>0.17639</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.69387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.31046</td>\n",
       "      <td>-0.11550</td>\n",
       "      <td>-0.00113</td>\n",
       "      <td>-0.41024</td>\n",
       "      <td>-0.10418</td>\n",
       "      <td>-0.04688</td>\n",
       "      <td>-0.09820</td>\n",
       "      <td>-0.00405</td>\n",
       "      <td>0.42762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12658</th>\n",
       "      <td>0.12792</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>-0.09195</td>\n",
       "      <td>0.07691</td>\n",
       "      <td>0.02707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>-0.15978</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.18952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24945</td>\n",
       "      <td>0.01816</td>\n",
       "      <td>0.06437</td>\n",
       "      <td>0.28888</td>\n",
       "      <td>0.02745</td>\n",
       "      <td>0.31398</td>\n",
       "      <td>0.00316</td>\n",
       "      <td>0.15535</td>\n",
       "      <td>0.15747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>-0.03910</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.08382</td>\n",
       "      <td>-0.04888</td>\n",
       "      <td>0.20399</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2904</td>\n",
       "      <td>0.06168</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.54524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04259</td>\n",
       "      <td>-0.10335</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>-0.00771</td>\n",
       "      <td>-0.08759</td>\n",
       "      <td>-0.07035</td>\n",
       "      <td>-0.04952</td>\n",
       "      <td>0.13356</td>\n",
       "      <td>0.26567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.05588</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>-0.01794</td>\n",
       "      <td>0.02727</td>\n",
       "      <td>0.30702</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>-0.07124</td>\n",
       "      <td>0.7522</td>\n",
       "      <td>0.49023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13421</td>\n",
       "      <td>0.01838</td>\n",
       "      <td>0.04953</td>\n",
       "      <td>-0.17271</td>\n",
       "      <td>0.00744</td>\n",
       "      <td>-0.05669</td>\n",
       "      <td>0.00900</td>\n",
       "      <td>-0.07454</td>\n",
       "      <td>0.43960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.00779</td>\n",
       "      <td>0.8573</td>\n",
       "      <td>0.09643</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.57101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.27440</td>\n",
       "      <td>0.3652</td>\n",
       "      <td>0.54342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.54095</td>\n",
       "      <td>-0.08010</td>\n",
       "      <td>-0.14624</td>\n",
       "      <td>-0.62989</td>\n",
       "      <td>-0.05792</td>\n",
       "      <td>-0.06233</td>\n",
       "      <td>-0.11014</td>\n",
       "      <td>-0.38185</td>\n",
       "      <td>0.27649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>0.01185</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.19087</td>\n",
       "      <td>-0.11105</td>\n",
       "      <td>0.15742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2971</td>\n",
       "      <td>0.17121</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.45311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.49866</td>\n",
       "      <td>-0.11848</td>\n",
       "      <td>-0.09278</td>\n",
       "      <td>-0.54630</td>\n",
       "      <td>-0.07028</td>\n",
       "      <td>-0.03942</td>\n",
       "      <td>-0.14239</td>\n",
       "      <td>-0.30948</td>\n",
       "      <td>0.23604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8005</th>\n",
       "      <td>0.24850</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>-0.01819</td>\n",
       "      <td>-0.09128</td>\n",
       "      <td>0.36717</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3084</td>\n",
       "      <td>0.10080</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.52156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20750</td>\n",
       "      <td>-0.02396</td>\n",
       "      <td>-0.08080</td>\n",
       "      <td>-0.17573</td>\n",
       "      <td>-0.05183</td>\n",
       "      <td>0.05814</td>\n",
       "      <td>0.54887</td>\n",
       "      <td>-0.19343</td>\n",
       "      <td>0.55406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>-0.04679</td>\n",
       "      <td>0.4967</td>\n",
       "      <td>0.36460</td>\n",
       "      <td>-0.19120</td>\n",
       "      <td>0.56688</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.28359</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.73938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.43509</td>\n",
       "      <td>-0.19827</td>\n",
       "      <td>-0.17938</td>\n",
       "      <td>-0.51616</td>\n",
       "      <td>-0.22846</td>\n",
       "      <td>-0.11877</td>\n",
       "      <td>-0.14230</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>0.36332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16400 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008   VAR009  \\\n",
       "13746 -0.06089  0.3584 -0.14236  0.08314 -0.00841       0  0.2965 -0.18202   \n",
       "1193  -0.03367  0.8111  0.33054 -0.18907  0.50606       0  0.4886  0.31240   \n",
       "451   -0.03627  0.8279  0.13692  0.00587  0.47595       0  0.9115  0.17639   \n",
       "12658  0.12792  0.1166 -0.09195  0.07691  0.02707       0  0.1782 -0.15978   \n",
       "2863  -0.03910  0.3933  0.08382 -0.04888  0.20399       0  0.2904  0.06168   \n",
       "...        ...     ...      ...      ...      ...     ...     ...      ...   \n",
       "6067  -0.05588  0.5902 -0.01794  0.02727  0.30702       0  0.4811 -0.07124   \n",
       "303    0.00779  0.8573  0.09643 -0.17238  0.57101       0  0.5401  0.27440   \n",
       "4734   0.01185  0.7955  0.19087 -0.11105  0.15742       0  0.2971  0.17121   \n",
       "8005   0.24850  0.9405 -0.01819 -0.09128  0.36717       1  0.3084  0.10080   \n",
       "1139  -0.04679  0.4967  0.36460 -0.19120  0.56688       0  0.7083  0.28359   \n",
       "\n",
       "       VAR010   VAR011  ...   VAR219   VAR220   VAR221   VAR222   VAR223  \\\n",
       "13746  0.9334 -0.05455  ...  0.23922  0.13177  0.08977  0.41950  0.27230   \n",
       "1193   0.1540  0.55700  ... -0.45100 -0.16388 -0.16951 -0.57495 -0.18113   \n",
       "451    0.8451  0.69387  ... -0.31046 -0.11550 -0.00113 -0.41024 -0.10418   \n",
       "12658  0.4563  0.18952  ...  0.24945  0.01816  0.06437  0.28888  0.02745   \n",
       "2863   0.8853  0.54524  ... -0.04259 -0.10335 -0.04549 -0.00771 -0.08759   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "6067   0.7522  0.49023  ... -0.13421  0.01838  0.04953 -0.17271  0.00744   \n",
       "303    0.3652  0.54342  ... -0.54095 -0.08010 -0.14624 -0.62989 -0.05792   \n",
       "4734   0.7251  0.45311  ... -0.49866 -0.11848 -0.09278 -0.54630 -0.07028   \n",
       "8005   0.0370  0.52156  ... -0.20750 -0.02396 -0.08080 -0.17573 -0.05183   \n",
       "1139   0.0091  0.73938  ... -0.43509 -0.19827 -0.17938 -0.51616 -0.22846   \n",
       "\n",
       "        VAR224   VAR225   VAR226   VAR227  MRC_ID_DI  \n",
       "13746 -0.04413  0.02582  0.17679 -0.24452          1  \n",
       "1193  -0.10811 -0.10341 -0.36850  0.29112          0  \n",
       "451   -0.04688 -0.09820 -0.00405  0.42762          0  \n",
       "12658  0.31398  0.00316  0.15535  0.15747          1  \n",
       "2863  -0.07035 -0.04952  0.13356  0.26567          0  \n",
       "...        ...      ...      ...      ...        ...  \n",
       "6067  -0.05669  0.00900 -0.07454  0.43960          0  \n",
       "303   -0.06233 -0.11014 -0.38185  0.27649          0  \n",
       "4734  -0.03942 -0.14239 -0.30948  0.23604          0  \n",
       "8005   0.05814  0.54887 -0.19343  0.55406          0  \n",
       "1139  -0.11877 -0.14230 -0.19967  0.36332          0  \n",
       "\n",
       "[16400 rows x 227 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=DF.sample(frac=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR214</th>\n",
       "      <th>VAR217</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13746</th>\n",
       "      <td>-0.06089</td>\n",
       "      <td>0.3584</td>\n",
       "      <td>-0.14236</td>\n",
       "      <td>0.08314</td>\n",
       "      <td>-0.00841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>-0.18202</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>-0.05455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20634</td>\n",
       "      <td>0.04837</td>\n",
       "      <td>0.13177</td>\n",
       "      <td>0.08977</td>\n",
       "      <td>0.27230</td>\n",
       "      <td>-0.04413</td>\n",
       "      <td>0.02582</td>\n",
       "      <td>0.17679</td>\n",
       "      <td>-0.24452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>-0.03367</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.33054</td>\n",
       "      <td>-0.18907</td>\n",
       "      <td>0.50606</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.31240</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.55700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22173</td>\n",
       "      <td>0.19258</td>\n",
       "      <td>-0.16388</td>\n",
       "      <td>-0.16951</td>\n",
       "      <td>-0.18113</td>\n",
       "      <td>-0.10811</td>\n",
       "      <td>-0.10341</td>\n",
       "      <td>-0.36850</td>\n",
       "      <td>0.29112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-0.03627</td>\n",
       "      <td>0.8279</td>\n",
       "      <td>0.13692</td>\n",
       "      <td>0.00587</td>\n",
       "      <td>0.47595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9115</td>\n",
       "      <td>0.17639</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.69387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02776</td>\n",
       "      <td>0.08458</td>\n",
       "      <td>-0.11550</td>\n",
       "      <td>-0.00113</td>\n",
       "      <td>-0.10418</td>\n",
       "      <td>-0.04688</td>\n",
       "      <td>-0.09820</td>\n",
       "      <td>-0.00405</td>\n",
       "      <td>0.42762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12658</th>\n",
       "      <td>0.12792</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>-0.09195</td>\n",
       "      <td>0.07691</td>\n",
       "      <td>0.02707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>-0.15978</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.18952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.09354</td>\n",
       "      <td>-0.09128</td>\n",
       "      <td>0.01816</td>\n",
       "      <td>0.06437</td>\n",
       "      <td>0.02745</td>\n",
       "      <td>0.31398</td>\n",
       "      <td>0.00316</td>\n",
       "      <td>0.15535</td>\n",
       "      <td>0.15747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>-0.03910</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.08382</td>\n",
       "      <td>-0.04888</td>\n",
       "      <td>0.20399</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2904</td>\n",
       "      <td>0.06168</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.54524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20188</td>\n",
       "      <td>0.05998</td>\n",
       "      <td>-0.10335</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>-0.08759</td>\n",
       "      <td>-0.07035</td>\n",
       "      <td>-0.04952</td>\n",
       "      <td>0.13356</td>\n",
       "      <td>0.26567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.05588</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>-0.01794</td>\n",
       "      <td>0.02727</td>\n",
       "      <td>0.30702</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>-0.07124</td>\n",
       "      <td>0.7522</td>\n",
       "      <td>0.49023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00627</td>\n",
       "      <td>-0.02105</td>\n",
       "      <td>0.01838</td>\n",
       "      <td>0.04953</td>\n",
       "      <td>0.00744</td>\n",
       "      <td>-0.05669</td>\n",
       "      <td>0.00900</td>\n",
       "      <td>-0.07454</td>\n",
       "      <td>0.43960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.00779</td>\n",
       "      <td>0.8573</td>\n",
       "      <td>0.09643</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.57101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.27440</td>\n",
       "      <td>0.3652</td>\n",
       "      <td>0.54342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30241</td>\n",
       "      <td>0.22383</td>\n",
       "      <td>-0.08010</td>\n",
       "      <td>-0.14624</td>\n",
       "      <td>-0.05792</td>\n",
       "      <td>-0.06233</td>\n",
       "      <td>-0.11014</td>\n",
       "      <td>-0.38185</td>\n",
       "      <td>0.27649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>0.01185</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.19087</td>\n",
       "      <td>-0.11105</td>\n",
       "      <td>0.15742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2971</td>\n",
       "      <td>0.17121</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.45311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22073</td>\n",
       "      <td>-0.22339</td>\n",
       "      <td>-0.11848</td>\n",
       "      <td>-0.09278</td>\n",
       "      <td>-0.07028</td>\n",
       "      <td>-0.03942</td>\n",
       "      <td>-0.14239</td>\n",
       "      <td>-0.30948</td>\n",
       "      <td>0.23604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8005</th>\n",
       "      <td>0.24850</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>-0.01819</td>\n",
       "      <td>-0.09128</td>\n",
       "      <td>0.36717</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3084</td>\n",
       "      <td>0.10080</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.52156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21994</td>\n",
       "      <td>-0.08585</td>\n",
       "      <td>-0.02396</td>\n",
       "      <td>-0.08080</td>\n",
       "      <td>-0.05183</td>\n",
       "      <td>0.05814</td>\n",
       "      <td>0.54887</td>\n",
       "      <td>-0.19343</td>\n",
       "      <td>0.55406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>-0.04679</td>\n",
       "      <td>0.4967</td>\n",
       "      <td>0.36460</td>\n",
       "      <td>-0.19120</td>\n",
       "      <td>0.56688</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.28359</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.73938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05099</td>\n",
       "      <td>0.14370</td>\n",
       "      <td>-0.19827</td>\n",
       "      <td>-0.17938</td>\n",
       "      <td>-0.22846</td>\n",
       "      <td>-0.11877</td>\n",
       "      <td>-0.14230</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>0.36332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16400 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008   VAR009  \\\n",
       "13746 -0.06089  0.3584 -0.14236  0.08314 -0.00841       0  0.2965 -0.18202   \n",
       "1193  -0.03367  0.8111  0.33054 -0.18907  0.50606       0  0.4886  0.31240   \n",
       "451   -0.03627  0.8279  0.13692  0.00587  0.47595       0  0.9115  0.17639   \n",
       "12658  0.12792  0.1166 -0.09195  0.07691  0.02707       0  0.1782 -0.15978   \n",
       "2863  -0.03910  0.3933  0.08382 -0.04888  0.20399       0  0.2904  0.06168   \n",
       "...        ...     ...      ...      ...      ...     ...     ...      ...   \n",
       "6067  -0.05588  0.5902 -0.01794  0.02727  0.30702       0  0.4811 -0.07124   \n",
       "303    0.00779  0.8573  0.09643 -0.17238  0.57101       0  0.5401  0.27440   \n",
       "4734   0.01185  0.7955  0.19087 -0.11105  0.15742       0  0.2971  0.17121   \n",
       "8005   0.24850  0.9405 -0.01819 -0.09128  0.36717       1  0.3084  0.10080   \n",
       "1139  -0.04679  0.4967  0.36460 -0.19120  0.56688       0  0.7083  0.28359   \n",
       "\n",
       "       VAR010   VAR011  ...   VAR214   VAR217   VAR220   VAR221   VAR223  \\\n",
       "13746  0.9334 -0.05455  ... -0.20634  0.04837  0.13177  0.08977  0.27230   \n",
       "1193   0.1540  0.55700  ...  0.22173  0.19258 -0.16388 -0.16951 -0.18113   \n",
       "451    0.8451  0.69387  ... -0.02776  0.08458 -0.11550 -0.00113 -0.10418   \n",
       "12658  0.4563  0.18952  ... -0.09354 -0.09128  0.01816  0.06437  0.02745   \n",
       "2863   0.8853  0.54524  ... -0.20188  0.05998 -0.10335 -0.04549 -0.08759   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "6067   0.7522  0.49023  ... -0.00627 -0.02105  0.01838  0.04953  0.00744   \n",
       "303    0.3652  0.54342  ...  0.30241  0.22383 -0.08010 -0.14624 -0.05792   \n",
       "4734   0.7251  0.45311  ...  0.22073 -0.22339 -0.11848 -0.09278 -0.07028   \n",
       "8005   0.0370  0.52156  ...  0.21994 -0.08585 -0.02396 -0.08080 -0.05183   \n",
       "1139   0.0091  0.73938  ...  0.05099  0.14370 -0.19827 -0.17938 -0.22846   \n",
       "\n",
       "        VAR224   VAR225   VAR226   VAR227  MRC_ID_DI  \n",
       "13746 -0.04413  0.02582  0.17679 -0.24452          1  \n",
       "1193  -0.10811 -0.10341 -0.36850  0.29112          0  \n",
       "451   -0.04688 -0.09820 -0.00405  0.42762          0  \n",
       "12658  0.31398  0.00316  0.15535  0.15747          1  \n",
       "2863  -0.07035 -0.04952  0.13356  0.26567          0  \n",
       "...        ...      ...      ...      ...        ...  \n",
       "6067  -0.05669  0.00900 -0.07454  0.43960          0  \n",
       "303   -0.06233 -0.11014 -0.38185  0.27649          0  \n",
       "4734  -0.03942 -0.14239 -0.30948  0.23604          0  \n",
       "8005   0.05814  0.54887 -0.19343  0.55406          0  \n",
       "1139  -0.11877 -0.14230 -0.19967  0.36332          0  \n",
       "\n",
       "[16400 rows x 189 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list95 = ['VAR034','VAR089',\n",
    "           'VAR091','VAR116','VAR123','VAR126','VAR134','VAR149','VAR153','VAR157','VAR160','VAR167','VAR169','VAR174','VAR176','VAR184',\n",
    "           'VAR202','VAR204','VAR209','VAR216','VAR218','VAR219','VAR222']\n",
    "\n",
    "list96 = ['VAR056',\n",
    "         'VAR069','VAR122','VAR123','VAR126','VAR134','VAR137','VAR157','VAR159','VAR184','VAR196','VAR215','VAR216','VAR218','VAR219']\n",
    "\n",
    "list97 = ['VAR058','VAR076','VAR134','VAR157','VAR176','VAR203','VAR215','VAR216','VAR218','VAR219','VAR222']\n",
    "\n",
    "list98 = ['VAR093','VAR106','VAR114','VAR115','VAR122','VAR147','VAR157']\n",
    "\n",
    "lists= list95+list96+list97+list98\n",
    "print(len(lists))\n",
    "lists = list(set(lists))\n",
    "print(len(lists))\n",
    "#var015추가 \n",
    "#lists.append('VAR015')\n",
    "#print(len(lists))\n",
    "\n",
    "df2=df2.drop(lists,axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16400, 188) (16400,)\n"
     ]
    }
   ],
   "source": [
    "X=df2.loc[:,'VAR002':'VAR227']\n",
    "y=df2.loc[:,'MRC_ID_DI']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = tf.keras.Input(dtype = tf.float32, shape = (len(X.columns),))\n",
    "\n",
    "dense_layer_1_1 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(input_)\n",
    "dense_layer_1_2 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_1)\n",
    "dense_layer_1_3 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_2)\n",
    "dense_layer_1_4 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_3)\n",
    "\n",
    "dropout_1_5 = tf.keras.layers.Dropout(rate = 0.2)(dense_layer_1_1)\n",
    "\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.softmax)(dropout_1_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=input_, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 188)]             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1890      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 1,912\n",
      "Trainable params: 1,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.00005), metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13284 samples, validate on 1476 samples\n",
      "Epoch 1/10000\n",
      "13284/13284 [==============================] - 0s 33us/sample - loss: 0.6413 - acc: 0.6084 - val_loss: 0.6223 - val_acc: 0.6551\n",
      "Epoch 2/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.6057 - acc: 0.6791 - val_loss: 0.5966 - val_acc: 0.6911\n",
      "Epoch 3/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5815 - acc: 0.7114 - val_loss: 0.5788 - val_acc: 0.7060\n",
      "Epoch 4/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5666 - acc: 0.7207 - val_loss: 0.5655 - val_acc: 0.7127\n",
      "Epoch 5/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5565 - acc: 0.7272 - val_loss: 0.5557 - val_acc: 0.7188\n",
      "Epoch 6/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5452 - acc: 0.7312 - val_loss: 0.5473 - val_acc: 0.7188\n",
      "Epoch 7/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5387 - acc: 0.7340 - val_loss: 0.5405 - val_acc: 0.7243\n",
      "Epoch 8/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5306 - acc: 0.7383 - val_loss: 0.5347 - val_acc: 0.7290\n",
      "Epoch 9/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5259 - acc: 0.7425 - val_loss: 0.5297 - val_acc: 0.7297\n",
      "Epoch 10/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5203 - acc: 0.7431 - val_loss: 0.5248 - val_acc: 0.7317\n",
      "Epoch 11/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5177 - acc: 0.7434 - val_loss: 0.5204 - val_acc: 0.7405\n",
      "Epoch 12/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5124 - acc: 0.7501 - val_loss: 0.5161 - val_acc: 0.7453\n",
      "Epoch 13/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5083 - acc: 0.7530 - val_loss: 0.5123 - val_acc: 0.7493\n",
      "Epoch 14/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.5049 - acc: 0.756 - 0s 27us/sample - loss: 0.5038 - acc: 0.7565 - val_loss: 0.5085 - val_acc: 0.7595\n",
      "Epoch 15/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.5029 - acc: 0.7587 - val_loss: 0.5049 - val_acc: 0.7629\n",
      "Epoch 16/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4975 - acc: 0.7630 - val_loss: 0.5016 - val_acc: 0.7581\n",
      "Epoch 17/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4973 - acc: 0.7618 - val_loss: 0.4988 - val_acc: 0.7636\n",
      "Epoch 18/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4930 - acc: 0.7655 - val_loss: 0.4961 - val_acc: 0.7581\n",
      "Epoch 19/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4926 - acc: 0.7669 - val_loss: 0.4936 - val_acc: 0.7622\n",
      "Epoch 20/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4856 - acc: 0.7705 - val_loss: 0.4909 - val_acc: 0.7615\n",
      "Epoch 21/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4866 - acc: 0.7651 - val_loss: 0.4885 - val_acc: 0.7642\n",
      "Epoch 22/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4826 - acc: 0.7708 - val_loss: 0.4862 - val_acc: 0.7608\n",
      "Epoch 23/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4805 - acc: 0.7713 - val_loss: 0.4838 - val_acc: 0.7710\n",
      "Epoch 24/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4782 - acc: 0.7722 - val_loss: 0.4819 - val_acc: 0.7663\n",
      "Epoch 25/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4781 - acc: 0.7727 - val_loss: 0.4800 - val_acc: 0.7717\n",
      "Epoch 26/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4757 - acc: 0.7760 - val_loss: 0.4783 - val_acc: 0.7717\n",
      "Epoch 27/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4735 - acc: 0.7795 - val_loss: 0.4766 - val_acc: 0.7724\n",
      "Epoch 28/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4723 - acc: 0.7757 - val_loss: 0.4751 - val_acc: 0.7757\n",
      "Epoch 29/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4685 - acc: 0.7816 - val_loss: 0.4737 - val_acc: 0.7724\n",
      "Epoch 30/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4685 - acc: 0.7788 - val_loss: 0.4718 - val_acc: 0.7771\n",
      "Epoch 31/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4679 - acc: 0.7796 - val_loss: 0.4710 - val_acc: 0.7785\n",
      "Epoch 32/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4649 - acc: 0.7833 - val_loss: 0.4694 - val_acc: 0.7818\n",
      "Epoch 33/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4615 - acc: 0.7846 - val_loss: 0.4682 - val_acc: 0.7832\n",
      "Epoch 34/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4634 - acc: 0.7852 - val_loss: 0.4671 - val_acc: 0.7818\n",
      "Epoch 35/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4630 - acc: 0.7857 - val_loss: 0.4661 - val_acc: 0.7825\n",
      "Epoch 36/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4610 - acc: 0.7852 - val_loss: 0.4649 - val_acc: 0.7832\n",
      "Epoch 37/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4616 - acc: 0.7855 - val_loss: 0.4644 - val_acc: 0.7805\n",
      "Epoch 38/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4606 - acc: 0.7856 - val_loss: 0.4634 - val_acc: 0.7839\n",
      "Epoch 39/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4571 - acc: 0.7874 - val_loss: 0.4625 - val_acc: 0.7846\n",
      "Epoch 40/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4573 - acc: 0.7856 - val_loss: 0.4614 - val_acc: 0.7866\n",
      "Epoch 41/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4542 - acc: 0.7885 - val_loss: 0.4605 - val_acc: 0.7846\n",
      "Epoch 42/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4535 - acc: 0.7929 - val_loss: 0.4596 - val_acc: 0.7859\n",
      "Epoch 43/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4547 - acc: 0.7890 - val_loss: 0.4592 - val_acc: 0.7818\n",
      "Epoch 44/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4507 - acc: 0.7921 - val_loss: 0.4580 - val_acc: 0.7832\n",
      "Epoch 45/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4494 - acc: 0.7916 - val_loss: 0.4573 - val_acc: 0.7839\n",
      "Epoch 46/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4523 - acc: 0.7912 - val_loss: 0.4566 - val_acc: 0.7832\n",
      "Epoch 47/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4488 - acc: 0.7923 - val_loss: 0.4556 - val_acc: 0.7825\n",
      "Epoch 48/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4493 - acc: 0.7913 - val_loss: 0.4550 - val_acc: 0.7825\n",
      "Epoch 49/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4512 - acc: 0.7909 - val_loss: 0.4547 - val_acc: 0.7839\n",
      "Epoch 50/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4493 - acc: 0.7909 - val_loss: 0.4536 - val_acc: 0.7866\n",
      "Epoch 51/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4470 - acc: 0.7934 - val_loss: 0.4532 - val_acc: 0.7873\n",
      "Epoch 52/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4470 - acc: 0.7917 - val_loss: 0.4526 - val_acc: 0.7873\n",
      "Epoch 53/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4464 - acc: 0.7953 - val_loss: 0.4521 - val_acc: 0.7886\n",
      "Epoch 54/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4454 - acc: 0.7940 - val_loss: 0.4510 - val_acc: 0.7886\n",
      "Epoch 55/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4420 - acc: 0.7967 - val_loss: 0.4506 - val_acc: 0.7893\n",
      "Epoch 56/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4434 - acc: 0.7952 - val_loss: 0.4503 - val_acc: 0.7873\n",
      "Epoch 57/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4432 - acc: 0.7958 - val_loss: 0.4492 - val_acc: 0.7886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4420 - acc: 0.7949 - val_loss: 0.4489 - val_acc: 0.7886\n",
      "Epoch 59/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4428 - acc: 0.7949 - val_loss: 0.4482 - val_acc: 0.7879\n",
      "Epoch 60/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4419 - acc: 0.7961 - val_loss: 0.4479 - val_acc: 0.7866\n",
      "Epoch 61/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4414 - acc: 0.7959 - val_loss: 0.4471 - val_acc: 0.7852\n",
      "Epoch 62/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4409 - acc: 0.7974 - val_loss: 0.4467 - val_acc: 0.7873\n",
      "Epoch 63/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4380 - acc: 0.7995 - val_loss: 0.4460 - val_acc: 0.7900\n",
      "Epoch 64/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4374 - acc: 0.7981 - val_loss: 0.4453 - val_acc: 0.7866\n",
      "Epoch 65/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4372 - acc: 0.8000 - val_loss: 0.4448 - val_acc: 0.7893\n",
      "Epoch 66/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4357 - acc: 0.8007 - val_loss: 0.4443 - val_acc: 0.7900\n",
      "Epoch 67/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4364 - acc: 0.7991 - val_loss: 0.4441 - val_acc: 0.7866\n",
      "Epoch 68/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4351 - acc: 0.7999 - val_loss: 0.4433 - val_acc: 0.7913\n",
      "Epoch 69/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4342 - acc: 0.7979 - val_loss: 0.4428 - val_acc: 0.7913\n",
      "Epoch 70/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4370 - acc: 0.8000 - val_loss: 0.4427 - val_acc: 0.7893\n",
      "Epoch 71/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4341 - acc: 0.8024 - val_loss: 0.4421 - val_acc: 0.7920\n",
      "Epoch 72/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4337 - acc: 0.7990 - val_loss: 0.4415 - val_acc: 0.7900\n",
      "Epoch 73/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4326 - acc: 0.8005 - val_loss: 0.4411 - val_acc: 0.7920\n",
      "Epoch 74/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4334 - acc: 0.7990 - val_loss: 0.4407 - val_acc: 0.7900\n",
      "Epoch 75/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4342 - acc: 0.7987 - val_loss: 0.4404 - val_acc: 0.7934\n",
      "Epoch 76/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4311 - acc: 0.8024 - val_loss: 0.4398 - val_acc: 0.7907\n",
      "Epoch 77/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4346 - acc: 0.8011 - val_loss: 0.4396 - val_acc: 0.7920\n",
      "Epoch 78/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.4293 - acc: 0.8010 - val_loss: 0.4392 - val_acc: 0.7866\n",
      "Epoch 79/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4301 - acc: 0.8015 - val_loss: 0.4385 - val_acc: 0.7920\n",
      "Epoch 80/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4314 - acc: 0.8044 - val_loss: 0.4381 - val_acc: 0.7920\n",
      "Epoch 81/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4300 - acc: 0.8004 - val_loss: 0.4382 - val_acc: 0.7940\n",
      "Epoch 82/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4282 - acc: 0.8021 - val_loss: 0.4374 - val_acc: 0.7920\n",
      "Epoch 83/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4287 - acc: 0.8021 - val_loss: 0.4370 - val_acc: 0.7913\n",
      "Epoch 84/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4266 - acc: 0.8026 - val_loss: 0.4368 - val_acc: 0.7879\n",
      "Epoch 85/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4283 - acc: 0.8025 - val_loss: 0.4362 - val_acc: 0.7934\n",
      "Epoch 86/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4275 - acc: 0.8042 - val_loss: 0.4359 - val_acc: 0.7940\n",
      "Epoch 87/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4270 - acc: 0.8040 - val_loss: 0.4358 - val_acc: 0.7920\n",
      "Epoch 88/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4254 - acc: 0.8028 - val_loss: 0.4355 - val_acc: 0.7913\n",
      "Epoch 89/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4261 - acc: 0.8007 - val_loss: 0.4349 - val_acc: 0.7913\n",
      "Epoch 90/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4248 - acc: 0.8033 - val_loss: 0.4347 - val_acc: 0.7900\n",
      "Epoch 91/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4260 - acc: 0.8033 - val_loss: 0.4343 - val_acc: 0.7893\n",
      "Epoch 92/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4254 - acc: 0.8064 - val_loss: 0.4341 - val_acc: 0.7954\n",
      "Epoch 93/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4230 - acc: 0.8053 - val_loss: 0.4338 - val_acc: 0.7907\n",
      "Epoch 94/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4222 - acc: 0.8039 - val_loss: 0.4329 - val_acc: 0.7940\n",
      "Epoch 95/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4252 - acc: 0.8035 - val_loss: 0.4324 - val_acc: 0.7940\n",
      "Epoch 96/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4240 - acc: 0.8049 - val_loss: 0.4326 - val_acc: 0.7947\n",
      "Epoch 97/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4235 - acc: 0.8048 - val_loss: 0.4322 - val_acc: 0.7900\n",
      "Epoch 98/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4213 - acc: 0.8070 - val_loss: 0.4317 - val_acc: 0.7907\n",
      "Epoch 99/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4241 - acc: 0.8048 - val_loss: 0.4311 - val_acc: 0.7981\n",
      "Epoch 100/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4221 - acc: 0.8057 - val_loss: 0.4310 - val_acc: 0.7940\n",
      "Epoch 101/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4205 - acc: 0.8059 - val_loss: 0.4311 - val_acc: 0.7907\n",
      "Epoch 102/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4194 - acc: 0.8067 - val_loss: 0.4301 - val_acc: 0.7954\n",
      "Epoch 103/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4183 - acc: 0.8089 - val_loss: 0.4297 - val_acc: 0.7961\n",
      "Epoch 104/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4202 - acc: 0.8083 - val_loss: 0.4297 - val_acc: 0.7913\n",
      "Epoch 105/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4189 - acc: 0.8051 - val_loss: 0.4294 - val_acc: 0.7927\n",
      "Epoch 106/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4171 - acc: 0.8101 - val_loss: 0.4288 - val_acc: 0.7961\n",
      "Epoch 107/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4168 - acc: 0.8075 - val_loss: 0.4287 - val_acc: 0.7961\n",
      "Epoch 108/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4178 - acc: 0.8062 - val_loss: 0.4282 - val_acc: 0.7961\n",
      "Epoch 109/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4185 - acc: 0.8090 - val_loss: 0.4280 - val_acc: 0.8001\n",
      "Epoch 110/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4196 - acc: 0.8057 - val_loss: 0.4283 - val_acc: 0.7927\n",
      "Epoch 111/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4176 - acc: 0.8083 - val_loss: 0.4279 - val_acc: 0.7920\n",
      "Epoch 112/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4164 - acc: 0.8096 - val_loss: 0.4275 - val_acc: 0.7967\n",
      "Epoch 113/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4179 - acc: 0.8089 - val_loss: 0.4273 - val_acc: 0.7981\n",
      "Epoch 114/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4145 - acc: 0.8133 - val_loss: 0.4268 - val_acc: 0.7940\n",
      "Epoch 115/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4164 - acc: 0.8081 - val_loss: 0.4268 - val_acc: 0.7940\n",
      "Epoch 116/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4153 - acc: 0.8082 - val_loss: 0.4265 - val_acc: 0.7947\n",
      "Epoch 117/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4148 - acc: 0.8091 - val_loss: 0.4262 - val_acc: 0.7954\n",
      "Epoch 118/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4153 - acc: 0.8101 - val_loss: 0.4263 - val_acc: 0.7940\n",
      "Epoch 119/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4137 - acc: 0.8077 - val_loss: 0.4260 - val_acc: 0.7920\n",
      "Epoch 120/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4140 - acc: 0.8101 - val_loss: 0.4254 - val_acc: 0.7947\n",
      "Epoch 121/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4139 - acc: 0.8108 - val_loss: 0.4247 - val_acc: 0.7954\n",
      "Epoch 122/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4140 - acc: 0.8096 - val_loss: 0.4247 - val_acc: 0.7974\n",
      "Epoch 123/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4130 - acc: 0.8094 - val_loss: 0.4241 - val_acc: 0.7967\n",
      "Epoch 124/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4135 - acc: 0.8111 - val_loss: 0.4240 - val_acc: 0.7967\n",
      "Epoch 125/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4143 - acc: 0.8113 - val_loss: 0.4239 - val_acc: 0.7940\n",
      "Epoch 126/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4107 - acc: 0.8114 - val_loss: 0.4234 - val_acc: 0.7974\n",
      "Epoch 127/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.4120 - acc: 0.8128 - val_loss: 0.4234 - val_acc: 0.7940\n",
      "Epoch 128/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.4106 - acc: 0.8104 - val_loss: 0.4234 - val_acc: 0.7947\n",
      "Epoch 129/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.4104 - acc: 0.8133 - val_loss: 0.4228 - val_acc: 0.7947\n",
      "Epoch 130/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4130 - acc: 0.8100 - val_loss: 0.4226 - val_acc: 0.7961\n",
      "Epoch 131/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4125 - acc: 0.8101 - val_loss: 0.4222 - val_acc: 0.7981\n",
      "Epoch 132/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4115 - acc: 0.8093 - val_loss: 0.4221 - val_acc: 0.7954\n",
      "Epoch 133/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4115 - acc: 0.8115 - val_loss: 0.4221 - val_acc: 0.7954\n",
      "Epoch 134/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4112 - acc: 0.8116 - val_loss: 0.4220 - val_acc: 0.7961\n",
      "Epoch 135/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4092 - acc: 0.8113 - val_loss: 0.4218 - val_acc: 0.7981\n",
      "Epoch 136/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4115 - acc: 0.8087 - val_loss: 0.4214 - val_acc: 0.7995\n",
      "Epoch 137/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4083 - acc: 0.8126 - val_loss: 0.4210 - val_acc: 0.7981\n",
      "Epoch 138/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4105 - acc: 0.8117 - val_loss: 0.4204 - val_acc: 0.8001\n",
      "Epoch 139/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4072 - acc: 0.8115 - val_loss: 0.4205 - val_acc: 0.7995\n",
      "Epoch 140/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4114 - acc: 0.8107 - val_loss: 0.4204 - val_acc: 0.7967\n",
      "Epoch 141/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4095 - acc: 0.8117 - val_loss: 0.4201 - val_acc: 0.8001\n",
      "Epoch 142/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4097 - acc: 0.8123 - val_loss: 0.4199 - val_acc: 0.7981\n",
      "Epoch 143/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4065 - acc: 0.8159 - val_loss: 0.4199 - val_acc: 0.7988\n",
      "Epoch 144/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.4078 - acc: 0.8115 - val_loss: 0.4202 - val_acc: 0.7967\n",
      "Epoch 145/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4093 - acc: 0.8095 - val_loss: 0.4193 - val_acc: 0.8022\n",
      "Epoch 146/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4072 - acc: 0.8123 - val_loss: 0.4194 - val_acc: 0.8001\n",
      "Epoch 147/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4103 - acc: 0.8107 - val_loss: 0.4189 - val_acc: 0.8008\n",
      "Epoch 148/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4054 - acc: 0.8147 - val_loss: 0.4190 - val_acc: 0.8008\n",
      "Epoch 149/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4061 - acc: 0.8143 - val_loss: 0.4190 - val_acc: 0.7995\n",
      "Epoch 150/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4073 - acc: 0.8135 - val_loss: 0.4189 - val_acc: 0.7995\n",
      "Epoch 151/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4069 - acc: 0.8142 - val_loss: 0.4183 - val_acc: 0.8015\n",
      "Epoch 152/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4047 - acc: 0.8148 - val_loss: 0.4181 - val_acc: 0.8001\n",
      "Epoch 153/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4054 - acc: 0.8143 - val_loss: 0.4179 - val_acc: 0.7988\n",
      "Epoch 154/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4040 - acc: 0.8120 - val_loss: 0.4177 - val_acc: 0.7981\n",
      "Epoch 155/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.4042 - acc: 0.8165 - val_loss: 0.4176 - val_acc: 0.7981\n",
      "Epoch 156/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4053 - acc: 0.8152 - val_loss: 0.4171 - val_acc: 0.8008\n",
      "Epoch 157/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4064 - acc: 0.8132 - val_loss: 0.4170 - val_acc: 0.7995\n",
      "Epoch 158/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4056 - acc: 0.8147 - val_loss: 0.4171 - val_acc: 0.8008\n",
      "Epoch 159/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4026 - acc: 0.8137 - val_loss: 0.4169 - val_acc: 0.8008\n",
      "Epoch 160/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4042 - acc: 0.8162 - val_loss: 0.4165 - val_acc: 0.8001\n",
      "Epoch 161/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4037 - acc: 0.8132 - val_loss: 0.4161 - val_acc: 0.7995\n",
      "Epoch 162/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4050 - acc: 0.8162 - val_loss: 0.4162 - val_acc: 0.8008\n",
      "Epoch 163/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4048 - acc: 0.8144 - val_loss: 0.4158 - val_acc: 0.8015\n",
      "Epoch 164/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4018 - acc: 0.8132 - val_loss: 0.4154 - val_acc: 0.8028\n",
      "Epoch 165/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4041 - acc: 0.8173 - val_loss: 0.4154 - val_acc: 0.8022\n",
      "Epoch 166/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4036 - acc: 0.8138 - val_loss: 0.4151 - val_acc: 0.8042\n",
      "Epoch 167/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4040 - acc: 0.8117 - val_loss: 0.4149 - val_acc: 0.8042\n",
      "Epoch 168/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3998 - acc: 0.8198 - val_loss: 0.4148 - val_acc: 0.8049\n",
      "Epoch 169/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4016 - acc: 0.8137 - val_loss: 0.4149 - val_acc: 0.8049\n",
      "Epoch 170/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4023 - acc: 0.8168 - val_loss: 0.4147 - val_acc: 0.8022\n",
      "Epoch 171/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4021 - acc: 0.8168 - val_loss: 0.4144 - val_acc: 0.8022\n",
      "Epoch 172/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4015 - acc: 0.8174 - val_loss: 0.4139 - val_acc: 0.8028\n",
      "Epoch 173/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3990 - acc: 0.8174 - val_loss: 0.4143 - val_acc: 0.8022\n",
      "Epoch 174/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4021 - acc: 0.8178 - val_loss: 0.4136 - val_acc: 0.8056\n",
      "Epoch 175/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3996 - acc: 0.8167 - val_loss: 0.4137 - val_acc: 0.8008\n",
      "Epoch 176/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.4014 - acc: 0.8141 - val_loss: 0.4133 - val_acc: 0.8049\n",
      "Epoch 177/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.4011 - acc: 0.8165 - val_loss: 0.4132 - val_acc: 0.8028\n",
      "Epoch 178/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.4004 - acc: 0.8160 - val_loss: 0.4134 - val_acc: 0.8049\n",
      "Epoch 179/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3982 - acc: 0.8177 - val_loss: 0.4127 - val_acc: 0.8049\n",
      "Epoch 180/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4011 - acc: 0.8176 - val_loss: 0.4127 - val_acc: 0.8062\n",
      "Epoch 181/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3988 - acc: 0.8178 - val_loss: 0.4124 - val_acc: 0.8069\n",
      "Epoch 182/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.4001 - acc: 0.8167 - val_loss: 0.4120 - val_acc: 0.8069\n",
      "Epoch 183/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3983 - acc: 0.8191 - val_loss: 0.4119 - val_acc: 0.8069\n",
      "Epoch 184/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3980 - acc: 0.8181 - val_loss: 0.4118 - val_acc: 0.8083\n",
      "Epoch 185/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3989 - acc: 0.8176 - val_loss: 0.4121 - val_acc: 0.8076\n",
      "Epoch 186/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3964 - acc: 0.8197 - val_loss: 0.4123 - val_acc: 0.8056\n",
      "Epoch 187/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3988 - acc: 0.8189 - val_loss: 0.4118 - val_acc: 0.8083\n",
      "Epoch 188/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3974 - acc: 0.8171 - val_loss: 0.4117 - val_acc: 0.8089\n",
      "Epoch 189/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3989 - acc: 0.8174 - val_loss: 0.4124 - val_acc: 0.8049\n",
      "Epoch 190/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3956 - acc: 0.8171 - val_loss: 0.4114 - val_acc: 0.8089\n",
      "Epoch 191/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3988 - acc: 0.8194 - val_loss: 0.4114 - val_acc: 0.8089\n",
      "Epoch 192/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3986 - acc: 0.8190 - val_loss: 0.4107 - val_acc: 0.8089\n",
      "Epoch 193/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3972 - acc: 0.8179 - val_loss: 0.4107 - val_acc: 0.8096\n",
      "Epoch 194/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3959 - acc: 0.8194 - val_loss: 0.4103 - val_acc: 0.8069\n",
      "Epoch 195/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3964 - acc: 0.8153 - val_loss: 0.4103 - val_acc: 0.8069\n",
      "Epoch 196/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3973 - acc: 0.8178 - val_loss: 0.4101 - val_acc: 0.8076\n",
      "Epoch 197/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3957 - acc: 0.8177 - val_loss: 0.4102 - val_acc: 0.8096\n",
      "Epoch 198/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3942 - acc: 0.8206 - val_loss: 0.4101 - val_acc: 0.8117\n",
      "Epoch 199/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3940 - acc: 0.8198 - val_loss: 0.4098 - val_acc: 0.8096\n",
      "Epoch 200/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3926 - acc: 0.8187 - val_loss: 0.4100 - val_acc: 0.8123\n",
      "Epoch 201/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3954 - acc: 0.8188 - val_loss: 0.4098 - val_acc: 0.8110\n",
      "Epoch 202/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3928 - acc: 0.8220 - val_loss: 0.4098 - val_acc: 0.8096\n",
      "Epoch 203/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3940 - acc: 0.8214 - val_loss: 0.4093 - val_acc: 0.8076\n",
      "Epoch 204/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3938 - acc: 0.8199 - val_loss: 0.4090 - val_acc: 0.8089\n",
      "Epoch 205/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3942 - acc: 0.8196 - val_loss: 0.4088 - val_acc: 0.8096\n",
      "Epoch 206/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3947 - acc: 0.8180 - val_loss: 0.4089 - val_acc: 0.8089\n",
      "Epoch 207/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3918 - acc: 0.8228 - val_loss: 0.4087 - val_acc: 0.8110\n",
      "Epoch 208/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3949 - acc: 0.8179 - val_loss: 0.4086 - val_acc: 0.8083\n",
      "Epoch 209/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3929 - acc: 0.8220 - val_loss: 0.4086 - val_acc: 0.8110\n",
      "Epoch 210/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3946 - acc: 0.8211 - val_loss: 0.4083 - val_acc: 0.8110\n",
      "Epoch 211/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3897 - acc: 0.8205 - val_loss: 0.4082 - val_acc: 0.8096\n",
      "Epoch 212/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3932 - acc: 0.8190 - val_loss: 0.4079 - val_acc: 0.8103\n",
      "Epoch 213/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3933 - acc: 0.8212 - val_loss: 0.4077 - val_acc: 0.8103\n",
      "Epoch 214/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3931 - acc: 0.8236 - val_loss: 0.4079 - val_acc: 0.8096\n",
      "Epoch 215/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3918 - acc: 0.8222 - val_loss: 0.4074 - val_acc: 0.8083\n",
      "Epoch 216/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3955 - acc: 0.8186 - val_loss: 0.4071 - val_acc: 0.8089\n",
      "Epoch 217/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3925 - acc: 0.8207 - val_loss: 0.4073 - val_acc: 0.8083\n",
      "Epoch 218/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3915 - acc: 0.8182 - val_loss: 0.4072 - val_acc: 0.8123\n",
      "Epoch 219/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3931 - acc: 0.8186 - val_loss: 0.4069 - val_acc: 0.8123\n",
      "Epoch 220/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3900 - acc: 0.8218 - val_loss: 0.4071 - val_acc: 0.8076\n",
      "Epoch 221/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3919 - acc: 0.8188 - val_loss: 0.4067 - val_acc: 0.8076\n",
      "Epoch 222/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3911 - acc: 0.8213 - val_loss: 0.4071 - val_acc: 0.8083\n",
      "Epoch 223/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3924 - acc: 0.8205 - val_loss: 0.4063 - val_acc: 0.8117\n",
      "Epoch 224/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3913 - acc: 0.8178 - val_loss: 0.4064 - val_acc: 0.8096\n",
      "Epoch 225/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3903 - acc: 0.8214 - val_loss: 0.4063 - val_acc: 0.8096\n",
      "Epoch 226/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3881 - acc: 0.8238 - val_loss: 0.4057 - val_acc: 0.8123\n",
      "Epoch 227/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3887 - acc: 0.8231 - val_loss: 0.4058 - val_acc: 0.8083\n",
      "Epoch 228/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3923 - acc: 0.8193 - val_loss: 0.4059 - val_acc: 0.8089\n",
      "Epoch 229/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3893 - acc: 0.8223 - val_loss: 0.4057 - val_acc: 0.8089\n",
      "Epoch 230/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3891 - acc: 0.8211 - val_loss: 0.4060 - val_acc: 0.8103\n",
      "Epoch 231/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3894 - acc: 0.8212 - val_loss: 0.4057 - val_acc: 0.8089\n",
      "Epoch 232/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3892 - acc: 0.8226 - val_loss: 0.4050 - val_acc: 0.8123\n",
      "Epoch 233/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3901 - acc: 0.8218 - val_loss: 0.4047 - val_acc: 0.8103\n",
      "Epoch 234/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3896 - acc: 0.8221 - val_loss: 0.4051 - val_acc: 0.8089\n",
      "Epoch 235/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3897 - acc: 0.8237 - val_loss: 0.4044 - val_acc: 0.8089\n",
      "Epoch 236/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3893 - acc: 0.8211 - val_loss: 0.4045 - val_acc: 0.8089\n",
      "Epoch 237/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3874 - acc: 0.8251 - val_loss: 0.4045 - val_acc: 0.8089\n",
      "Epoch 238/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3896 - acc: 0.8229 - val_loss: 0.4041 - val_acc: 0.8096\n",
      "Epoch 239/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3879 - acc: 0.8224 - val_loss: 0.4039 - val_acc: 0.8123\n",
      "Epoch 240/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3888 - acc: 0.8228 - val_loss: 0.4042 - val_acc: 0.8089\n",
      "Epoch 241/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3893 - acc: 0.8209 - val_loss: 0.4041 - val_acc: 0.8117\n",
      "Epoch 242/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3878 - acc: 0.8236 - val_loss: 0.4044 - val_acc: 0.8083\n",
      "Epoch 243/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3889 - acc: 0.8254 - val_loss: 0.4036 - val_acc: 0.8117\n",
      "Epoch 244/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3851 - acc: 0.8219 - val_loss: 0.4039 - val_acc: 0.8130\n",
      "Epoch 245/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3884 - acc: 0.8250 - val_loss: 0.4035 - val_acc: 0.8110\n",
      "Epoch 246/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3845 - acc: 0.8235 - val_loss: 0.4029 - val_acc: 0.8150\n",
      "Epoch 247/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3861 - acc: 0.8241 - val_loss: 0.4031 - val_acc: 0.8110\n",
      "Epoch 248/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3869 - acc: 0.8239 - val_loss: 0.4033 - val_acc: 0.8103\n",
      "Epoch 249/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3864 - acc: 0.8236 - val_loss: 0.4031 - val_acc: 0.8144\n",
      "Epoch 250/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3865 - acc: 0.8250 - val_loss: 0.4028 - val_acc: 0.8117\n",
      "Epoch 251/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3876 - acc: 0.8251 - val_loss: 0.4025 - val_acc: 0.8137\n",
      "Epoch 252/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3863 - acc: 0.8243 - val_loss: 0.4024 - val_acc: 0.8096\n",
      "Epoch 253/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3857 - acc: 0.8245 - val_loss: 0.4028 - val_acc: 0.8110\n",
      "Epoch 254/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3867 - acc: 0.8232 - val_loss: 0.4022 - val_acc: 0.8110\n",
      "Epoch 255/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3841 - acc: 0.8268 - val_loss: 0.4019 - val_acc: 0.8096\n",
      "Epoch 256/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3822 - acc: 0.8259 - val_loss: 0.4016 - val_acc: 0.8117\n",
      "Epoch 257/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3853 - acc: 0.8265 - val_loss: 0.4018 - val_acc: 0.8076\n",
      "Epoch 258/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3853 - acc: 0.8250 - val_loss: 0.4014 - val_acc: 0.8103\n",
      "Epoch 259/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3839 - acc: 0.8251 - val_loss: 0.4018 - val_acc: 0.8123\n",
      "Epoch 260/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3854 - acc: 0.8267 - val_loss: 0.4014 - val_acc: 0.8110\n",
      "Epoch 261/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3851 - acc: 0.8241 - val_loss: 0.4010 - val_acc: 0.8110\n",
      "Epoch 262/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3827 - acc: 0.8269 - val_loss: 0.4008 - val_acc: 0.8110\n",
      "Epoch 263/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3842 - acc: 0.8247 - val_loss: 0.4007 - val_acc: 0.8117\n",
      "Epoch 264/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3825 - acc: 0.8251 - val_loss: 0.4003 - val_acc: 0.8089\n",
      "Epoch 265/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3823 - acc: 0.8259 - val_loss: 0.4007 - val_acc: 0.8096\n",
      "Epoch 266/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3840 - acc: 0.8246 - val_loss: 0.4002 - val_acc: 0.8103\n",
      "Epoch 267/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3811 - acc: 0.8269 - val_loss: 0.4004 - val_acc: 0.8089\n",
      "Epoch 268/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3824 - acc: 0.8263 - val_loss: 0.4002 - val_acc: 0.8103\n",
      "Epoch 269/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3841 - acc: 0.8274 - val_loss: 0.3996 - val_acc: 0.8123\n",
      "Epoch 270/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3806 - acc: 0.8272 - val_loss: 0.3994 - val_acc: 0.8123\n",
      "Epoch 271/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3825 - acc: 0.8270 - val_loss: 0.3997 - val_acc: 0.8117\n",
      "Epoch 272/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3810 - acc: 0.8278 - val_loss: 0.3993 - val_acc: 0.8110\n",
      "Epoch 273/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3845 - acc: 0.8257 - val_loss: 0.3989 - val_acc: 0.8083\n",
      "Epoch 274/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3847 - acc: 0.8232 - val_loss: 0.3989 - val_acc: 0.8117\n",
      "Epoch 275/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3816 - acc: 0.8260 - val_loss: 0.3986 - val_acc: 0.8117\n",
      "Epoch 276/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3802 - acc: 0.8280 - val_loss: 0.3989 - val_acc: 0.8123\n",
      "Epoch 277/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3783 - acc: 0.8286 - val_loss: 0.3985 - val_acc: 0.8103\n",
      "Epoch 278/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3805 - acc: 0.8252 - val_loss: 0.3985 - val_acc: 0.8096\n",
      "Epoch 279/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3794 - acc: 0.8283 - val_loss: 0.3987 - val_acc: 0.8117\n",
      "Epoch 280/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3790 - acc: 0.8284 - val_loss: 0.3985 - val_acc: 0.8123\n",
      "Epoch 281/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3796 - acc: 0.8272 - val_loss: 0.3983 - val_acc: 0.8103\n",
      "Epoch 282/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3808 - acc: 0.8290 - val_loss: 0.3981 - val_acc: 0.8103\n",
      "Epoch 283/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3794 - acc: 0.8261 - val_loss: 0.3979 - val_acc: 0.8144\n",
      "Epoch 284/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3798 - acc: 0.8263 - val_loss: 0.3976 - val_acc: 0.8103\n",
      "Epoch 285/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3834 - acc: 0.8252 - val_loss: 0.3975 - val_acc: 0.8144\n",
      "Epoch 286/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3799 - acc: 0.8294 - val_loss: 0.3974 - val_acc: 0.8117\n",
      "Epoch 287/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3797 - acc: 0.8254 - val_loss: 0.3972 - val_acc: 0.8110\n",
      "Epoch 288/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3800 - acc: 0.8289 - val_loss: 0.3970 - val_acc: 0.8130\n",
      "Epoch 289/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3799 - acc: 0.8255 - val_loss: 0.3967 - val_acc: 0.8123\n",
      "Epoch 290/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3791 - acc: 0.8259 - val_loss: 0.3962 - val_acc: 0.8150\n",
      "Epoch 291/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3773 - acc: 0.8299 - val_loss: 0.3966 - val_acc: 0.8144\n",
      "Epoch 292/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3777 - acc: 0.8303 - val_loss: 0.3967 - val_acc: 0.8137\n",
      "Epoch 293/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3780 - acc: 0.8272 - val_loss: 0.3967 - val_acc: 0.8117\n",
      "Epoch 294/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.3758 - acc: 0.8314 - val_loss: 0.3961 - val_acc: 0.8150\n",
      "Epoch 295/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3779 - acc: 0.8300 - val_loss: 0.3959 - val_acc: 0.8171\n",
      "Epoch 296/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3774 - acc: 0.8287 - val_loss: 0.3966 - val_acc: 0.8137\n",
      "Epoch 297/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3772 - acc: 0.8290 - val_loss: 0.3962 - val_acc: 0.8123\n",
      "Epoch 298/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3793 - acc: 0.8287 - val_loss: 0.3956 - val_acc: 0.8130\n",
      "Epoch 299/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3796 - acc: 0.8277 - val_loss: 0.3954 - val_acc: 0.8157\n",
      "Epoch 300/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3772 - acc: 0.8294 - val_loss: 0.3953 - val_acc: 0.8157\n",
      "Epoch 301/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3778 - acc: 0.8305 - val_loss: 0.3950 - val_acc: 0.8164\n",
      "Epoch 302/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3790 - acc: 0.8269 - val_loss: 0.3953 - val_acc: 0.8130\n",
      "Epoch 303/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3776 - acc: 0.8261 - val_loss: 0.3949 - val_acc: 0.8164\n",
      "Epoch 304/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3770 - acc: 0.8266 - val_loss: 0.3947 - val_acc: 0.8137\n",
      "Epoch 305/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3764 - acc: 0.8324 - val_loss: 0.3947 - val_acc: 0.8157\n",
      "Epoch 306/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3764 - acc: 0.8299 - val_loss: 0.3950 - val_acc: 0.8150\n",
      "Epoch 307/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3779 - acc: 0.8299 - val_loss: 0.3948 - val_acc: 0.8171\n",
      "Epoch 308/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3782 - acc: 0.8276 - val_loss: 0.3947 - val_acc: 0.8150\n",
      "Epoch 309/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3760 - acc: 0.8281 - val_loss: 0.3944 - val_acc: 0.8150\n",
      "Epoch 310/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3745 - acc: 0.8341 - val_loss: 0.3944 - val_acc: 0.8150\n",
      "Epoch 311/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3765 - acc: 0.8309 - val_loss: 0.3942 - val_acc: 0.8171\n",
      "Epoch 312/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3778 - acc: 0.8309 - val_loss: 0.3941 - val_acc: 0.8184\n",
      "Epoch 313/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3749 - acc: 0.8311 - val_loss: 0.3936 - val_acc: 0.8191\n",
      "Epoch 314/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3768 - acc: 0.8287 - val_loss: 0.3939 - val_acc: 0.8184\n",
      "Epoch 315/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3761 - acc: 0.8327 - val_loss: 0.3938 - val_acc: 0.8164\n",
      "Epoch 316/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3740 - acc: 0.8318 - val_loss: 0.3937 - val_acc: 0.8130\n",
      "Epoch 317/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3766 - acc: 0.8296 - val_loss: 0.3937 - val_acc: 0.8144\n",
      "Epoch 318/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3748 - acc: 0.8293 - val_loss: 0.3937 - val_acc: 0.8164\n",
      "Epoch 319/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3733 - acc: 0.8302 - val_loss: 0.3934 - val_acc: 0.8184\n",
      "Epoch 320/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3751 - acc: 0.8321 - val_loss: 0.3930 - val_acc: 0.8150\n",
      "Epoch 321/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3757 - acc: 0.8307 - val_loss: 0.3929 - val_acc: 0.8211\n",
      "Epoch 322/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3730 - acc: 0.8319 - val_loss: 0.3929 - val_acc: 0.8211\n",
      "Epoch 323/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3743 - acc: 0.8308 - val_loss: 0.3925 - val_acc: 0.8191\n",
      "Epoch 324/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3755 - acc: 0.8289 - val_loss: 0.3929 - val_acc: 0.8211\n",
      "Epoch 325/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3742 - acc: 0.8306 - val_loss: 0.3922 - val_acc: 0.8211\n",
      "Epoch 326/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3727 - acc: 0.8336 - val_loss: 0.3922 - val_acc: 0.8205\n",
      "Epoch 327/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3726 - acc: 0.8339 - val_loss: 0.3920 - val_acc: 0.8171\n",
      "Epoch 328/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3728 - acc: 0.8327 - val_loss: 0.3920 - val_acc: 0.8191\n",
      "Epoch 329/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3740 - acc: 0.8312 - val_loss: 0.3919 - val_acc: 0.8211\n",
      "Epoch 330/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3744 - acc: 0.8298 - val_loss: 0.3921 - val_acc: 0.8171\n",
      "Epoch 331/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3725 - acc: 0.8329 - val_loss: 0.3916 - val_acc: 0.8198\n",
      "Epoch 332/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3733 - acc: 0.8304 - val_loss: 0.3915 - val_acc: 0.8205\n",
      "Epoch 333/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3720 - acc: 0.8335 - val_loss: 0.3921 - val_acc: 0.8191\n",
      "Epoch 334/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3732 - acc: 0.8326 - val_loss: 0.3916 - val_acc: 0.8211\n",
      "Epoch 335/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3723 - acc: 0.8318 - val_loss: 0.3912 - val_acc: 0.8198\n",
      "Epoch 336/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3715 - acc: 0.8350 - val_loss: 0.3914 - val_acc: 0.8184\n",
      "Epoch 337/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3729 - acc: 0.8338 - val_loss: 0.3912 - val_acc: 0.8191\n",
      "Epoch 338/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3724 - acc: 0.8330 - val_loss: 0.3910 - val_acc: 0.8198\n",
      "Epoch 339/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3731 - acc: 0.8326 - val_loss: 0.3907 - val_acc: 0.8198\n",
      "Epoch 340/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3720 - acc: 0.8334 - val_loss: 0.3907 - val_acc: 0.8211\n",
      "Epoch 341/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3712 - acc: 0.8352 - val_loss: 0.3908 - val_acc: 0.8178\n",
      "Epoch 342/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3704 - acc: 0.8360 - val_loss: 0.3908 - val_acc: 0.8198\n",
      "Epoch 343/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3685 - acc: 0.8375 - val_loss: 0.3905 - val_acc: 0.8184\n",
      "Epoch 344/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3690 - acc: 0.8351 - val_loss: 0.3903 - val_acc: 0.8205\n",
      "Epoch 345/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3724 - acc: 0.8324 - val_loss: 0.3901 - val_acc: 0.8198\n",
      "Epoch 346/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3708 - acc: 0.8332 - val_loss: 0.3900 - val_acc: 0.8205\n",
      "Epoch 347/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3721 - acc: 0.8326 - val_loss: 0.3897 - val_acc: 0.8205\n",
      "Epoch 348/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3691 - acc: 0.8347 - val_loss: 0.3898 - val_acc: 0.8178\n",
      "Epoch 349/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3690 - acc: 0.8358 - val_loss: 0.3894 - val_acc: 0.8198\n",
      "Epoch 350/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3725 - acc: 0.8312 - val_loss: 0.3894 - val_acc: 0.8205\n",
      "Epoch 351/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3701 - acc: 0.8370 - val_loss: 0.3895 - val_acc: 0.8191\n",
      "Epoch 352/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3713 - acc: 0.8333 - val_loss: 0.3897 - val_acc: 0.8184\n",
      "Epoch 353/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3723 - acc: 0.8312 - val_loss: 0.3890 - val_acc: 0.8191\n",
      "Epoch 354/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3694 - acc: 0.8340 - val_loss: 0.3893 - val_acc: 0.8191\n",
      "Epoch 355/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3719 - acc: 0.8348 - val_loss: 0.3890 - val_acc: 0.8198\n",
      "Epoch 356/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3730 - acc: 0.8313 - val_loss: 0.3890 - val_acc: 0.8184\n",
      "Epoch 357/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3696 - acc: 0.8346 - val_loss: 0.3886 - val_acc: 0.8191\n",
      "Epoch 358/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3697 - acc: 0.8362 - val_loss: 0.3890 - val_acc: 0.8178\n",
      "Epoch 359/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3674 - acc: 0.8349 - val_loss: 0.3885 - val_acc: 0.8184\n",
      "Epoch 360/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3682 - acc: 0.8348 - val_loss: 0.3887 - val_acc: 0.8178\n",
      "Epoch 361/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3698 - acc: 0.8357 - val_loss: 0.3881 - val_acc: 0.8225\n",
      "Epoch 362/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3698 - acc: 0.8354 - val_loss: 0.3886 - val_acc: 0.8225\n",
      "Epoch 363/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3690 - acc: 0.8352 - val_loss: 0.3883 - val_acc: 0.8238\n",
      "Epoch 364/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3684 - acc: 0.8330 - val_loss: 0.3883 - val_acc: 0.8205\n",
      "Epoch 365/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3696 - acc: 0.8355 - val_loss: 0.3880 - val_acc: 0.8225\n",
      "Epoch 366/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3707 - acc: 0.8312 - val_loss: 0.3884 - val_acc: 0.8205\n",
      "Epoch 367/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3683 - acc: 0.8357 - val_loss: 0.3883 - val_acc: 0.8198\n",
      "Epoch 368/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3646 - acc: 0.8348 - val_loss: 0.3880 - val_acc: 0.8198\n",
      "Epoch 369/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3671 - acc: 0.8355 - val_loss: 0.3876 - val_acc: 0.8218\n",
      "Epoch 370/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3678 - acc: 0.8352 - val_loss: 0.3875 - val_acc: 0.8211\n",
      "Epoch 371/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3698 - acc: 0.8323 - val_loss: 0.3878 - val_acc: 0.8198\n",
      "Epoch 372/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3673 - acc: 0.8369 - val_loss: 0.3871 - val_acc: 0.8252\n",
      "Epoch 373/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3658 - acc: 0.8354 - val_loss: 0.3871 - val_acc: 0.8232\n",
      "Epoch 374/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3697 - acc: 0.8348 - val_loss: 0.3873 - val_acc: 0.8225\n",
      "Epoch 375/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3662 - acc: 0.8364 - val_loss: 0.3874 - val_acc: 0.8225\n",
      "Epoch 376/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3650 - acc: 0.8367 - val_loss: 0.3879 - val_acc: 0.8191\n",
      "Epoch 377/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.3656 - acc: 0.836 - 0s 27us/sample - loss: 0.3650 - acc: 0.8372 - val_loss: 0.3873 - val_acc: 0.8211\n",
      "Epoch 378/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.3626 - acc: 0.839 - 0s 27us/sample - loss: 0.3636 - acc: 0.8385 - val_loss: 0.3869 - val_acc: 0.8225\n",
      "Epoch 379/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3691 - acc: 0.8330 - val_loss: 0.3871 - val_acc: 0.8232\n",
      "Epoch 380/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3654 - acc: 0.8354 - val_loss: 0.3867 - val_acc: 0.8238\n",
      "Epoch 381/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3637 - acc: 0.8401 - val_loss: 0.3867 - val_acc: 0.8184\n",
      "Epoch 382/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3662 - acc: 0.8352 - val_loss: 0.3864 - val_acc: 0.8205\n",
      "Epoch 383/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3663 - acc: 0.8343 - val_loss: 0.3864 - val_acc: 0.8245\n",
      "Epoch 384/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3654 - acc: 0.8364 - val_loss: 0.3867 - val_acc: 0.8218\n",
      "Epoch 385/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3660 - acc: 0.8372 - val_loss: 0.3861 - val_acc: 0.8232\n",
      "Epoch 386/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3632 - acc: 0.8379 - val_loss: 0.3864 - val_acc: 0.8211\n",
      "Epoch 387/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3659 - acc: 0.8369 - val_loss: 0.3859 - val_acc: 0.8205\n",
      "Epoch 388/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3630 - acc: 0.8380 - val_loss: 0.3859 - val_acc: 0.8211\n",
      "Epoch 389/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3631 - acc: 0.8391 - val_loss: 0.3857 - val_acc: 0.8225\n",
      "Epoch 390/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3650 - acc: 0.8379 - val_loss: 0.3856 - val_acc: 0.8252\n",
      "Epoch 391/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3636 - acc: 0.8364 - val_loss: 0.3857 - val_acc: 0.8238\n",
      "Epoch 392/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3616 - acc: 0.8390 - val_loss: 0.3855 - val_acc: 0.8225\n",
      "Epoch 393/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3660 - acc: 0.8348 - val_loss: 0.3852 - val_acc: 0.8259\n",
      "Epoch 394/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3631 - acc: 0.8371 - val_loss: 0.3856 - val_acc: 0.8225\n",
      "Epoch 395/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3656 - acc: 0.8366 - val_loss: 0.3854 - val_acc: 0.8238\n",
      "Epoch 396/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3628 - acc: 0.8394 - val_loss: 0.3851 - val_acc: 0.8232\n",
      "Epoch 397/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3663 - acc: 0.8356 - val_loss: 0.3852 - val_acc: 0.8232\n",
      "Epoch 398/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3667 - acc: 0.8372 - val_loss: 0.3855 - val_acc: 0.8238\n",
      "Epoch 399/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3649 - acc: 0.8366 - val_loss: 0.3847 - val_acc: 0.8238\n",
      "Epoch 400/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3622 - acc: 0.8388 - val_loss: 0.3848 - val_acc: 0.8218\n",
      "Epoch 401/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3646 - acc: 0.8375 - val_loss: 0.3846 - val_acc: 0.8259\n",
      "Epoch 402/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3633 - acc: 0.8382 - val_loss: 0.3847 - val_acc: 0.8238\n",
      "Epoch 403/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3627 - acc: 0.8375 - val_loss: 0.3847 - val_acc: 0.8238\n",
      "Epoch 404/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3621 - acc: 0.8392 - val_loss: 0.3845 - val_acc: 0.8238\n",
      "Epoch 405/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3643 - acc: 0.8382 - val_loss: 0.3850 - val_acc: 0.8205\n",
      "Epoch 406/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3642 - acc: 0.8406 - val_loss: 0.3842 - val_acc: 0.8245\n",
      "Epoch 407/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3616 - acc: 0.8409 - val_loss: 0.3846 - val_acc: 0.8232\n",
      "Epoch 408/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3650 - acc: 0.8390 - val_loss: 0.3841 - val_acc: 0.8279\n",
      "Epoch 409/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3633 - acc: 0.8363 - val_loss: 0.3843 - val_acc: 0.8211\n",
      "Epoch 410/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3624 - acc: 0.8367 - val_loss: 0.3842 - val_acc: 0.8238\n",
      "Epoch 411/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3605 - acc: 0.8383 - val_loss: 0.3848 - val_acc: 0.8205\n",
      "Epoch 412/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3598 - acc: 0.8406 - val_loss: 0.3836 - val_acc: 0.8245\n",
      "Epoch 413/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3601 - acc: 0.8420 - val_loss: 0.3837 - val_acc: 0.8245\n",
      "Epoch 414/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3631 - acc: 0.8400 - val_loss: 0.3836 - val_acc: 0.8252\n",
      "Epoch 415/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3593 - acc: 0.8384 - val_loss: 0.3841 - val_acc: 0.8232\n",
      "Epoch 416/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3605 - acc: 0.8402 - val_loss: 0.3836 - val_acc: 0.8286\n",
      "Epoch 417/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3626 - acc: 0.8379 - val_loss: 0.3837 - val_acc: 0.8279\n",
      "Epoch 418/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3628 - acc: 0.8387 - val_loss: 0.3835 - val_acc: 0.8238\n",
      "Epoch 419/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3625 - acc: 0.8355 - val_loss: 0.3834 - val_acc: 0.8286\n",
      "Epoch 420/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3608 - acc: 0.8392 - val_loss: 0.3838 - val_acc: 0.8238\n",
      "Epoch 421/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3605 - acc: 0.8404 - val_loss: 0.3833 - val_acc: 0.8245\n",
      "Epoch 422/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3615 - acc: 0.8390 - val_loss: 0.3833 - val_acc: 0.8293\n",
      "Epoch 423/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3582 - acc: 0.8411 - val_loss: 0.3835 - val_acc: 0.8238\n",
      "Epoch 424/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3590 - acc: 0.8422 - val_loss: 0.3832 - val_acc: 0.8252\n",
      "Epoch 425/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3618 - acc: 0.8363 - val_loss: 0.3827 - val_acc: 0.8245\n",
      "Epoch 426/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3604 - acc: 0.8402 - val_loss: 0.3832 - val_acc: 0.8232\n",
      "Epoch 427/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3610 - acc: 0.8374 - val_loss: 0.3828 - val_acc: 0.8259\n",
      "Epoch 428/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3599 - acc: 0.8391 - val_loss: 0.3827 - val_acc: 0.8293\n",
      "Epoch 429/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3605 - acc: 0.8400 - val_loss: 0.3828 - val_acc: 0.8286\n",
      "Epoch 430/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3612 - acc: 0.8388 - val_loss: 0.3826 - val_acc: 0.8293\n",
      "Epoch 431/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3574 - acc: 0.8403 - val_loss: 0.3823 - val_acc: 0.8286\n",
      "Epoch 432/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3620 - acc: 0.8372 - val_loss: 0.3824 - val_acc: 0.8245\n",
      "Epoch 433/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3584 - acc: 0.8420 - val_loss: 0.3822 - val_acc: 0.8266\n",
      "Epoch 434/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3572 - acc: 0.8424 - val_loss: 0.3824 - val_acc: 0.8272\n",
      "Epoch 435/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3600 - acc: 0.8422 - val_loss: 0.3821 - val_acc: 0.8259\n",
      "Epoch 436/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3591 - acc: 0.8413 - val_loss: 0.3816 - val_acc: 0.8279\n",
      "Epoch 437/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3600 - acc: 0.8402 - val_loss: 0.3814 - val_acc: 0.8327\n",
      "Epoch 438/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3590 - acc: 0.8400 - val_loss: 0.3827 - val_acc: 0.8286\n",
      "Epoch 439/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3597 - acc: 0.8378 - val_loss: 0.3818 - val_acc: 0.8293\n",
      "Epoch 440/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3584 - acc: 0.8412 - val_loss: 0.3816 - val_acc: 0.8266\n",
      "Epoch 441/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3590 - acc: 0.8400 - val_loss: 0.3821 - val_acc: 0.8272\n",
      "Epoch 442/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3606 - acc: 0.8390 - val_loss: 0.3815 - val_acc: 0.8306\n",
      "Epoch 443/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3593 - acc: 0.8424 - val_loss: 0.3814 - val_acc: 0.8279\n",
      "Epoch 444/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3562 - acc: 0.8428 - val_loss: 0.3811 - val_acc: 0.8320\n",
      "Epoch 445/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3600 - acc: 0.8386 - val_loss: 0.3809 - val_acc: 0.8299\n",
      "Epoch 446/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3584 - acc: 0.8385 - val_loss: 0.3812 - val_acc: 0.8293\n",
      "Epoch 447/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3575 - acc: 0.8403 - val_loss: 0.3811 - val_acc: 0.8306\n",
      "Epoch 448/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3587 - acc: 0.8427 - val_loss: 0.3811 - val_acc: 0.8286\n",
      "Epoch 449/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3573 - acc: 0.8418 - val_loss: 0.3811 - val_acc: 0.8306\n",
      "Epoch 450/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3593 - acc: 0.8412 - val_loss: 0.3810 - val_acc: 0.8320\n",
      "Epoch 451/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3588 - acc: 0.8403 - val_loss: 0.3807 - val_acc: 0.8313\n",
      "Epoch 452/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3574 - acc: 0.8391 - val_loss: 0.3805 - val_acc: 0.8299\n",
      "Epoch 453/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3574 - acc: 0.8391 - val_loss: 0.3804 - val_acc: 0.8279\n",
      "Epoch 454/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3559 - acc: 0.8404 - val_loss: 0.3814 - val_acc: 0.8293\n",
      "Epoch 455/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3594 - acc: 0.8403 - val_loss: 0.3805 - val_acc: 0.8306\n",
      "Epoch 456/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3561 - acc: 0.8433 - val_loss: 0.3806 - val_acc: 0.8306\n",
      "Epoch 457/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3585 - acc: 0.8418 - val_loss: 0.3806 - val_acc: 0.8306\n",
      "Epoch 458/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3563 - acc: 0.8430 - val_loss: 0.3804 - val_acc: 0.8299\n",
      "Epoch 459/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3564 - acc: 0.8441 - val_loss: 0.3802 - val_acc: 0.8286\n",
      "Epoch 460/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3565 - acc: 0.8430 - val_loss: 0.3800 - val_acc: 0.8299\n",
      "Epoch 461/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3576 - acc: 0.8407 - val_loss: 0.3798 - val_acc: 0.8306\n",
      "Epoch 462/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3570 - acc: 0.8405 - val_loss: 0.3802 - val_acc: 0.8299\n",
      "Epoch 463/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3576 - acc: 0.8403 - val_loss: 0.3801 - val_acc: 0.8299\n",
      "Epoch 464/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3568 - acc: 0.8411 - val_loss: 0.3798 - val_acc: 0.8333\n",
      "Epoch 465/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3577 - acc: 0.8424 - val_loss: 0.3798 - val_acc: 0.8327\n",
      "Epoch 466/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3563 - acc: 0.8436 - val_loss: 0.3792 - val_acc: 0.8320\n",
      "Epoch 467/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3580 - acc: 0.8409 - val_loss: 0.3792 - val_acc: 0.8327\n",
      "Epoch 468/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3548 - acc: 0.8427 - val_loss: 0.3800 - val_acc: 0.8313\n",
      "Epoch 469/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3555 - acc: 0.8438 - val_loss: 0.3798 - val_acc: 0.8320\n",
      "Epoch 470/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3567 - acc: 0.8418 - val_loss: 0.3798 - val_acc: 0.8306\n",
      "Epoch 471/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3541 - acc: 0.8414 - val_loss: 0.3795 - val_acc: 0.8327\n",
      "Epoch 472/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3542 - acc: 0.8424 - val_loss: 0.3792 - val_acc: 0.8320\n",
      "Epoch 473/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3544 - acc: 0.8445 - val_loss: 0.3787 - val_acc: 0.8306\n",
      "Epoch 474/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3552 - acc: 0.8440 - val_loss: 0.3794 - val_acc: 0.8306\n",
      "Epoch 475/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3558 - acc: 0.8399 - val_loss: 0.3788 - val_acc: 0.8313\n",
      "Epoch 476/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3535 - acc: 0.8437 - val_loss: 0.3791 - val_acc: 0.8340\n",
      "Epoch 477/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3528 - acc: 0.8455 - val_loss: 0.3790 - val_acc: 0.8299\n",
      "Epoch 478/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3551 - acc: 0.8467 - val_loss: 0.3787 - val_acc: 0.8286\n",
      "Epoch 479/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3552 - acc: 0.8453 - val_loss: 0.3790 - val_acc: 0.8320\n",
      "Epoch 480/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3556 - acc: 0.8418 - val_loss: 0.3789 - val_acc: 0.8320\n",
      "Epoch 481/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3548 - acc: 0.8436 - val_loss: 0.3785 - val_acc: 0.8327\n",
      "Epoch 482/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3521 - acc: 0.8444 - val_loss: 0.3789 - val_acc: 0.8293\n",
      "Epoch 483/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3566 - acc: 0.8434 - val_loss: 0.3788 - val_acc: 0.8299\n",
      "Epoch 484/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3565 - acc: 0.8427 - val_loss: 0.3791 - val_acc: 0.8306\n",
      "Epoch 485/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3512 - acc: 0.8446 - val_loss: 0.3784 - val_acc: 0.8299\n",
      "Epoch 486/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3541 - acc: 0.8437 - val_loss: 0.3789 - val_acc: 0.8293\n",
      "Epoch 487/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3515 - acc: 0.8460 - val_loss: 0.3789 - val_acc: 0.8293\n",
      "Epoch 488/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3511 - acc: 0.8460 - val_loss: 0.3779 - val_acc: 0.8313\n",
      "Epoch 489/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3539 - acc: 0.8458 - val_loss: 0.3783 - val_acc: 0.8293\n",
      "Epoch 490/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3531 - acc: 0.8434 - val_loss: 0.3784 - val_acc: 0.8299\n",
      "Epoch 491/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3542 - acc: 0.8438 - val_loss: 0.3782 - val_acc: 0.8313\n",
      "Epoch 492/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3526 - acc: 0.8436 - val_loss: 0.3784 - val_acc: 0.8320\n",
      "Epoch 493/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3557 - acc: 0.8402 - val_loss: 0.3779 - val_acc: 0.8299\n",
      "Epoch 494/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3535 - acc: 0.8452 - val_loss: 0.3778 - val_acc: 0.8299\n",
      "Epoch 495/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3535 - acc: 0.8436 - val_loss: 0.3777 - val_acc: 0.8299\n",
      "Epoch 496/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3554 - acc: 0.8419 - val_loss: 0.3774 - val_acc: 0.8306\n",
      "Epoch 497/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3547 - acc: 0.8435 - val_loss: 0.3776 - val_acc: 0.8320\n",
      "Epoch 498/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3542 - acc: 0.8436 - val_loss: 0.3774 - val_acc: 0.8313\n",
      "Epoch 499/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3535 - acc: 0.8424 - val_loss: 0.3772 - val_acc: 0.8320\n",
      "Epoch 500/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3520 - acc: 0.8414 - val_loss: 0.3779 - val_acc: 0.8320\n",
      "Epoch 501/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3536 - acc: 0.8453 - val_loss: 0.3772 - val_acc: 0.8313\n",
      "Epoch 502/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3506 - acc: 0.8455 - val_loss: 0.3770 - val_acc: 0.8299\n",
      "Epoch 503/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3540 - acc: 0.8420 - val_loss: 0.3775 - val_acc: 0.8313\n",
      "Epoch 504/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3513 - acc: 0.8444 - val_loss: 0.3776 - val_acc: 0.8306\n",
      "Epoch 505/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3531 - acc: 0.8453 - val_loss: 0.3766 - val_acc: 0.8313\n",
      "Epoch 506/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3503 - acc: 0.8449 - val_loss: 0.3769 - val_acc: 0.8313\n",
      "Epoch 507/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3521 - acc: 0.8441 - val_loss: 0.3774 - val_acc: 0.8320\n",
      "Epoch 508/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3532 - acc: 0.8412 - val_loss: 0.3771 - val_acc: 0.8313\n",
      "Epoch 509/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3493 - acc: 0.8443 - val_loss: 0.3766 - val_acc: 0.8320\n",
      "Epoch 510/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3480 - acc: 0.8476 - val_loss: 0.3765 - val_acc: 0.8320\n",
      "Epoch 511/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3506 - acc: 0.8444 - val_loss: 0.3770 - val_acc: 0.8306\n",
      "Epoch 512/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3501 - acc: 0.8443 - val_loss: 0.3765 - val_acc: 0.8306\n",
      "Epoch 513/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3510 - acc: 0.8475 - val_loss: 0.3763 - val_acc: 0.8327\n",
      "Epoch 514/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3500 - acc: 0.8475 - val_loss: 0.3765 - val_acc: 0.8313\n",
      "Epoch 515/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3489 - acc: 0.8452 - val_loss: 0.3768 - val_acc: 0.8293\n",
      "Epoch 516/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3502 - acc: 0.8468 - val_loss: 0.3767 - val_acc: 0.8320\n",
      "Epoch 517/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3484 - acc: 0.8462 - val_loss: 0.3767 - val_acc: 0.8293\n",
      "Epoch 518/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3508 - acc: 0.8436 - val_loss: 0.3763 - val_acc: 0.8313\n",
      "Epoch 519/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3526 - acc: 0.8445 - val_loss: 0.3766 - val_acc: 0.8340\n",
      "Epoch 520/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3510 - acc: 0.8441 - val_loss: 0.3766 - val_acc: 0.8320\n",
      "Epoch 521/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3497 - acc: 0.8464 - val_loss: 0.3766 - val_acc: 0.8320\n",
      "Epoch 522/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3506 - acc: 0.8445 - val_loss: 0.3759 - val_acc: 0.8320\n",
      "Epoch 523/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3502 - acc: 0.8455 - val_loss: 0.3757 - val_acc: 0.8313\n",
      "Epoch 524/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3521 - acc: 0.8464 - val_loss: 0.3761 - val_acc: 0.8306\n",
      "Epoch 525/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3489 - acc: 0.8459 - val_loss: 0.3757 - val_acc: 0.8299\n",
      "Epoch 526/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3517 - acc: 0.8420 - val_loss: 0.3753 - val_acc: 0.8320\n",
      "Epoch 527/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3496 - acc: 0.8444 - val_loss: 0.3757 - val_acc: 0.8306\n",
      "Epoch 528/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3512 - acc: 0.8455 - val_loss: 0.3757 - val_acc: 0.8313\n",
      "Epoch 529/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3504 - acc: 0.8455 - val_loss: 0.3754 - val_acc: 0.8313\n",
      "Epoch 530/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3501 - acc: 0.8461 - val_loss: 0.3755 - val_acc: 0.8340\n",
      "Epoch 531/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3494 - acc: 0.8476 - val_loss: 0.3762 - val_acc: 0.8327\n",
      "Epoch 532/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3487 - acc: 0.8470 - val_loss: 0.3755 - val_acc: 0.8327\n",
      "Epoch 533/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3464 - acc: 0.8481 - val_loss: 0.3753 - val_acc: 0.8327\n",
      "Epoch 534/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3478 - acc: 0.8472 - val_loss: 0.3753 - val_acc: 0.8313\n",
      "Epoch 535/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3498 - acc: 0.8477 - val_loss: 0.3754 - val_acc: 0.8340\n",
      "Epoch 536/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3478 - acc: 0.8473 - val_loss: 0.3752 - val_acc: 0.8313\n",
      "Epoch 537/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3483 - acc: 0.8465 - val_loss: 0.3751 - val_acc: 0.8327\n",
      "Epoch 538/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3501 - acc: 0.8452 - val_loss: 0.3750 - val_acc: 0.8320\n",
      "Epoch 539/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3480 - acc: 0.8486 - val_loss: 0.3749 - val_acc: 0.8299\n",
      "Epoch 540/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3484 - acc: 0.8459 - val_loss: 0.3750 - val_acc: 0.8306\n",
      "Epoch 541/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3496 - acc: 0.8459 - val_loss: 0.3750 - val_acc: 0.8306\n",
      "Epoch 542/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3482 - acc: 0.8439 - val_loss: 0.3749 - val_acc: 0.8313\n",
      "Epoch 543/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3494 - acc: 0.8469 - val_loss: 0.3753 - val_acc: 0.8306\n",
      "Epoch 544/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3468 - acc: 0.8465 - val_loss: 0.3750 - val_acc: 0.8313\n",
      "Epoch 545/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3483 - acc: 0.8468 - val_loss: 0.3741 - val_acc: 0.8299\n",
      "Epoch 546/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3511 - acc: 0.8465 - val_loss: 0.3743 - val_acc: 0.8306\n",
      "Epoch 547/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3467 - acc: 0.8465 - val_loss: 0.3742 - val_acc: 0.8333\n",
      "Epoch 548/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3479 - acc: 0.8487 - val_loss: 0.3752 - val_acc: 0.8306\n",
      "Epoch 549/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3466 - acc: 0.8452 - val_loss: 0.3744 - val_acc: 0.8293\n",
      "Epoch 550/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3462 - acc: 0.8459 - val_loss: 0.3743 - val_acc: 0.8299\n",
      "Epoch 551/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3458 - acc: 0.8457 - val_loss: 0.3749 - val_acc: 0.8293\n",
      "Epoch 552/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3483 - acc: 0.8444 - val_loss: 0.3742 - val_acc: 0.8299\n",
      "Epoch 553/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3476 - acc: 0.8426 - val_loss: 0.3743 - val_acc: 0.8306\n",
      "Epoch 554/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3464 - acc: 0.8497 - val_loss: 0.3743 - val_acc: 0.8313\n",
      "Epoch 555/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3460 - acc: 0.8457 - val_loss: 0.3742 - val_acc: 0.8279\n",
      "Epoch 556/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3502 - acc: 0.8464 - val_loss: 0.3740 - val_acc: 0.8313\n",
      "Epoch 557/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3506 - acc: 0.8453 - val_loss: 0.3738 - val_acc: 0.8313\n",
      "Epoch 558/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3481 - acc: 0.8458 - val_loss: 0.3739 - val_acc: 0.8320\n",
      "Epoch 559/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3469 - acc: 0.8509 - val_loss: 0.3742 - val_acc: 0.8320\n",
      "Epoch 560/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3453 - acc: 0.8476 - val_loss: 0.3737 - val_acc: 0.8327\n",
      "Epoch 561/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3494 - acc: 0.8452 - val_loss: 0.3732 - val_acc: 0.8320\n",
      "Epoch 562/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3500 - acc: 0.8476 - val_loss: 0.3731 - val_acc: 0.8340\n",
      "Epoch 563/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3469 - acc: 0.8455 - val_loss: 0.3736 - val_acc: 0.8340\n",
      "Epoch 564/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3471 - acc: 0.8476 - val_loss: 0.3738 - val_acc: 0.8327\n",
      "Epoch 565/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3469 - acc: 0.8477 - val_loss: 0.3737 - val_acc: 0.8320\n",
      "Epoch 566/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3475 - acc: 0.8473 - val_loss: 0.3732 - val_acc: 0.8320\n",
      "Epoch 567/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3443 - acc: 0.8493 - val_loss: 0.3732 - val_acc: 0.8306\n",
      "Epoch 568/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3446 - acc: 0.8499 - val_loss: 0.3727 - val_acc: 0.8333\n",
      "Epoch 569/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3450 - acc: 0.8474 - val_loss: 0.3727 - val_acc: 0.8347\n",
      "Epoch 570/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3467 - acc: 0.8484 - val_loss: 0.3729 - val_acc: 0.8320\n",
      "Epoch 571/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3469 - acc: 0.8476 - val_loss: 0.3726 - val_acc: 0.8360\n",
      "Epoch 572/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3485 - acc: 0.8449 - val_loss: 0.3727 - val_acc: 0.8367\n",
      "Epoch 573/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3441 - acc: 0.8482 - val_loss: 0.3725 - val_acc: 0.8340\n",
      "Epoch 574/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3481 - acc: 0.8464 - val_loss: 0.3729 - val_acc: 0.8354\n",
      "Epoch 575/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3479 - acc: 0.8466 - val_loss: 0.3729 - val_acc: 0.8320\n",
      "Epoch 576/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3457 - acc: 0.8462 - val_loss: 0.3729 - val_acc: 0.8360\n",
      "Epoch 577/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3450 - acc: 0.8487 - val_loss: 0.3728 - val_acc: 0.8354\n",
      "Epoch 578/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3465 - acc: 0.8476 - val_loss: 0.3726 - val_acc: 0.8327\n",
      "Epoch 579/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3459 - acc: 0.8484 - val_loss: 0.3725 - val_acc: 0.8360\n",
      "Epoch 580/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3449 - acc: 0.8495 - val_loss: 0.3735 - val_acc: 0.8354\n",
      "Epoch 581/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3431 - acc: 0.8486 - val_loss: 0.3723 - val_acc: 0.8354\n",
      "Epoch 582/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3440 - acc: 0.8485 - val_loss: 0.3722 - val_acc: 0.8340\n",
      "Epoch 583/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3465 - acc: 0.8473 - val_loss: 0.3721 - val_acc: 0.8367\n",
      "Epoch 584/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3440 - acc: 0.8499 - val_loss: 0.3724 - val_acc: 0.8333\n",
      "Epoch 585/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3416 - acc: 0.8487 - val_loss: 0.3723 - val_acc: 0.8354\n",
      "Epoch 586/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3466 - acc: 0.8473 - val_loss: 0.3718 - val_acc: 0.8374\n",
      "Epoch 587/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3451 - acc: 0.8519 - val_loss: 0.3717 - val_acc: 0.8374\n",
      "Epoch 588/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3449 - acc: 0.8485 - val_loss: 0.3718 - val_acc: 0.8347\n",
      "Epoch 589/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3457 - acc: 0.8469 - val_loss: 0.3717 - val_acc: 0.8374\n",
      "Epoch 590/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3451 - acc: 0.8482 - val_loss: 0.3717 - val_acc: 0.8367\n",
      "Epoch 591/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3435 - acc: 0.8481 - val_loss: 0.3724 - val_acc: 0.8388\n",
      "Epoch 592/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3453 - acc: 0.8482 - val_loss: 0.3717 - val_acc: 0.8360\n",
      "Epoch 593/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3438 - acc: 0.8479 - val_loss: 0.3716 - val_acc: 0.8340\n",
      "Epoch 594/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3405 - acc: 0.8510 - val_loss: 0.3719 - val_acc: 0.8374\n",
      "Epoch 595/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3426 - acc: 0.8498 - val_loss: 0.3719 - val_acc: 0.8394\n",
      "Epoch 596/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3438 - acc: 0.8504 - val_loss: 0.3719 - val_acc: 0.8367\n",
      "Epoch 597/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3451 - acc: 0.8490 - val_loss: 0.3709 - val_acc: 0.8367\n",
      "Epoch 598/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3448 - acc: 0.8491 - val_loss: 0.3710 - val_acc: 0.8354\n",
      "Epoch 599/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3413 - acc: 0.8479 - val_loss: 0.3710 - val_acc: 0.8394\n",
      "Epoch 600/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3467 - acc: 0.8504 - val_loss: 0.3714 - val_acc: 0.8401\n",
      "Epoch 601/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3439 - acc: 0.8482 - val_loss: 0.3710 - val_acc: 0.8374\n",
      "Epoch 602/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3400 - acc: 0.8523 - val_loss: 0.3712 - val_acc: 0.8394\n",
      "Epoch 603/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3444 - acc: 0.8503 - val_loss: 0.3714 - val_acc: 0.8374\n",
      "Epoch 604/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3466 - acc: 0.8469 - val_loss: 0.3714 - val_acc: 0.8367\n",
      "Epoch 605/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3445 - acc: 0.8488 - val_loss: 0.3709 - val_acc: 0.8388\n",
      "Epoch 606/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3431 - acc: 0.8476 - val_loss: 0.3709 - val_acc: 0.8388\n",
      "Epoch 607/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3423 - acc: 0.8506 - val_loss: 0.3710 - val_acc: 0.8388\n",
      "Epoch 608/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3438 - acc: 0.8494 - val_loss: 0.3713 - val_acc: 0.8401\n",
      "Epoch 609/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3466 - acc: 0.8482 - val_loss: 0.3708 - val_acc: 0.8388\n",
      "Epoch 610/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3421 - acc: 0.8465 - val_loss: 0.3706 - val_acc: 0.8381\n",
      "Epoch 611/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3412 - acc: 0.8524 - val_loss: 0.3704 - val_acc: 0.8374\n",
      "Epoch 612/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3424 - acc: 0.8494 - val_loss: 0.3706 - val_acc: 0.8381\n",
      "Epoch 613/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3394 - acc: 0.8525 - val_loss: 0.3702 - val_acc: 0.8374\n",
      "Epoch 614/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3412 - acc: 0.8508 - val_loss: 0.3704 - val_acc: 0.8388\n",
      "Epoch 615/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3402 - acc: 0.8506 - val_loss: 0.3707 - val_acc: 0.8374\n",
      "Epoch 616/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3391 - acc: 0.8533 - val_loss: 0.3702 - val_acc: 0.8394\n",
      "Epoch 617/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3428 - acc: 0.8494 - val_loss: 0.3700 - val_acc: 0.8394\n",
      "Epoch 618/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3388 - acc: 0.8540 - val_loss: 0.3706 - val_acc: 0.8388\n",
      "Epoch 619/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3411 - acc: 0.8499 - val_loss: 0.3700 - val_acc: 0.8401\n",
      "Epoch 620/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3392 - acc: 0.8541 - val_loss: 0.3703 - val_acc: 0.8415\n",
      "Epoch 621/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3418 - acc: 0.8497 - val_loss: 0.3695 - val_acc: 0.8381\n",
      "Epoch 622/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3423 - acc: 0.8500 - val_loss: 0.3698 - val_acc: 0.8394\n",
      "Epoch 623/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3439 - acc: 0.8494 - val_loss: 0.3699 - val_acc: 0.8394\n",
      "Epoch 624/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3440 - acc: 0.8481 - val_loss: 0.3698 - val_acc: 0.8388\n",
      "Epoch 625/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3411 - acc: 0.8505 - val_loss: 0.3693 - val_acc: 0.8388\n",
      "Epoch 626/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3400 - acc: 0.8511 - val_loss: 0.3691 - val_acc: 0.8408\n",
      "Epoch 627/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3392 - acc: 0.8529 - val_loss: 0.3694 - val_acc: 0.8381\n",
      "Epoch 628/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3415 - acc: 0.8494 - val_loss: 0.3691 - val_acc: 0.8381\n",
      "Epoch 629/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3418 - acc: 0.8502 - val_loss: 0.3692 - val_acc: 0.8388\n",
      "Epoch 630/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3399 - acc: 0.8498 - val_loss: 0.3689 - val_acc: 0.8401\n",
      "Epoch 631/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3380 - acc: 0.8526 - val_loss: 0.3688 - val_acc: 0.8415\n",
      "Epoch 632/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3428 - acc: 0.8516 - val_loss: 0.3692 - val_acc: 0.8401\n",
      "Epoch 633/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3429 - acc: 0.8475 - val_loss: 0.3695 - val_acc: 0.8381\n",
      "Epoch 634/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3388 - acc: 0.8545 - val_loss: 0.3690 - val_acc: 0.8388\n",
      "Epoch 635/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3418 - acc: 0.8479 - val_loss: 0.3689 - val_acc: 0.8394\n",
      "Epoch 636/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3401 - acc: 0.8511 - val_loss: 0.3694 - val_acc: 0.8401\n",
      "Epoch 637/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3408 - acc: 0.8507 - val_loss: 0.3688 - val_acc: 0.8408\n",
      "Epoch 638/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3432 - acc: 0.8482 - val_loss: 0.3688 - val_acc: 0.8408\n",
      "Epoch 639/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3434 - acc: 0.8490 - val_loss: 0.3684 - val_acc: 0.8401\n",
      "Epoch 640/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3414 - acc: 0.8513 - val_loss: 0.3685 - val_acc: 0.8394\n",
      "Epoch 641/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3402 - acc: 0.8498 - val_loss: 0.3689 - val_acc: 0.8381\n",
      "Epoch 642/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3430 - acc: 0.8472 - val_loss: 0.3685 - val_acc: 0.8401\n",
      "Epoch 643/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3385 - acc: 0.8517 - val_loss: 0.3687 - val_acc: 0.8381\n",
      "Epoch 644/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3409 - acc: 0.8509 - val_loss: 0.3691 - val_acc: 0.8381\n",
      "Epoch 645/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3410 - acc: 0.8492 - val_loss: 0.3687 - val_acc: 0.8394\n",
      "Epoch 646/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3396 - acc: 0.8484 - val_loss: 0.3688 - val_acc: 0.8381\n",
      "Epoch 647/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3390 - acc: 0.8545 - val_loss: 0.3688 - val_acc: 0.8374\n",
      "Epoch 648/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3386 - acc: 0.8533 - val_loss: 0.3684 - val_acc: 0.8388\n",
      "Epoch 649/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3398 - acc: 0.8516 - val_loss: 0.3680 - val_acc: 0.8388\n",
      "Epoch 650/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3395 - acc: 0.8511 - val_loss: 0.3685 - val_acc: 0.8381\n",
      "Epoch 651/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3393 - acc: 0.8506 - val_loss: 0.3685 - val_acc: 0.8374\n",
      "Epoch 652/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3407 - acc: 0.8530 - val_loss: 0.3685 - val_acc: 0.8388\n",
      "Epoch 653/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3407 - acc: 0.8521 - val_loss: 0.3683 - val_acc: 0.8374\n",
      "Epoch 654/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3383 - acc: 0.8533 - val_loss: 0.3686 - val_acc: 0.8367\n",
      "Epoch 655/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3391 - acc: 0.8506 - val_loss: 0.3682 - val_acc: 0.8394\n",
      "Epoch 656/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3388 - acc: 0.8504 - val_loss: 0.3683 - val_acc: 0.8381\n",
      "Epoch 657/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3366 - acc: 0.8531 - val_loss: 0.3685 - val_acc: 0.8374\n",
      "Epoch 658/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3366 - acc: 0.8546 - val_loss: 0.3687 - val_acc: 0.8367\n",
      "Epoch 659/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3369 - acc: 0.8517 - val_loss: 0.3684 - val_acc: 0.8394\n",
      "Epoch 660/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3381 - acc: 0.8512 - val_loss: 0.3680 - val_acc: 0.8408\n",
      "Epoch 661/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3368 - acc: 0.8537 - val_loss: 0.3682 - val_acc: 0.8388\n",
      "Epoch 662/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3359 - acc: 0.8537 - val_loss: 0.3685 - val_acc: 0.8401\n",
      "Epoch 663/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3379 - acc: 0.8538 - val_loss: 0.3685 - val_acc: 0.8374\n",
      "Epoch 664/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3392 - acc: 0.8518 - val_loss: 0.3683 - val_acc: 0.8394\n",
      "Epoch 665/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.3421 - acc: 0.8509 - val_loss: 0.3682 - val_acc: 0.8381\n",
      "Epoch 666/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3377 - acc: 0.8533 - val_loss: 0.3683 - val_acc: 0.8367\n",
      "Epoch 667/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3354 - acc: 0.8556 - val_loss: 0.3679 - val_acc: 0.8394\n",
      "Epoch 668/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3359 - acc: 0.8534 - val_loss: 0.3679 - val_acc: 0.8374\n",
      "Epoch 669/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3377 - acc: 0.8511 - val_loss: 0.3675 - val_acc: 0.8388\n",
      "Epoch 670/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3372 - acc: 0.8541 - val_loss: 0.3670 - val_acc: 0.8388\n",
      "Epoch 671/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3377 - acc: 0.8543 - val_loss: 0.3671 - val_acc: 0.8394\n",
      "Epoch 672/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3363 - acc: 0.8542 - val_loss: 0.3674 - val_acc: 0.8374\n",
      "Epoch 673/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3385 - acc: 0.8515 - val_loss: 0.3677 - val_acc: 0.8367\n",
      "Epoch 674/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3372 - acc: 0.8549 - val_loss: 0.3673 - val_acc: 0.8374\n",
      "Epoch 675/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3393 - acc: 0.8507 - val_loss: 0.3671 - val_acc: 0.8367\n",
      "Epoch 676/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3356 - acc: 0.8570 - val_loss: 0.3671 - val_acc: 0.8394\n",
      "Epoch 677/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3367 - acc: 0.8522 - val_loss: 0.3672 - val_acc: 0.8374\n",
      "Epoch 678/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3323 - acc: 0.8553 - val_loss: 0.3672 - val_acc: 0.8374\n",
      "Epoch 679/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3366 - acc: 0.8537 - val_loss: 0.3669 - val_acc: 0.8367\n",
      "Epoch 680/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3346 - acc: 0.8542 - val_loss: 0.3669 - val_acc: 0.8374\n",
      "Epoch 681/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3342 - acc: 0.8555 - val_loss: 0.3670 - val_acc: 0.8354\n",
      "Epoch 682/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3364 - acc: 0.8522 - val_loss: 0.3671 - val_acc: 0.8381\n",
      "Epoch 683/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3352 - acc: 0.8541 - val_loss: 0.3668 - val_acc: 0.8381\n",
      "Epoch 684/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3357 - acc: 0.8549 - val_loss: 0.3669 - val_acc: 0.8394\n",
      "Epoch 685/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3349 - acc: 0.8540 - val_loss: 0.3668 - val_acc: 0.8367\n",
      "Epoch 686/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3356 - acc: 0.8530 - val_loss: 0.3666 - val_acc: 0.8374\n",
      "Epoch 687/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3318 - acc: 0.8562 - val_loss: 0.3668 - val_acc: 0.8388\n",
      "Epoch 688/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3342 - acc: 0.8542 - val_loss: 0.3667 - val_acc: 0.8367\n",
      "Epoch 689/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3350 - acc: 0.8568 - val_loss: 0.3664 - val_acc: 0.8367\n",
      "Epoch 690/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3378 - acc: 0.8515 - val_loss: 0.3663 - val_acc: 0.8381\n",
      "Epoch 691/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3359 - acc: 0.8508 - val_loss: 0.3663 - val_acc: 0.8374\n",
      "Epoch 692/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3332 - acc: 0.8555 - val_loss: 0.3662 - val_acc: 0.8394\n",
      "Epoch 693/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3385 - acc: 0.8502 - val_loss: 0.3663 - val_acc: 0.8374\n",
      "Epoch 694/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3362 - acc: 0.8526 - val_loss: 0.3661 - val_acc: 0.8381\n",
      "Epoch 695/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3374 - acc: 0.8519 - val_loss: 0.3662 - val_acc: 0.8360\n",
      "Epoch 696/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3340 - acc: 0.8545 - val_loss: 0.3665 - val_acc: 0.8381\n",
      "Epoch 697/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3314 - acc: 0.8573 - val_loss: 0.3661 - val_acc: 0.8381\n",
      "Epoch 698/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3347 - acc: 0.8540 - val_loss: 0.3664 - val_acc: 0.8388\n",
      "Epoch 699/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3314 - acc: 0.8549 - val_loss: 0.3663 - val_acc: 0.8367\n",
      "Epoch 700/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3374 - acc: 0.8528 - val_loss: 0.3667 - val_acc: 0.8367\n",
      "Epoch 701/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3343 - acc: 0.8584 - val_loss: 0.3663 - val_acc: 0.8394\n",
      "Epoch 702/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3357 - acc: 0.8524 - val_loss: 0.3660 - val_acc: 0.8374\n",
      "Epoch 703/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3328 - acc: 0.8555 - val_loss: 0.3663 - val_acc: 0.8381\n",
      "Epoch 704/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3354 - acc: 0.8540 - val_loss: 0.3659 - val_acc: 0.8374\n",
      "Epoch 705/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3317 - acc: 0.8580 - val_loss: 0.3665 - val_acc: 0.8394\n",
      "Epoch 706/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3354 - acc: 0.8535 - val_loss: 0.3662 - val_acc: 0.8394\n",
      "Epoch 707/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3339 - acc: 0.8567 - val_loss: 0.3657 - val_acc: 0.8388\n",
      "Epoch 708/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3319 - acc: 0.8573 - val_loss: 0.3660 - val_acc: 0.8374\n",
      "Epoch 709/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3327 - acc: 0.8543 - val_loss: 0.3659 - val_acc: 0.8367\n",
      "Epoch 710/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3340 - acc: 0.8562 - val_loss: 0.3660 - val_acc: 0.8388\n",
      "Epoch 711/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3370 - acc: 0.8546 - val_loss: 0.3657 - val_acc: 0.8381\n",
      "Epoch 712/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3318 - acc: 0.8581 - val_loss: 0.3660 - val_acc: 0.8401\n",
      "Epoch 713/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3314 - acc: 0.8555 - val_loss: 0.3657 - val_acc: 0.8408\n",
      "Epoch 714/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3355 - acc: 0.8531 - val_loss: 0.3657 - val_acc: 0.8401\n",
      "Epoch 715/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3340 - acc: 0.8568 - val_loss: 0.3659 - val_acc: 0.8401\n",
      "Epoch 716/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3312 - acc: 0.8558 - val_loss: 0.3654 - val_acc: 0.8381\n",
      "Epoch 717/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3307 - acc: 0.8579 - val_loss: 0.3658 - val_acc: 0.8388\n",
      "Epoch 718/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3339 - acc: 0.8519 - val_loss: 0.3651 - val_acc: 0.8381\n",
      "Epoch 719/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3335 - acc: 0.8575 - val_loss: 0.3651 - val_acc: 0.8374\n",
      "Epoch 720/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3305 - acc: 0.8575 - val_loss: 0.3656 - val_acc: 0.8408\n",
      "Epoch 721/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3312 - acc: 0.8532 - val_loss: 0.3653 - val_acc: 0.8408\n",
      "Epoch 722/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3335 - acc: 0.8565 - val_loss: 0.3652 - val_acc: 0.8381\n",
      "Epoch 723/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3324 - acc: 0.8566 - val_loss: 0.3652 - val_acc: 0.8388\n",
      "Epoch 724/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3334 - acc: 0.8543 - val_loss: 0.3658 - val_acc: 0.8415\n",
      "Epoch 725/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3338 - acc: 0.8555 - val_loss: 0.3657 - val_acc: 0.8394\n",
      "Epoch 726/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3310 - acc: 0.8558 - val_loss: 0.3656 - val_acc: 0.8388\n",
      "Epoch 727/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3324 - acc: 0.8571 - val_loss: 0.3657 - val_acc: 0.8388\n",
      "Epoch 728/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3345 - acc: 0.8549 - val_loss: 0.3657 - val_acc: 0.8408\n",
      "Epoch 729/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3286 - acc: 0.8587 - val_loss: 0.3656 - val_acc: 0.8408\n",
      "Epoch 730/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3282 - acc: 0.8592 - val_loss: 0.3653 - val_acc: 0.8401\n",
      "Epoch 731/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3319 - acc: 0.8568 - val_loss: 0.3652 - val_acc: 0.8374\n",
      "Epoch 732/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3322 - acc: 0.8555 - val_loss: 0.3650 - val_acc: 0.8394\n",
      "Epoch 733/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3351 - acc: 0.8563 - val_loss: 0.3653 - val_acc: 0.8394\n",
      "Epoch 734/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3337 - acc: 0.8521 - val_loss: 0.3656 - val_acc: 0.8401\n",
      "Epoch 735/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3337 - acc: 0.8561 - val_loss: 0.3648 - val_acc: 0.8394\n",
      "Epoch 736/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3314 - acc: 0.8563 - val_loss: 0.3651 - val_acc: 0.8388\n",
      "Epoch 737/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3314 - acc: 0.8571 - val_loss: 0.3653 - val_acc: 0.8394\n",
      "Epoch 738/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3312 - acc: 0.8579 - val_loss: 0.3655 - val_acc: 0.8394\n",
      "Epoch 739/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3348 - acc: 0.8545 - val_loss: 0.3649 - val_acc: 0.8394\n",
      "Epoch 740/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3314 - acc: 0.8567 - val_loss: 0.3650 - val_acc: 0.8388\n",
      "Epoch 741/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3281 - acc: 0.8564 - val_loss: 0.3648 - val_acc: 0.8408\n",
      "Epoch 742/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3296 - acc: 0.8588 - val_loss: 0.3644 - val_acc: 0.8401\n",
      "Epoch 743/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3317 - acc: 0.8573 - val_loss: 0.3644 - val_acc: 0.8408\n",
      "Epoch 744/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3314 - acc: 0.8559 - val_loss: 0.3651 - val_acc: 0.8408\n",
      "Epoch 745/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3273 - acc: 0.8570 - val_loss: 0.3649 - val_acc: 0.8401\n",
      "Epoch 746/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3304 - acc: 0.8586 - val_loss: 0.3647 - val_acc: 0.8394\n",
      "Epoch 747/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3313 - acc: 0.8569 - val_loss: 0.3646 - val_acc: 0.8408\n",
      "Epoch 748/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3303 - acc: 0.8584 - val_loss: 0.3647 - val_acc: 0.8401\n",
      "Epoch 749/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3305 - acc: 0.8579 - val_loss: 0.3645 - val_acc: 0.8408\n",
      "Epoch 750/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3330 - acc: 0.8538 - val_loss: 0.3643 - val_acc: 0.8394\n",
      "Epoch 751/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3320 - acc: 0.8546 - val_loss: 0.3646 - val_acc: 0.8408\n",
      "Epoch 752/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.3329 - acc: 0.8564 - val_loss: 0.3648 - val_acc: 0.8388\n",
      "Epoch 753/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3300 - acc: 0.8577 - val_loss: 0.3643 - val_acc: 0.8394\n",
      "Epoch 754/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.3292 - acc: 0.8589 - val_loss: 0.3643 - val_acc: 0.8401\n",
      "Epoch 755/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3316 - acc: 0.8550 - val_loss: 0.3644 - val_acc: 0.8408\n",
      "Epoch 756/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3292 - acc: 0.8582 - val_loss: 0.3637 - val_acc: 0.8394\n",
      "Epoch 757/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3253 - acc: 0.8595 - val_loss: 0.3639 - val_acc: 0.8401\n",
      "Epoch 758/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3323 - acc: 0.8548 - val_loss: 0.3640 - val_acc: 0.8388\n",
      "Epoch 759/10000\n",
      "13284/13284 [==============================] - 0s 33us/sample - loss: 0.3306 - acc: 0.8585 - val_loss: 0.3639 - val_acc: 0.8401\n",
      "Epoch 760/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3309 - acc: 0.8563 - val_loss: 0.3637 - val_acc: 0.8381\n",
      "Epoch 761/10000\n",
      "13284/13284 [==============================] - 0s 32us/sample - loss: 0.3296 - acc: 0.8579 - val_loss: 0.3638 - val_acc: 0.8415\n",
      "Epoch 762/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3271 - acc: 0.8586 - val_loss: 0.3636 - val_acc: 0.8408\n",
      "Epoch 763/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3293 - acc: 0.8587 - val_loss: 0.3640 - val_acc: 0.8408\n",
      "Epoch 764/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3300 - acc: 0.8598 - val_loss: 0.3634 - val_acc: 0.8435\n",
      "Epoch 765/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3304 - acc: 0.8544 - val_loss: 0.3636 - val_acc: 0.8388\n",
      "Epoch 766/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3326 - acc: 0.8559 - val_loss: 0.3634 - val_acc: 0.8401\n",
      "Epoch 767/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3298 - acc: 0.8558 - val_loss: 0.3640 - val_acc: 0.8408\n",
      "Epoch 768/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3310 - acc: 0.8563 - val_loss: 0.3640 - val_acc: 0.8388\n",
      "Epoch 769/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3308 - acc: 0.8574 - val_loss: 0.3634 - val_acc: 0.8401\n",
      "Epoch 770/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3281 - acc: 0.8573 - val_loss: 0.3636 - val_acc: 0.8388\n",
      "Epoch 771/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3277 - acc: 0.8597 - val_loss: 0.3634 - val_acc: 0.8408\n",
      "Epoch 772/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3277 - acc: 0.8577 - val_loss: 0.3636 - val_acc: 0.8381\n",
      "Epoch 773/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3301 - acc: 0.8572 - val_loss: 0.3636 - val_acc: 0.8381\n",
      "Epoch 774/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.3300 - acc: 0.858 - 0s 30us/sample - loss: 0.3299 - acc: 0.8584 - val_loss: 0.3632 - val_acc: 0.8394\n",
      "Epoch 775/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3267 - acc: 0.8577 - val_loss: 0.3631 - val_acc: 0.8394\n",
      "Epoch 776/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3266 - acc: 0.8595 - val_loss: 0.3632 - val_acc: 0.8394\n",
      "Epoch 777/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3333 - acc: 0.8554 - val_loss: 0.3632 - val_acc: 0.8401\n",
      "Epoch 778/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3283 - acc: 0.8558 - val_loss: 0.3635 - val_acc: 0.8408\n",
      "Epoch 779/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3297 - acc: 0.8571 - val_loss: 0.3632 - val_acc: 0.8401\n",
      "Epoch 780/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3289 - acc: 0.8543 - val_loss: 0.3634 - val_acc: 0.8415\n",
      "Epoch 781/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3280 - acc: 0.8592 - val_loss: 0.3630 - val_acc: 0.8394\n",
      "Epoch 782/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3293 - acc: 0.8576 - val_loss: 0.3629 - val_acc: 0.8415\n",
      "Epoch 783/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3277 - acc: 0.8625 - val_loss: 0.3626 - val_acc: 0.8401\n",
      "Epoch 784/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3298 - acc: 0.8572 - val_loss: 0.3634 - val_acc: 0.8408\n",
      "Epoch 785/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.3295 - acc: 0.8594 - val_loss: 0.3626 - val_acc: 0.8421\n",
      "Epoch 786/10000\n",
      "13284/13284 [==============================] - 0s 32us/sample - loss: 0.3305 - acc: 0.8567 - val_loss: 0.3632 - val_acc: 0.8415\n",
      "Epoch 787/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.3286 - acc: 0.8583 - val_loss: 0.3630 - val_acc: 0.8415\n",
      "Epoch 788/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3275 - acc: 0.8591 - val_loss: 0.3633 - val_acc: 0.8415\n",
      "Epoch 789/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3266 - acc: 0.8616 - val_loss: 0.3630 - val_acc: 0.8408\n",
      "Epoch 790/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.3282 - acc: 0.8585 - val_loss: 0.3631 - val_acc: 0.8415\n",
      "Epoch 791/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3265 - acc: 0.8601 - val_loss: 0.3627 - val_acc: 0.8421\n",
      "Epoch 792/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3258 - acc: 0.8610 - val_loss: 0.3630 - val_acc: 0.8408\n",
      "Epoch 793/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.3244 - acc: 0.8594 - val_loss: 0.3630 - val_acc: 0.8401\n",
      "Epoch 794/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3277 - acc: 0.8570 - val_loss: 0.3629 - val_acc: 0.8401\n",
      "Epoch 795/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3285 - acc: 0.8580 - val_loss: 0.3626 - val_acc: 0.8408\n",
      "Epoch 796/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3267 - acc: 0.8590 - val_loss: 0.3628 - val_acc: 0.8415\n",
      "Epoch 797/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3260 - acc: 0.8586 - val_loss: 0.3623 - val_acc: 0.8408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 798/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3288 - acc: 0.8584 - val_loss: 0.3629 - val_acc: 0.8394\n",
      "Epoch 799/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3294 - acc: 0.8579 - val_loss: 0.3627 - val_acc: 0.8401\n",
      "Epoch 800/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3277 - acc: 0.8578 - val_loss: 0.3629 - val_acc: 0.8394\n",
      "Epoch 801/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3239 - acc: 0.8607 - val_loss: 0.3632 - val_acc: 0.8401\n",
      "Epoch 802/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3268 - acc: 0.8552 - val_loss: 0.3628 - val_acc: 0.8401\n",
      "Epoch 803/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3268 - acc: 0.8575 - val_loss: 0.3622 - val_acc: 0.8428\n",
      "Epoch 804/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3262 - acc: 0.8580 - val_loss: 0.3626 - val_acc: 0.8401\n",
      "Epoch 805/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3259 - acc: 0.8586 - val_loss: 0.3625 - val_acc: 0.8421\n",
      "Epoch 806/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3264 - acc: 0.8598 - val_loss: 0.3620 - val_acc: 0.8401\n",
      "Epoch 807/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3255 - acc: 0.8592 - val_loss: 0.3623 - val_acc: 0.8401\n",
      "Epoch 808/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3283 - acc: 0.8589 - val_loss: 0.3623 - val_acc: 0.8415\n",
      "Epoch 809/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3247 - acc: 0.8595 - val_loss: 0.3625 - val_acc: 0.8401\n",
      "Epoch 810/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3293 - acc: 0.8570 - val_loss: 0.3627 - val_acc: 0.8401\n",
      "Epoch 811/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3295 - acc: 0.8577 - val_loss: 0.3625 - val_acc: 0.8415\n",
      "Epoch 812/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3263 - acc: 0.8598 - val_loss: 0.3620 - val_acc: 0.8394\n",
      "Epoch 813/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3270 - acc: 0.8598 - val_loss: 0.3621 - val_acc: 0.8401\n",
      "Epoch 814/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3278 - acc: 0.8581 - val_loss: 0.3620 - val_acc: 0.8415\n",
      "Epoch 815/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3233 - acc: 0.8607 - val_loss: 0.3618 - val_acc: 0.8401\n",
      "Epoch 816/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3237 - acc: 0.8598 - val_loss: 0.3617 - val_acc: 0.8401\n",
      "Epoch 817/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3263 - acc: 0.8596 - val_loss: 0.3616 - val_acc: 0.8408\n",
      "Epoch 818/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3258 - acc: 0.8601 - val_loss: 0.3620 - val_acc: 0.8415\n",
      "Epoch 819/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3255 - acc: 0.8597 - val_loss: 0.3619 - val_acc: 0.8394\n",
      "Epoch 820/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3223 - acc: 0.8621 - val_loss: 0.3616 - val_acc: 0.8415\n",
      "Epoch 821/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3256 - acc: 0.8607 - val_loss: 0.3623 - val_acc: 0.8408\n",
      "Epoch 822/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3270 - acc: 0.8602 - val_loss: 0.3615 - val_acc: 0.8421\n",
      "Epoch 823/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3242 - acc: 0.8597 - val_loss: 0.3617 - val_acc: 0.8435\n",
      "Epoch 824/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3253 - acc: 0.8596 - val_loss: 0.3621 - val_acc: 0.8415\n",
      "Epoch 825/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3253 - acc: 0.8614 - val_loss: 0.3618 - val_acc: 0.8415\n",
      "Epoch 826/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3269 - acc: 0.8592 - val_loss: 0.3615 - val_acc: 0.8401\n",
      "Epoch 827/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3253 - acc: 0.8606 - val_loss: 0.3615 - val_acc: 0.8415\n",
      "Epoch 828/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3229 - acc: 0.8592 - val_loss: 0.3620 - val_acc: 0.8401\n",
      "Epoch 829/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3292 - acc: 0.8588 - val_loss: 0.3613 - val_acc: 0.8408\n",
      "Epoch 830/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3253 - acc: 0.8591 - val_loss: 0.3611 - val_acc: 0.8435\n",
      "Epoch 831/10000\n",
      "13284/13284 [==============================] - 0s 34us/sample - loss: 0.3253 - acc: 0.8596 - val_loss: 0.3614 - val_acc: 0.8415\n",
      "Epoch 832/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3219 - acc: 0.8612 - val_loss: 0.3615 - val_acc: 0.8421\n",
      "Epoch 833/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3249 - acc: 0.8586 - val_loss: 0.3616 - val_acc: 0.8401\n",
      "Epoch 834/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3235 - acc: 0.8614 - val_loss: 0.3618 - val_acc: 0.8421\n",
      "Epoch 835/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3244 - acc: 0.8595 - val_loss: 0.3617 - val_acc: 0.8421\n",
      "Epoch 836/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3218 - acc: 0.8623 - val_loss: 0.3618 - val_acc: 0.8415\n",
      "Epoch 837/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3253 - acc: 0.8582 - val_loss: 0.3610 - val_acc: 0.8401\n",
      "Epoch 838/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3234 - acc: 0.8610 - val_loss: 0.3611 - val_acc: 0.8428\n",
      "Epoch 839/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3216 - acc: 0.8632 - val_loss: 0.3609 - val_acc: 0.8428\n",
      "Epoch 840/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3253 - acc: 0.8601 - val_loss: 0.3613 - val_acc: 0.8435\n",
      "Epoch 841/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3214 - acc: 0.8624 - val_loss: 0.3612 - val_acc: 0.8421\n",
      "Epoch 842/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3246 - acc: 0.8613 - val_loss: 0.3608 - val_acc: 0.8428\n",
      "Epoch 843/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3213 - acc: 0.8618 - val_loss: 0.3613 - val_acc: 0.8401\n",
      "Epoch 844/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3244 - acc: 0.8593 - val_loss: 0.3610 - val_acc: 0.8408\n",
      "Epoch 845/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3231 - acc: 0.8615 - val_loss: 0.3611 - val_acc: 0.8421\n",
      "Epoch 846/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3221 - acc: 0.8623 - val_loss: 0.3609 - val_acc: 0.8428\n",
      "Epoch 847/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3236 - acc: 0.8609 - val_loss: 0.3606 - val_acc: 0.8408\n",
      "Epoch 848/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3262 - acc: 0.8592 - val_loss: 0.3605 - val_acc: 0.8408\n",
      "Epoch 849/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3210 - acc: 0.8634 - val_loss: 0.3613 - val_acc: 0.8415\n",
      "Epoch 850/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3209 - acc: 0.8643 - val_loss: 0.3615 - val_acc: 0.8428\n",
      "Epoch 851/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3261 - acc: 0.8612 - val_loss: 0.3611 - val_acc: 0.8428\n",
      "Epoch 852/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3223 - acc: 0.8628 - val_loss: 0.3610 - val_acc: 0.8421\n",
      "Epoch 853/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3230 - acc: 0.8597 - val_loss: 0.3603 - val_acc: 0.8415\n",
      "Epoch 854/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3223 - acc: 0.8631 - val_loss: 0.3607 - val_acc: 0.8408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3223 - acc: 0.8638 - val_loss: 0.3611 - val_acc: 0.8449\n",
      "Epoch 856/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3226 - acc: 0.8634 - val_loss: 0.3604 - val_acc: 0.8428\n",
      "Epoch 857/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3187 - acc: 0.8622 - val_loss: 0.3607 - val_acc: 0.8408\n",
      "Epoch 858/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3231 - acc: 0.8594 - val_loss: 0.3604 - val_acc: 0.8435\n",
      "Epoch 859/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3211 - acc: 0.8604 - val_loss: 0.3603 - val_acc: 0.8421\n",
      "Epoch 860/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3197 - acc: 0.8643 - val_loss: 0.3603 - val_acc: 0.8442\n",
      "Epoch 861/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3245 - acc: 0.8599 - val_loss: 0.3605 - val_acc: 0.8428\n",
      "Epoch 862/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3198 - acc: 0.8637 - val_loss: 0.3607 - val_acc: 0.8455\n",
      "Epoch 863/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3197 - acc: 0.8619 - val_loss: 0.3604 - val_acc: 0.8455\n",
      "Epoch 864/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3208 - acc: 0.8643 - val_loss: 0.3600 - val_acc: 0.8421\n",
      "Epoch 865/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3223 - acc: 0.8603 - val_loss: 0.3600 - val_acc: 0.8442\n",
      "Epoch 866/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3175 - acc: 0.8667 - val_loss: 0.3600 - val_acc: 0.8421\n",
      "Epoch 867/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3191 - acc: 0.8637 - val_loss: 0.3602 - val_acc: 0.8421\n",
      "Epoch 868/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3205 - acc: 0.8654 - val_loss: 0.3601 - val_acc: 0.8455\n",
      "Epoch 869/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3252 - acc: 0.8590 - val_loss: 0.3604 - val_acc: 0.8442\n",
      "Epoch 870/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3235 - acc: 0.8646 - val_loss: 0.3601 - val_acc: 0.8421\n",
      "Epoch 871/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3233 - acc: 0.8615 - val_loss: 0.3599 - val_acc: 0.8408\n",
      "Epoch 872/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3221 - acc: 0.8631 - val_loss: 0.3603 - val_acc: 0.8428\n",
      "Epoch 873/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3227 - acc: 0.8616 - val_loss: 0.3599 - val_acc: 0.8428\n",
      "Epoch 874/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3209 - acc: 0.8613 - val_loss: 0.3601 - val_acc: 0.8435\n",
      "Epoch 875/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3240 - acc: 0.8614 - val_loss: 0.3595 - val_acc: 0.8442\n",
      "Epoch 876/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3220 - acc: 0.8621 - val_loss: 0.3599 - val_acc: 0.8455\n",
      "Epoch 877/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3217 - acc: 0.8631 - val_loss: 0.3596 - val_acc: 0.8442\n",
      "Epoch 878/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3240 - acc: 0.8628 - val_loss: 0.3596 - val_acc: 0.8449\n",
      "Epoch 879/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3208 - acc: 0.8646 - val_loss: 0.3600 - val_acc: 0.8462\n",
      "Epoch 880/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3182 - acc: 0.8626 - val_loss: 0.3594 - val_acc: 0.8455\n",
      "Epoch 881/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3195 - acc: 0.8668 - val_loss: 0.3600 - val_acc: 0.8435\n",
      "Epoch 882/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3208 - acc: 0.8616 - val_loss: 0.3596 - val_acc: 0.8435\n",
      "Epoch 883/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3200 - acc: 0.8639 - val_loss: 0.3592 - val_acc: 0.8449\n",
      "Epoch 884/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3204 - acc: 0.8619 - val_loss: 0.3596 - val_acc: 0.8435\n",
      "Epoch 885/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3240 - acc: 0.8622 - val_loss: 0.3598 - val_acc: 0.8442\n",
      "Epoch 886/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3219 - acc: 0.8625 - val_loss: 0.3594 - val_acc: 0.8442\n",
      "Epoch 887/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3218 - acc: 0.8636 - val_loss: 0.3598 - val_acc: 0.8449\n",
      "Epoch 888/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3208 - acc: 0.8631 - val_loss: 0.3596 - val_acc: 0.8428\n",
      "Epoch 889/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3229 - acc: 0.8636 - val_loss: 0.3602 - val_acc: 0.8428\n",
      "Epoch 890/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3189 - acc: 0.8656 - val_loss: 0.3596 - val_acc: 0.8442\n",
      "Epoch 891/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3192 - acc: 0.8641 - val_loss: 0.3598 - val_acc: 0.8442\n",
      "Epoch 892/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3207 - acc: 0.8645 - val_loss: 0.3593 - val_acc: 0.8428\n",
      "Epoch 893/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3201 - acc: 0.8639 - val_loss: 0.3591 - val_acc: 0.8435\n",
      "Epoch 894/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3186 - acc: 0.8651 - val_loss: 0.3600 - val_acc: 0.8442\n",
      "Epoch 895/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3192 - acc: 0.8652 - val_loss: 0.3594 - val_acc: 0.8428\n",
      "Epoch 896/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3202 - acc: 0.8634 - val_loss: 0.3594 - val_acc: 0.8442\n",
      "Epoch 897/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3191 - acc: 0.8664 - val_loss: 0.3592 - val_acc: 0.8428\n",
      "Epoch 898/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3217 - acc: 0.8653 - val_loss: 0.3593 - val_acc: 0.8449\n",
      "Epoch 899/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3182 - acc: 0.8654 - val_loss: 0.3594 - val_acc: 0.8442\n",
      "Epoch 900/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3227 - acc: 0.8631 - val_loss: 0.3598 - val_acc: 0.8442\n",
      "Epoch 901/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3203 - acc: 0.8635 - val_loss: 0.3598 - val_acc: 0.8455\n",
      "Epoch 902/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3197 - acc: 0.8646 - val_loss: 0.3597 - val_acc: 0.8428\n",
      "Epoch 903/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3208 - acc: 0.8646 - val_loss: 0.3594 - val_acc: 0.8428\n",
      "Epoch 904/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3202 - acc: 0.8649 - val_loss: 0.3596 - val_acc: 0.8421\n",
      "Epoch 905/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3187 - acc: 0.8659 - val_loss: 0.3590 - val_acc: 0.8428\n",
      "Epoch 906/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3182 - acc: 0.8645 - val_loss: 0.3594 - val_acc: 0.8449\n",
      "Epoch 907/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3189 - acc: 0.8647 - val_loss: 0.3592 - val_acc: 0.8428\n",
      "Epoch 908/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3199 - acc: 0.8658 - val_loss: 0.3592 - val_acc: 0.8435\n",
      "Epoch 909/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.3191 - acc: 0.8622 - val_loss: 0.3595 - val_acc: 0.8435\n",
      "Epoch 910/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3192 - acc: 0.8640 - val_loss: 0.3592 - val_acc: 0.8449\n",
      "Epoch 911/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3216 - acc: 0.8587 - val_loss: 0.3595 - val_acc: 0.8476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3182 - acc: 0.8636 - val_loss: 0.3591 - val_acc: 0.8462\n",
      "Epoch 913/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3195 - acc: 0.8637 - val_loss: 0.3594 - val_acc: 0.8455\n",
      "Epoch 914/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3200 - acc: 0.8624 - val_loss: 0.3596 - val_acc: 0.8449\n",
      "Epoch 915/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3205 - acc: 0.8656 - val_loss: 0.3589 - val_acc: 0.8469\n",
      "Epoch 916/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3171 - acc: 0.8688 - val_loss: 0.3592 - val_acc: 0.8455\n",
      "Epoch 917/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3210 - acc: 0.8639 - val_loss: 0.3590 - val_acc: 0.8449\n",
      "Epoch 918/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3196 - acc: 0.8647 - val_loss: 0.3591 - val_acc: 0.8455\n",
      "Epoch 919/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3169 - acc: 0.8650 - val_loss: 0.3596 - val_acc: 0.8435\n",
      "Epoch 920/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3183 - acc: 0.8664 - val_loss: 0.3591 - val_acc: 0.8435\n",
      "Epoch 921/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3200 - acc: 0.8652 - val_loss: 0.3593 - val_acc: 0.8449\n",
      "Epoch 922/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3215 - acc: 0.8622 - val_loss: 0.3591 - val_acc: 0.8469\n",
      "Epoch 923/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3156 - acc: 0.8694 - val_loss: 0.3589 - val_acc: 0.8428\n",
      "Epoch 924/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3153 - acc: 0.8676 - val_loss: 0.3593 - val_acc: 0.8442\n",
      "Epoch 925/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3198 - acc: 0.8646 - val_loss: 0.3593 - val_acc: 0.8449\n",
      "Epoch 926/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3156 - acc: 0.8676 - val_loss: 0.3587 - val_acc: 0.8442\n",
      "Epoch 927/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3194 - acc: 0.8654 - val_loss: 0.3590 - val_acc: 0.8442\n",
      "Epoch 928/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3188 - acc: 0.8652 - val_loss: 0.3583 - val_acc: 0.8421\n",
      "Epoch 929/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3201 - acc: 0.8644 - val_loss: 0.3581 - val_acc: 0.8435\n",
      "Epoch 930/10000\n",
      "13284/13284 [==============================] - 1s 51us/sample - loss: 0.3154 - acc: 0.8670 - val_loss: 0.3583 - val_acc: 0.8449\n",
      "Epoch 931/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3164 - acc: 0.8677 - val_loss: 0.3589 - val_acc: 0.8435\n",
      "Epoch 932/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3183 - acc: 0.8666 - val_loss: 0.3580 - val_acc: 0.8421\n",
      "Epoch 933/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3171 - acc: 0.8666 - val_loss: 0.3587 - val_acc: 0.8449\n",
      "Epoch 934/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3179 - acc: 0.8677 - val_loss: 0.3588 - val_acc: 0.8428\n",
      "Epoch 935/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3187 - acc: 0.8638 - val_loss: 0.3592 - val_acc: 0.8442\n",
      "Epoch 936/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3163 - acc: 0.8653 - val_loss: 0.3586 - val_acc: 0.8442\n",
      "Epoch 937/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3171 - acc: 0.8686 - val_loss: 0.3589 - val_acc: 0.8428\n",
      "Epoch 938/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3152 - acc: 0.8647 - val_loss: 0.3585 - val_acc: 0.8442\n",
      "Epoch 939/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3183 - acc: 0.8653 - val_loss: 0.3589 - val_acc: 0.8428\n",
      "Epoch 940/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3159 - acc: 0.8657 - val_loss: 0.3594 - val_acc: 0.8449\n",
      "Epoch 941/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3184 - acc: 0.8656 - val_loss: 0.3586 - val_acc: 0.8428\n",
      "Epoch 942/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3164 - acc: 0.8649 - val_loss: 0.3584 - val_acc: 0.8442\n",
      "Epoch 943/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3157 - acc: 0.8665 - val_loss: 0.3586 - val_acc: 0.8428\n",
      "Epoch 944/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3201 - acc: 0.8640 - val_loss: 0.3591 - val_acc: 0.8442\n",
      "Epoch 945/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3164 - acc: 0.8674 - val_loss: 0.3584 - val_acc: 0.8428\n",
      "Epoch 946/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3136 - acc: 0.8665 - val_loss: 0.3584 - val_acc: 0.8442\n",
      "Epoch 947/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3165 - acc: 0.8668 - val_loss: 0.3582 - val_acc: 0.8442\n",
      "Epoch 948/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3163 - acc: 0.8656 - val_loss: 0.3587 - val_acc: 0.8449\n",
      "Epoch 949/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3135 - acc: 0.8680 - val_loss: 0.3584 - val_acc: 0.8455\n",
      "Epoch 950/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3189 - acc: 0.8643 - val_loss: 0.3576 - val_acc: 0.8442\n",
      "Epoch 951/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3141 - acc: 0.8692 - val_loss: 0.3583 - val_acc: 0.8428\n",
      "Epoch 952/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3180 - acc: 0.8646 - val_loss: 0.3579 - val_acc: 0.8442\n",
      "Epoch 953/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3193 - acc: 0.8646 - val_loss: 0.3578 - val_acc: 0.8455\n",
      "Epoch 954/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3154 - acc: 0.8677 - val_loss: 0.3582 - val_acc: 0.8421\n",
      "Epoch 955/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3157 - acc: 0.8675 - val_loss: 0.3588 - val_acc: 0.8435\n",
      "Epoch 956/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3192 - acc: 0.8659 - val_loss: 0.3582 - val_acc: 0.8435\n",
      "Epoch 957/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3173 - acc: 0.8661 - val_loss: 0.3590 - val_acc: 0.8449\n",
      "Epoch 958/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3176 - acc: 0.8655 - val_loss: 0.3581 - val_acc: 0.8428\n",
      "Epoch 959/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3151 - acc: 0.8687 - val_loss: 0.3587 - val_acc: 0.8415\n",
      "Epoch 960/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3150 - acc: 0.8639 - val_loss: 0.3583 - val_acc: 0.8428\n",
      "Epoch 961/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3174 - acc: 0.8669 - val_loss: 0.3584 - val_acc: 0.8449\n",
      "Epoch 962/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3181 - acc: 0.8652 - val_loss: 0.3580 - val_acc: 0.8421\n",
      "Epoch 963/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3156 - acc: 0.8660 - val_loss: 0.3586 - val_acc: 0.8449\n",
      "Epoch 964/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3134 - acc: 0.8697 - val_loss: 0.3583 - val_acc: 0.8442\n",
      "Epoch 965/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3162 - acc: 0.8643 - val_loss: 0.3584 - val_acc: 0.8428\n",
      "Epoch 966/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3162 - acc: 0.8662 - val_loss: 0.3584 - val_acc: 0.8449\n",
      "Epoch 967/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3153 - acc: 0.8662 - val_loss: 0.3580 - val_acc: 0.8442\n",
      "Epoch 968/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3193 - acc: 0.8632 - val_loss: 0.3582 - val_acc: 0.8455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 969/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3129 - acc: 0.8705 - val_loss: 0.3577 - val_acc: 0.8428\n",
      "Epoch 970/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3137 - acc: 0.8669 - val_loss: 0.3584 - val_acc: 0.8462\n",
      "Epoch 971/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3178 - acc: 0.8647 - val_loss: 0.3574 - val_acc: 0.8455\n",
      "Epoch 972/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3156 - acc: 0.8671 - val_loss: 0.3577 - val_acc: 0.8449\n",
      "Epoch 973/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3154 - acc: 0.8675 - val_loss: 0.3577 - val_acc: 0.8462\n",
      "Epoch 974/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3103 - acc: 0.8692 - val_loss: 0.3578 - val_acc: 0.8455\n",
      "Epoch 975/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3171 - acc: 0.8656 - val_loss: 0.3580 - val_acc: 0.8435\n",
      "Epoch 976/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3127 - acc: 0.8694 - val_loss: 0.3581 - val_acc: 0.8442\n",
      "Epoch 977/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3155 - acc: 0.8690 - val_loss: 0.3579 - val_acc: 0.8455\n",
      "Epoch 978/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3146 - acc: 0.8668 - val_loss: 0.3579 - val_acc: 0.8421\n",
      "Epoch 979/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3169 - acc: 0.8674 - val_loss: 0.3581 - val_acc: 0.8428\n",
      "Epoch 980/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3114 - acc: 0.8684 - val_loss: 0.3578 - val_acc: 0.8449\n",
      "Epoch 981/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3143 - acc: 0.8694 - val_loss: 0.3574 - val_acc: 0.8435\n",
      "Epoch 982/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3090 - acc: 0.8683 - val_loss: 0.3580 - val_acc: 0.8455\n",
      "Epoch 983/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3132 - acc: 0.8692 - val_loss: 0.3581 - val_acc: 0.8469\n",
      "Epoch 984/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3139 - acc: 0.8667 - val_loss: 0.3580 - val_acc: 0.8489\n",
      "Epoch 985/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3176 - acc: 0.8654 - val_loss: 0.3574 - val_acc: 0.8435\n",
      "Epoch 986/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3125 - acc: 0.8671 - val_loss: 0.3583 - val_acc: 0.8469\n",
      "Epoch 987/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3143 - acc: 0.8660 - val_loss: 0.3576 - val_acc: 0.8482\n",
      "Epoch 988/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3146 - acc: 0.8667 - val_loss: 0.3579 - val_acc: 0.8469\n",
      "Epoch 989/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3191 - acc: 0.8645 - val_loss: 0.3574 - val_acc: 0.8455\n",
      "Epoch 990/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3124 - acc: 0.8666 - val_loss: 0.3577 - val_acc: 0.8442\n",
      "Epoch 991/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3149 - acc: 0.8669 - val_loss: 0.3576 - val_acc: 0.8428\n",
      "Epoch 992/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3143 - acc: 0.8677 - val_loss: 0.3581 - val_acc: 0.8455\n",
      "Epoch 993/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3146 - acc: 0.8684 - val_loss: 0.3579 - val_acc: 0.8449\n",
      "Epoch 994/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3120 - acc: 0.8695 - val_loss: 0.3577 - val_acc: 0.8449\n",
      "Epoch 995/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3121 - acc: 0.8698 - val_loss: 0.3578 - val_acc: 0.8462\n",
      "Epoch 996/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3179 - acc: 0.8640 - val_loss: 0.3571 - val_acc: 0.8449\n",
      "Epoch 997/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3123 - acc: 0.8690 - val_loss: 0.3575 - val_acc: 0.8428\n",
      "Epoch 998/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3142 - acc: 0.8687 - val_loss: 0.3577 - val_acc: 0.8449\n",
      "Epoch 999/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3086 - acc: 0.8723 - val_loss: 0.3576 - val_acc: 0.8442\n",
      "Epoch 1000/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3122 - acc: 0.8661 - val_loss: 0.3574 - val_acc: 0.8482\n",
      "Epoch 1001/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3143 - acc: 0.8677 - val_loss: 0.3576 - val_acc: 0.8476\n",
      "Epoch 1002/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3150 - acc: 0.8668 - val_loss: 0.3568 - val_acc: 0.8462\n",
      "Epoch 1003/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3138 - acc: 0.8674 - val_loss: 0.3567 - val_acc: 0.8449\n",
      "Epoch 1004/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3118 - acc: 0.8708 - val_loss: 0.3572 - val_acc: 0.8455\n",
      "Epoch 1005/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3130 - acc: 0.8683 - val_loss: 0.3567 - val_acc: 0.8469\n",
      "Epoch 1006/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3151 - acc: 0.8664 - val_loss: 0.3561 - val_acc: 0.8469\n",
      "Epoch 1007/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3161 - acc: 0.8673 - val_loss: 0.3567 - val_acc: 0.8435\n",
      "Epoch 1008/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3140 - acc: 0.8695 - val_loss: 0.3570 - val_acc: 0.8455\n",
      "Epoch 1009/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3112 - acc: 0.8692 - val_loss: 0.3565 - val_acc: 0.8462\n",
      "Epoch 1010/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3109 - acc: 0.8699 - val_loss: 0.3571 - val_acc: 0.8462\n",
      "Epoch 1011/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3121 - acc: 0.8680 - val_loss: 0.3574 - val_acc: 0.8482\n",
      "Epoch 1012/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3108 - acc: 0.8692 - val_loss: 0.3569 - val_acc: 0.8455\n",
      "Epoch 1013/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3112 - acc: 0.8692 - val_loss: 0.3566 - val_acc: 0.8482\n",
      "Epoch 1014/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3142 - acc: 0.8694 - val_loss: 0.3566 - val_acc: 0.8462\n",
      "Epoch 1015/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3178 - acc: 0.8663 - val_loss: 0.3565 - val_acc: 0.8469\n",
      "Epoch 1016/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3119 - acc: 0.8699 - val_loss: 0.3570 - val_acc: 0.8489\n",
      "Epoch 1017/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3131 - acc: 0.8701 - val_loss: 0.3563 - val_acc: 0.8455\n",
      "Epoch 1018/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3134 - acc: 0.8689 - val_loss: 0.3561 - val_acc: 0.8462\n",
      "Epoch 1019/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3128 - acc: 0.8682 - val_loss: 0.3561 - val_acc: 0.8476\n",
      "Epoch 1020/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3129 - acc: 0.8685 - val_loss: 0.3562 - val_acc: 0.8462\n",
      "Epoch 1021/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3114 - acc: 0.8712 - val_loss: 0.3559 - val_acc: 0.8462\n",
      "Epoch 1022/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3150 - acc: 0.8680 - val_loss: 0.3562 - val_acc: 0.8462\n",
      "Epoch 1023/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3115 - acc: 0.8694 - val_loss: 0.3565 - val_acc: 0.8469\n",
      "Epoch 1024/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3122 - acc: 0.8683 - val_loss: 0.3567 - val_acc: 0.8489\n",
      "Epoch 1025/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3128 - acc: 0.8674 - val_loss: 0.3559 - val_acc: 0.8489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1026/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3143 - acc: 0.8675 - val_loss: 0.3561 - val_acc: 0.8469\n",
      "Epoch 1027/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3100 - acc: 0.8713 - val_loss: 0.3561 - val_acc: 0.8476\n",
      "Epoch 1028/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3086 - acc: 0.8715 - val_loss: 0.3561 - val_acc: 0.8449\n",
      "Epoch 1029/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3106 - acc: 0.8681 - val_loss: 0.3556 - val_acc: 0.8469\n",
      "Epoch 1030/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3127 - acc: 0.8688 - val_loss: 0.3556 - val_acc: 0.8469\n",
      "Epoch 1031/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3086 - acc: 0.8702 - val_loss: 0.3557 - val_acc: 0.8476\n",
      "Epoch 1032/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3109 - acc: 0.8707 - val_loss: 0.3556 - val_acc: 0.8455\n",
      "Epoch 1033/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3122 - acc: 0.8687 - val_loss: 0.3559 - val_acc: 0.8462\n",
      "Epoch 1034/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3092 - acc: 0.8703 - val_loss: 0.3558 - val_acc: 0.8469\n",
      "Epoch 1035/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3122 - acc: 0.8695 - val_loss: 0.3562 - val_acc: 0.8503\n",
      "Epoch 1036/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3159 - acc: 0.8680 - val_loss: 0.3559 - val_acc: 0.8476\n",
      "Epoch 1037/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3105 - acc: 0.8690 - val_loss: 0.3559 - val_acc: 0.8462\n",
      "Epoch 1038/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.3100 - acc: 0.870 - 0s 26us/sample - loss: 0.3101 - acc: 0.8700 - val_loss: 0.3558 - val_acc: 0.8489\n",
      "Epoch 1039/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3097 - acc: 0.8697 - val_loss: 0.3563 - val_acc: 0.8482\n",
      "Epoch 1040/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3142 - acc: 0.8678 - val_loss: 0.3564 - val_acc: 0.8476\n",
      "Epoch 1041/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3109 - acc: 0.8700 - val_loss: 0.3563 - val_acc: 0.8476\n",
      "Epoch 1042/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3083 - acc: 0.8727 - val_loss: 0.3562 - val_acc: 0.8476\n",
      "Epoch 1043/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3120 - acc: 0.8673 - val_loss: 0.3560 - val_acc: 0.8469\n",
      "Epoch 1044/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3104 - acc: 0.8707 - val_loss: 0.3560 - val_acc: 0.8503\n",
      "Epoch 1045/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3122 - acc: 0.8687 - val_loss: 0.3550 - val_acc: 0.8489\n",
      "Epoch 1046/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.3101 - acc: 0.869 - 0s 27us/sample - loss: 0.3099 - acc: 0.8695 - val_loss: 0.3554 - val_acc: 0.8469\n",
      "Epoch 1047/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3127 - acc: 0.8698 - val_loss: 0.3565 - val_acc: 0.8489\n",
      "Epoch 1048/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3116 - acc: 0.8680 - val_loss: 0.3549 - val_acc: 0.8489\n",
      "Epoch 1049/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3088 - acc: 0.8710 - val_loss: 0.3547 - val_acc: 0.8476\n",
      "Epoch 1050/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3128 - acc: 0.8667 - val_loss: 0.3550 - val_acc: 0.8482\n",
      "Epoch 1051/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3127 - acc: 0.8690 - val_loss: 0.3550 - val_acc: 0.8489\n",
      "Epoch 1052/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3064 - acc: 0.8710 - val_loss: 0.3555 - val_acc: 0.8496\n",
      "Epoch 1053/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3125 - acc: 0.8677 - val_loss: 0.3553 - val_acc: 0.8509\n",
      "Epoch 1054/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3140 - acc: 0.8702 - val_loss: 0.3550 - val_acc: 0.8489\n",
      "Epoch 1055/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3119 - acc: 0.8702 - val_loss: 0.3550 - val_acc: 0.8496\n",
      "Epoch 1056/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3096 - acc: 0.8691 - val_loss: 0.3546 - val_acc: 0.8516\n",
      "Epoch 1057/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3097 - acc: 0.8707 - val_loss: 0.3557 - val_acc: 0.8482\n",
      "Epoch 1058/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3130 - acc: 0.8671 - val_loss: 0.3545 - val_acc: 0.8489\n",
      "Epoch 1059/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3105 - acc: 0.8675 - val_loss: 0.3549 - val_acc: 0.8503\n",
      "Epoch 1060/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3082 - acc: 0.8713 - val_loss: 0.3551 - val_acc: 0.8503\n",
      "Epoch 1061/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3104 - acc: 0.8674 - val_loss: 0.3550 - val_acc: 0.8503\n",
      "Epoch 1062/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3095 - acc: 0.8720 - val_loss: 0.3552 - val_acc: 0.8489\n",
      "Epoch 1063/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3117 - acc: 0.8681 - val_loss: 0.3550 - val_acc: 0.8503\n",
      "Epoch 1064/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3105 - acc: 0.8717 - val_loss: 0.3551 - val_acc: 0.8496\n",
      "Epoch 1065/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3090 - acc: 0.8727 - val_loss: 0.3551 - val_acc: 0.8482\n",
      "Epoch 1066/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3092 - acc: 0.8700 - val_loss: 0.3551 - val_acc: 0.8509\n",
      "Epoch 1067/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3116 - acc: 0.8692 - val_loss: 0.3547 - val_acc: 0.8469\n",
      "Epoch 1068/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3091 - acc: 0.8707 - val_loss: 0.3551 - val_acc: 0.8482\n",
      "Epoch 1069/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3102 - acc: 0.8704 - val_loss: 0.3547 - val_acc: 0.8503\n",
      "Epoch 1070/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3079 - acc: 0.8712 - val_loss: 0.3549 - val_acc: 0.8503\n",
      "Epoch 1071/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3088 - acc: 0.8708 - val_loss: 0.3548 - val_acc: 0.8476\n",
      "Epoch 1072/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3038 - acc: 0.8726 - val_loss: 0.3550 - val_acc: 0.8503\n",
      "Epoch 1073/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3071 - acc: 0.8711 - val_loss: 0.3550 - val_acc: 0.8482\n",
      "Epoch 1074/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3113 - acc: 0.8685 - val_loss: 0.3541 - val_acc: 0.8503\n",
      "Epoch 1075/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3036 - acc: 0.8747 - val_loss: 0.3550 - val_acc: 0.8509\n",
      "Epoch 1076/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3091 - acc: 0.8689 - val_loss: 0.3543 - val_acc: 0.8516\n",
      "Epoch 1077/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3097 - acc: 0.8683 - val_loss: 0.3545 - val_acc: 0.8503\n",
      "Epoch 1078/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3096 - acc: 0.8685 - val_loss: 0.3546 - val_acc: 0.8509\n",
      "Epoch 1079/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3073 - acc: 0.8699 - val_loss: 0.3545 - val_acc: 0.8489\n",
      "Epoch 1080/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3073 - acc: 0.8698 - val_loss: 0.3543 - val_acc: 0.8496\n",
      "Epoch 1081/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3121 - acc: 0.8665 - val_loss: 0.3540 - val_acc: 0.8530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1082/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3083 - acc: 0.8726 - val_loss: 0.3540 - val_acc: 0.8503\n",
      "Epoch 1083/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3073 - acc: 0.8708 - val_loss: 0.3537 - val_acc: 0.8496\n",
      "Epoch 1084/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3068 - acc: 0.8733 - val_loss: 0.3545 - val_acc: 0.8537\n",
      "Epoch 1085/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3058 - acc: 0.8708 - val_loss: 0.3547 - val_acc: 0.8503\n",
      "Epoch 1086/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3084 - acc: 0.8686 - val_loss: 0.3544 - val_acc: 0.8516\n",
      "Epoch 1087/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3101 - acc: 0.8685 - val_loss: 0.3543 - val_acc: 0.8496\n",
      "Epoch 1088/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3091 - acc: 0.8715 - val_loss: 0.3546 - val_acc: 0.8509\n",
      "Epoch 1089/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3101 - acc: 0.8692 - val_loss: 0.3544 - val_acc: 0.8496\n",
      "Epoch 1090/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3064 - acc: 0.8704 - val_loss: 0.3538 - val_acc: 0.8496\n",
      "Epoch 1091/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3057 - acc: 0.8745 - val_loss: 0.3542 - val_acc: 0.8509\n",
      "Epoch 1092/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3084 - acc: 0.8705 - val_loss: 0.3545 - val_acc: 0.8503\n",
      "Epoch 1093/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3082 - acc: 0.8702 - val_loss: 0.3544 - val_acc: 0.8516\n",
      "Epoch 1094/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3074 - acc: 0.8710 - val_loss: 0.3543 - val_acc: 0.8496\n",
      "Epoch 1095/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3061 - acc: 0.8726 - val_loss: 0.3548 - val_acc: 0.8496\n",
      "Epoch 1096/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3085 - acc: 0.8716 - val_loss: 0.3541 - val_acc: 0.8489\n",
      "Epoch 1097/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3108 - acc: 0.8683 - val_loss: 0.3545 - val_acc: 0.8469\n",
      "Epoch 1098/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3114 - acc: 0.8675 - val_loss: 0.3537 - val_acc: 0.8516\n",
      "Epoch 1099/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3064 - acc: 0.8711 - val_loss: 0.3546 - val_acc: 0.8489\n",
      "Epoch 1100/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3077 - acc: 0.8692 - val_loss: 0.3543 - val_acc: 0.8482\n",
      "Epoch 1101/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3086 - acc: 0.8694 - val_loss: 0.3535 - val_acc: 0.8482\n",
      "Epoch 1102/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3103 - acc: 0.8681 - val_loss: 0.3541 - val_acc: 0.8503\n",
      "Epoch 1103/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3082 - acc: 0.8721 - val_loss: 0.3539 - val_acc: 0.8469\n",
      "Epoch 1104/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3072 - acc: 0.8723 - val_loss: 0.3539 - val_acc: 0.8496\n",
      "Epoch 1105/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3061 - acc: 0.8717 - val_loss: 0.3539 - val_acc: 0.8482\n",
      "Epoch 1106/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3061 - acc: 0.8719 - val_loss: 0.3547 - val_acc: 0.8476\n",
      "Epoch 1107/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3052 - acc: 0.8740 - val_loss: 0.3544 - val_acc: 0.8496\n",
      "Epoch 1108/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3083 - acc: 0.8692 - val_loss: 0.3542 - val_acc: 0.8496\n",
      "Epoch 1109/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3085 - acc: 0.8709 - val_loss: 0.3547 - val_acc: 0.8496\n",
      "Epoch 1110/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3063 - acc: 0.8729 - val_loss: 0.3542 - val_acc: 0.8503\n",
      "Epoch 1111/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3078 - acc: 0.8715 - val_loss: 0.3542 - val_acc: 0.8516\n",
      "Epoch 1112/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3050 - acc: 0.8747 - val_loss: 0.3544 - val_acc: 0.8523\n",
      "Epoch 1113/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3077 - acc: 0.8704 - val_loss: 0.3544 - val_acc: 0.8489\n",
      "Epoch 1114/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3058 - acc: 0.8736 - val_loss: 0.3553 - val_acc: 0.8455\n",
      "Epoch 1115/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3072 - acc: 0.8712 - val_loss: 0.3543 - val_acc: 0.8482\n",
      "Epoch 1116/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3049 - acc: 0.8753 - val_loss: 0.3545 - val_acc: 0.8516\n",
      "Epoch 1117/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3091 - acc: 0.8688 - val_loss: 0.3543 - val_acc: 0.8496\n",
      "Epoch 1118/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3089 - acc: 0.8733 - val_loss: 0.3545 - val_acc: 0.8509\n",
      "Epoch 1119/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3100 - acc: 0.8718 - val_loss: 0.3542 - val_acc: 0.8503\n",
      "Epoch 1120/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3069 - acc: 0.8721 - val_loss: 0.3545 - val_acc: 0.8503\n",
      "Epoch 1121/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3060 - acc: 0.8712 - val_loss: 0.3541 - val_acc: 0.8523\n",
      "Epoch 1122/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3072 - acc: 0.8725 - val_loss: 0.3547 - val_acc: 0.8530\n",
      "Epoch 1123/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3086 - acc: 0.8710 - val_loss: 0.3537 - val_acc: 0.8503\n",
      "Epoch 1124/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3067 - acc: 0.8725 - val_loss: 0.3541 - val_acc: 0.8503\n",
      "Epoch 1125/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3047 - acc: 0.8748 - val_loss: 0.3539 - val_acc: 0.8503\n",
      "Epoch 1126/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3069 - acc: 0.8716 - val_loss: 0.3536 - val_acc: 0.8516\n",
      "Epoch 1127/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3079 - acc: 0.8719 - val_loss: 0.3538 - val_acc: 0.8489\n",
      "Epoch 1128/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3096 - acc: 0.8683 - val_loss: 0.3540 - val_acc: 0.8516\n",
      "Epoch 1129/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3055 - acc: 0.8711 - val_loss: 0.3538 - val_acc: 0.8516\n",
      "Epoch 1130/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3072 - acc: 0.8713 - val_loss: 0.3539 - val_acc: 0.8489\n",
      "Epoch 1131/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3066 - acc: 0.8717 - val_loss: 0.3538 - val_acc: 0.8503\n",
      "Epoch 1132/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3087 - acc: 0.8687 - val_loss: 0.3547 - val_acc: 0.8503\n",
      "Epoch 1133/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3092 - acc: 0.8689 - val_loss: 0.3547 - val_acc: 0.8509\n",
      "Epoch 1134/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3065 - acc: 0.8711 - val_loss: 0.3533 - val_acc: 0.8509\n",
      "Epoch 1135/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3052 - acc: 0.8698 - val_loss: 0.3545 - val_acc: 0.8503\n",
      "Epoch 1136/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3086 - acc: 0.8694 - val_loss: 0.3539 - val_acc: 0.8516\n",
      "Epoch 1137/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3031 - acc: 0.8747 - val_loss: 0.3542 - val_acc: 0.8523\n",
      "Epoch 1138/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3078 - acc: 0.8720 - val_loss: 0.3543 - val_acc: 0.8523\n",
      "Epoch 1139/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3058 - acc: 0.8729 - val_loss: 0.3539 - val_acc: 0.8469\n",
      "Epoch 1140/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3052 - acc: 0.8741 - val_loss: 0.3535 - val_acc: 0.8503\n",
      "Epoch 1141/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3068 - acc: 0.8712 - val_loss: 0.3538 - val_acc: 0.8509\n",
      "Epoch 1142/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3050 - acc: 0.8717 - val_loss: 0.3536 - val_acc: 0.8516\n",
      "Epoch 1143/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3012 - acc: 0.8723 - val_loss: 0.3539 - val_acc: 0.8509\n",
      "Epoch 1144/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3028 - acc: 0.8713 - val_loss: 0.3534 - val_acc: 0.8496\n",
      "Epoch 1145/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3081 - acc: 0.8704 - val_loss: 0.3538 - val_acc: 0.8509\n",
      "Epoch 1146/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3089 - acc: 0.8708 - val_loss: 0.3537 - val_acc: 0.8530\n",
      "Epoch 1147/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3067 - acc: 0.8723 - val_loss: 0.3539 - val_acc: 0.8503\n",
      "Epoch 1148/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3042 - acc: 0.8761 - val_loss: 0.3538 - val_acc: 0.8523\n",
      "Epoch 1149/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3069 - acc: 0.8717 - val_loss: 0.3534 - val_acc: 0.8503\n",
      "Epoch 1150/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3063 - acc: 0.8721 - val_loss: 0.3534 - val_acc: 0.8503\n",
      "Epoch 1151/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3084 - acc: 0.8678 - val_loss: 0.3533 - val_acc: 0.8509\n",
      "Epoch 1152/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3033 - acc: 0.8746 - val_loss: 0.3544 - val_acc: 0.8523\n",
      "Epoch 1153/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.3062 - acc: 0.8741 - val_loss: 0.3532 - val_acc: 0.8523\n",
      "Epoch 1154/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3055 - acc: 0.8723 - val_loss: 0.3534 - val_acc: 0.8516\n",
      "Epoch 1155/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3043 - acc: 0.8724 - val_loss: 0.3535 - val_acc: 0.8509\n",
      "Epoch 1156/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3025 - acc: 0.8748 - val_loss: 0.3534 - val_acc: 0.8523\n",
      "Epoch 1157/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3112 - acc: 0.8690 - val_loss: 0.3537 - val_acc: 0.8516\n",
      "Epoch 1158/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3061 - acc: 0.8719 - val_loss: 0.3535 - val_acc: 0.8523\n",
      "Epoch 1159/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3048 - acc: 0.8718 - val_loss: 0.3533 - val_acc: 0.8537\n",
      "Epoch 1160/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3023 - acc: 0.8753 - val_loss: 0.3533 - val_acc: 0.8516\n",
      "Epoch 1161/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3035 - acc: 0.8732 - val_loss: 0.3530 - val_acc: 0.8516\n",
      "Epoch 1162/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3039 - acc: 0.8717 - val_loss: 0.3538 - val_acc: 0.8550\n",
      "Epoch 1163/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3073 - acc: 0.8698 - val_loss: 0.3541 - val_acc: 0.8550\n",
      "Epoch 1164/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3029 - acc: 0.8749 - val_loss: 0.3536 - val_acc: 0.8503\n",
      "Epoch 1165/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3064 - acc: 0.8720 - val_loss: 0.3536 - val_acc: 0.8543\n",
      "Epoch 1166/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3045 - acc: 0.8719 - val_loss: 0.3535 - val_acc: 0.8516\n",
      "Epoch 1167/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3019 - acc: 0.8732 - val_loss: 0.3541 - val_acc: 0.8503\n",
      "Epoch 1168/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3038 - acc: 0.8712 - val_loss: 0.3537 - val_acc: 0.8509\n",
      "Epoch 1169/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3064 - acc: 0.8730 - val_loss: 0.3537 - val_acc: 0.8530\n",
      "Epoch 1170/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3057 - acc: 0.8713 - val_loss: 0.3535 - val_acc: 0.8516\n",
      "Epoch 1171/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3064 - acc: 0.8738 - val_loss: 0.3540 - val_acc: 0.8509\n",
      "Epoch 1172/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3031 - acc: 0.8721 - val_loss: 0.3532 - val_acc: 0.8523\n",
      "Epoch 1173/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3018 - acc: 0.8742 - val_loss: 0.3532 - val_acc: 0.8530\n",
      "Epoch 1174/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3051 - acc: 0.8720 - val_loss: 0.3528 - val_acc: 0.8503\n",
      "Epoch 1175/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3012 - acc: 0.8744 - val_loss: 0.3527 - val_acc: 0.8516\n",
      "Epoch 1176/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3015 - acc: 0.8738 - val_loss: 0.3534 - val_acc: 0.8509\n",
      "Epoch 1177/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3037 - acc: 0.8725 - val_loss: 0.3525 - val_acc: 0.8503\n",
      "Epoch 1178/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3046 - acc: 0.8713 - val_loss: 0.3534 - val_acc: 0.8530\n",
      "Epoch 1179/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3012 - acc: 0.8738 - val_loss: 0.3533 - val_acc: 0.8523\n",
      "Epoch 1180/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3051 - acc: 0.8726 - val_loss: 0.3536 - val_acc: 0.8530\n",
      "Epoch 1181/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3052 - acc: 0.8711 - val_loss: 0.3531 - val_acc: 0.8537\n",
      "Epoch 1182/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3048 - acc: 0.8712 - val_loss: 0.3532 - val_acc: 0.8537\n",
      "Epoch 1183/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3053 - acc: 0.8713 - val_loss: 0.3532 - val_acc: 0.8516\n",
      "Epoch 1184/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3027 - acc: 0.8718 - val_loss: 0.3531 - val_acc: 0.8509\n",
      "Epoch 1185/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3063 - acc: 0.8724 - val_loss: 0.3531 - val_acc: 0.8516\n",
      "Epoch 1186/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3031 - acc: 0.8738 - val_loss: 0.3536 - val_acc: 0.8523\n",
      "Epoch 1187/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3064 - acc: 0.8726 - val_loss: 0.3530 - val_acc: 0.8523\n",
      "Epoch 1188/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3012 - acc: 0.8754 - val_loss: 0.3531 - val_acc: 0.8503\n",
      "Epoch 1189/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3008 - acc: 0.8738 - val_loss: 0.3530 - val_acc: 0.8550\n",
      "Epoch 1190/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3015 - acc: 0.8762 - val_loss: 0.3523 - val_acc: 0.8530\n",
      "Epoch 1191/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.2992 - acc: 0.8746 - val_loss: 0.3525 - val_acc: 0.8523\n",
      "Epoch 1192/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3050 - acc: 0.8704 - val_loss: 0.3527 - val_acc: 0.8550\n",
      "Epoch 1193/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3023 - acc: 0.8726 - val_loss: 0.3529 - val_acc: 0.8530\n",
      "Epoch 1194/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3023 - acc: 0.8734 - val_loss: 0.3535 - val_acc: 0.8496\n",
      "Epoch 1195/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3021 - acc: 0.8738 - val_loss: 0.3527 - val_acc: 0.8550\n",
      "Epoch 1196/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3036 - acc: 0.8738 - val_loss: 0.3528 - val_acc: 0.8537\n",
      "Epoch 1197/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3004 - acc: 0.8723 - val_loss: 0.3529 - val_acc: 0.8537\n",
      "Epoch 1198/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3034 - acc: 0.8739 - val_loss: 0.3527 - val_acc: 0.8577\n",
      "Epoch 1199/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3020 - acc: 0.8734 - val_loss: 0.3529 - val_acc: 0.8557\n",
      "Epoch 1200/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3012 - acc: 0.8736 - val_loss: 0.3528 - val_acc: 0.8523\n",
      "Epoch 1201/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3019 - acc: 0.8729 - val_loss: 0.3527 - val_acc: 0.8523\n",
      "Epoch 1202/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3051 - acc: 0.8707 - val_loss: 0.3527 - val_acc: 0.8523\n",
      "Epoch 1203/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3009 - acc: 0.8740 - val_loss: 0.3527 - val_acc: 0.8543\n",
      "Epoch 1204/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3014 - acc: 0.8749 - val_loss: 0.3525 - val_acc: 0.8543\n",
      "Epoch 1205/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3084 - acc: 0.8707 - val_loss: 0.3532 - val_acc: 0.8530\n",
      "Epoch 1206/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3060 - acc: 0.8717 - val_loss: 0.3527 - val_acc: 0.8523\n",
      "Epoch 1207/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3031 - acc: 0.8719 - val_loss: 0.3526 - val_acc: 0.8564\n",
      "Epoch 1208/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3022 - acc: 0.8765 - val_loss: 0.3529 - val_acc: 0.8537\n",
      "Epoch 1209/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3029 - acc: 0.8723 - val_loss: 0.3523 - val_acc: 0.8516\n",
      "Epoch 1210/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3002 - acc: 0.8763 - val_loss: 0.3524 - val_acc: 0.8543\n",
      "Epoch 1211/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2995 - acc: 0.8740 - val_loss: 0.3524 - val_acc: 0.8530\n",
      "Epoch 1212/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3049 - acc: 0.8714 - val_loss: 0.3533 - val_acc: 0.8523\n",
      "Epoch 1213/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3026 - acc: 0.8706 - val_loss: 0.3522 - val_acc: 0.8509\n",
      "Epoch 1214/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3027 - acc: 0.8725 - val_loss: 0.3523 - val_acc: 0.8523\n",
      "Epoch 1215/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3015 - acc: 0.8711 - val_loss: 0.3524 - val_acc: 0.8530\n",
      "Epoch 1216/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3035 - acc: 0.8694 - val_loss: 0.3520 - val_acc: 0.8537\n",
      "Epoch 1217/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3016 - acc: 0.8708 - val_loss: 0.3528 - val_acc: 0.8503\n",
      "Epoch 1218/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3023 - acc: 0.8722 - val_loss: 0.3518 - val_acc: 0.8543\n",
      "Epoch 1219/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3048 - acc: 0.8726 - val_loss: 0.3523 - val_acc: 0.8537\n",
      "Epoch 1220/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3019 - acc: 0.8762 - val_loss: 0.3518 - val_acc: 0.8543\n",
      "Epoch 1221/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3028 - acc: 0.8720 - val_loss: 0.3528 - val_acc: 0.8523\n",
      "Epoch 1222/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2994 - acc: 0.8738 - val_loss: 0.3529 - val_acc: 0.8516\n",
      "Epoch 1223/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3024 - acc: 0.8711 - val_loss: 0.3524 - val_acc: 0.8543\n",
      "Epoch 1224/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3016 - acc: 0.8758 - val_loss: 0.3524 - val_acc: 0.8537\n",
      "Epoch 1225/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2995 - acc: 0.8746 - val_loss: 0.3522 - val_acc: 0.8537\n",
      "Epoch 1226/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.2980 - acc: 0.8746- ETA: 0s - loss: 0.2989 - acc: 0.87 - 0s 28us/sample - loss: 0.3000 - acc: 0.8742 - val_loss: 0.3517 - val_acc: 0.8543\n",
      "Epoch 1227/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3025 - acc: 0.8725 - val_loss: 0.3521 - val_acc: 0.8537\n",
      "Epoch 1228/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3008 - acc: 0.8758 - val_loss: 0.3516 - val_acc: 0.8523\n",
      "Epoch 1229/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3009 - acc: 0.8750 - val_loss: 0.3525 - val_acc: 0.8516\n",
      "Epoch 1230/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3027 - acc: 0.8735 - val_loss: 0.3525 - val_acc: 0.8550\n",
      "Epoch 1231/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3023 - acc: 0.8740 - val_loss: 0.3519 - val_acc: 0.8550\n",
      "Epoch 1232/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3021 - acc: 0.8738 - val_loss: 0.3522 - val_acc: 0.8516\n",
      "Epoch 1233/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3008 - acc: 0.8765 - val_loss: 0.3524 - val_acc: 0.8509\n",
      "Epoch 1234/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2993 - acc: 0.8744 - val_loss: 0.3523 - val_acc: 0.8523\n",
      "Epoch 1235/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3037 - acc: 0.8706 - val_loss: 0.3522 - val_acc: 0.8530\n",
      "Epoch 1236/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3031 - acc: 0.8756 - val_loss: 0.3525 - val_acc: 0.8523\n",
      "Epoch 1237/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2998 - acc: 0.8730 - val_loss: 0.3514 - val_acc: 0.8543\n",
      "Epoch 1238/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3019 - acc: 0.8741 - val_loss: 0.3514 - val_acc: 0.8543\n",
      "Epoch 1239/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2987 - acc: 0.8773 - val_loss: 0.3513 - val_acc: 0.8509\n",
      "Epoch 1240/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3028 - acc: 0.8723 - val_loss: 0.3514 - val_acc: 0.8523\n",
      "Epoch 1241/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2996 - acc: 0.8751 - val_loss: 0.3515 - val_acc: 0.8509\n",
      "Epoch 1242/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2986 - acc: 0.8760 - val_loss: 0.3515 - val_acc: 0.8516\n",
      "Epoch 1243/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2987 - acc: 0.8744 - val_loss: 0.3509 - val_acc: 0.8523\n",
      "Epoch 1244/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3009 - acc: 0.8726 - val_loss: 0.3516 - val_acc: 0.8530\n",
      "Epoch 1245/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.3016 - acc: 0.8732 - val_loss: 0.3516 - val_acc: 0.8537\n",
      "Epoch 1246/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3026 - acc: 0.8711 - val_loss: 0.3518 - val_acc: 0.8503\n",
      "Epoch 1247/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3018 - acc: 0.8729 - val_loss: 0.3515 - val_acc: 0.8516\n",
      "Epoch 1248/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2980 - acc: 0.8755 - val_loss: 0.3517 - val_acc: 0.8509\n",
      "Epoch 1249/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2994 - acc: 0.8733 - val_loss: 0.3512 - val_acc: 0.8503\n",
      "Epoch 1250/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2973 - acc: 0.8761 - val_loss: 0.3513 - val_acc: 0.8516\n",
      "Epoch 1251/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3010 - acc: 0.8753 - val_loss: 0.3515 - val_acc: 0.8509\n",
      "Epoch 1252/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3007 - acc: 0.8734 - val_loss: 0.3512 - val_acc: 0.8523\n",
      "Epoch 1253/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2978 - acc: 0.8747 - val_loss: 0.3516 - val_acc: 0.8503\n",
      "Epoch 1254/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3002 - acc: 0.8724 - val_loss: 0.3514 - val_acc: 0.8523\n",
      "Epoch 1255/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2997 - acc: 0.8756 - val_loss: 0.3512 - val_acc: 0.8523\n",
      "Epoch 1256/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2992 - acc: 0.8768 - val_loss: 0.3522 - val_acc: 0.8523\n",
      "Epoch 1257/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2981 - acc: 0.8735 - val_loss: 0.3514 - val_acc: 0.8509\n",
      "Epoch 1258/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3047 - acc: 0.8713 - val_loss: 0.3517 - val_acc: 0.8509\n",
      "Epoch 1259/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3012 - acc: 0.8748 - val_loss: 0.3514 - val_acc: 0.8503\n",
      "Epoch 1260/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3000 - acc: 0.8729 - val_loss: 0.3511 - val_acc: 0.8530\n",
      "Epoch 1261/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2973 - acc: 0.8776 - val_loss: 0.3512 - val_acc: 0.8503\n",
      "Epoch 1262/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2982 - acc: 0.8741 - val_loss: 0.3515 - val_acc: 0.8489\n",
      "Epoch 1263/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2978 - acc: 0.8740 - val_loss: 0.3512 - val_acc: 0.8496\n",
      "Epoch 1264/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3017 - acc: 0.8745 - val_loss: 0.3508 - val_acc: 0.8530\n",
      "Epoch 1265/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2989 - acc: 0.8750 - val_loss: 0.3514 - val_acc: 0.8496\n",
      "Epoch 1266/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3029 - acc: 0.8727 - val_loss: 0.3505 - val_acc: 0.8523\n",
      "Epoch 1267/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3006 - acc: 0.8717 - val_loss: 0.3514 - val_acc: 0.8530\n",
      "Epoch 1268/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3000 - acc: 0.8733 - val_loss: 0.3510 - val_acc: 0.8530\n",
      "Epoch 1269/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3010 - acc: 0.8738 - val_loss: 0.3515 - val_acc: 0.8537\n",
      "Epoch 1270/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3006 - acc: 0.8720 - val_loss: 0.3513 - val_acc: 0.8523\n",
      "Epoch 1271/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2945 - acc: 0.8769 - val_loss: 0.3513 - val_acc: 0.8530\n",
      "Epoch 1272/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2957 - acc: 0.8779 - val_loss: 0.3513 - val_acc: 0.8530\n",
      "Epoch 1273/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3021 - acc: 0.8734 - val_loss: 0.3504 - val_acc: 0.8530\n",
      "Epoch 1274/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3013 - acc: 0.8735 - val_loss: 0.3514 - val_acc: 0.8543\n",
      "Epoch 1275/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3003 - acc: 0.8761 - val_loss: 0.3508 - val_acc: 0.8543\n",
      "Epoch 1276/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2977 - acc: 0.8764 - val_loss: 0.3518 - val_acc: 0.8516\n",
      "Epoch 1277/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3000 - acc: 0.8741 - val_loss: 0.3508 - val_acc: 0.8509\n",
      "Epoch 1278/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2959 - acc: 0.8764 - val_loss: 0.3515 - val_acc: 0.8496\n",
      "Epoch 1279/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2987 - acc: 0.8745 - val_loss: 0.3508 - val_acc: 0.8523\n",
      "Epoch 1280/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2954 - acc: 0.8762 - val_loss: 0.3513 - val_acc: 0.8516\n",
      "Epoch 1281/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3036 - acc: 0.8711 - val_loss: 0.3503 - val_acc: 0.8530\n",
      "Epoch 1282/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3009 - acc: 0.8743 - val_loss: 0.3508 - val_acc: 0.8509\n",
      "Epoch 1283/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2995 - acc: 0.8729 - val_loss: 0.3513 - val_acc: 0.8489\n",
      "Epoch 1284/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.2997 - acc: 0.8744 - val_loss: 0.3504 - val_acc: 0.8523\n",
      "Epoch 1285/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3007 - acc: 0.8735 - val_loss: 0.3505 - val_acc: 0.8523\n",
      "Epoch 1286/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2984 - acc: 0.8730 - val_loss: 0.3499 - val_acc: 0.8516\n",
      "Epoch 1287/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2967 - acc: 0.8756 - val_loss: 0.3507 - val_acc: 0.8509\n",
      "Epoch 1288/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2993 - acc: 0.8722 - val_loss: 0.3507 - val_acc: 0.8516\n",
      "Epoch 1289/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2983 - acc: 0.8744 - val_loss: 0.3510 - val_acc: 0.8516\n",
      "Epoch 1290/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2973 - acc: 0.8757 - val_loss: 0.3508 - val_acc: 0.8516\n",
      "Epoch 1291/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2964 - acc: 0.8771 - val_loss: 0.3508 - val_acc: 0.8516\n",
      "Epoch 1292/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2975 - acc: 0.8742 - val_loss: 0.3505 - val_acc: 0.8523\n",
      "Epoch 1293/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2970 - acc: 0.8750 - val_loss: 0.3499 - val_acc: 0.8516\n",
      "Epoch 1294/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2997 - acc: 0.8750 - val_loss: 0.3514 - val_acc: 0.8503\n",
      "Epoch 1295/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3006 - acc: 0.8737 - val_loss: 0.3511 - val_acc: 0.8509\n",
      "Epoch 1296/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3001 - acc: 0.8750 - val_loss: 0.3512 - val_acc: 0.8503\n",
      "Epoch 1297/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2989 - acc: 0.8759 - val_loss: 0.3507 - val_acc: 0.8516\n",
      "Epoch 1298/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2978 - acc: 0.8758 - val_loss: 0.3503 - val_acc: 0.8516\n",
      "Epoch 1299/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2957 - acc: 0.8761 - val_loss: 0.3502 - val_acc: 0.8516\n",
      "Epoch 1300/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2980 - acc: 0.8765 - val_loss: 0.3514 - val_acc: 0.8503\n",
      "Epoch 1301/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2983 - acc: 0.8751 - val_loss: 0.3503 - val_acc: 0.8516\n",
      "Epoch 1302/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2955 - acc: 0.8784 - val_loss: 0.3504 - val_acc: 0.8503\n",
      "Epoch 1303/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2959 - acc: 0.8775 - val_loss: 0.3504 - val_acc: 0.8509\n",
      "Epoch 1304/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3000 - acc: 0.8746 - val_loss: 0.3510 - val_acc: 0.8509\n",
      "Epoch 1305/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2997 - acc: 0.8752 - val_loss: 0.3508 - val_acc: 0.8516\n",
      "Epoch 1306/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2970 - acc: 0.8775 - val_loss: 0.3508 - val_acc: 0.8503\n",
      "Epoch 1307/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2952 - acc: 0.8759 - val_loss: 0.3508 - val_acc: 0.8496\n",
      "Epoch 1308/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2997 - acc: 0.8750 - val_loss: 0.3502 - val_acc: 0.8537\n",
      "Epoch 1309/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2987 - acc: 0.8754 - val_loss: 0.3513 - val_acc: 0.8496\n",
      "Epoch 1310/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2988 - acc: 0.8760 - val_loss: 0.3509 - val_acc: 0.8509\n",
      "Epoch 1311/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3025 - acc: 0.8725 - val_loss: 0.3512 - val_acc: 0.8496\n",
      "Epoch 1312/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2974 - acc: 0.8753 - val_loss: 0.3508 - val_acc: 0.8503\n",
      "Epoch 1313/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.3003 - acc: 0.8736 - val_loss: 0.3507 - val_acc: 0.8509\n",
      "Epoch 1314/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2965 - acc: 0.8759 - val_loss: 0.3509 - val_acc: 0.8509\n",
      "Epoch 1315/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2972 - acc: 0.8738 - val_loss: 0.3514 - val_acc: 0.8516\n",
      "Epoch 1316/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2943 - acc: 0.8777 - val_loss: 0.3509 - val_acc: 0.8496\n",
      "Epoch 1317/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2987 - acc: 0.8762 - val_loss: 0.3513 - val_acc: 0.8503\n",
      "Epoch 1318/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2969 - acc: 0.8756 - val_loss: 0.3518 - val_acc: 0.8503\n",
      "Epoch 1319/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2982 - acc: 0.8759 - val_loss: 0.3512 - val_acc: 0.8489\n",
      "Epoch 1320/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2973 - acc: 0.8754 - val_loss: 0.3510 - val_acc: 0.8509\n",
      "Epoch 1321/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2931 - acc: 0.8767 - val_loss: 0.3516 - val_acc: 0.8496\n",
      "Epoch 1322/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2967 - acc: 0.8778 - val_loss: 0.3512 - val_acc: 0.8516\n",
      "Epoch 1323/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2957 - acc: 0.8776 - val_loss: 0.3513 - val_acc: 0.8503\n",
      "Epoch 1324/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2992 - acc: 0.8740 - val_loss: 0.3512 - val_acc: 0.8516\n",
      "Epoch 1325/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.3000 - acc: 0.8732 - val_loss: 0.3508 - val_acc: 0.8516\n",
      "Epoch 1326/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2964 - acc: 0.8770 - val_loss: 0.3506 - val_acc: 0.8489\n",
      "Epoch 1327/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2988 - acc: 0.8767 - val_loss: 0.3510 - val_acc: 0.8503\n",
      "Epoch 1328/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2918 - acc: 0.8791 - val_loss: 0.3503 - val_acc: 0.8503\n",
      "Epoch 1329/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2942 - acc: 0.8789 - val_loss: 0.3512 - val_acc: 0.8489\n",
      "Epoch 1330/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2980 - acc: 0.8769 - val_loss: 0.3506 - val_acc: 0.8503\n",
      "Epoch 1331/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2951 - acc: 0.8761 - val_loss: 0.3505 - val_acc: 0.8482\n",
      "Epoch 1332/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2976 - acc: 0.8762 - val_loss: 0.3508 - val_acc: 0.8509\n",
      "Epoch 1333/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2959 - acc: 0.8755 - val_loss: 0.3513 - val_acc: 0.8503\n",
      "Epoch 1334/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2977 - acc: 0.8758 - val_loss: 0.3511 - val_acc: 0.8496\n",
      "Epoch 1335/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2966 - acc: 0.8755 - val_loss: 0.3509 - val_acc: 0.8509\n",
      "Epoch 1336/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2923 - acc: 0.8793 - val_loss: 0.3508 - val_acc: 0.8489\n",
      "Epoch 1337/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2979 - acc: 0.8760 - val_loss: 0.3504 - val_acc: 0.8496\n",
      "Epoch 1338/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2983 - acc: 0.8777 - val_loss: 0.3501 - val_acc: 0.8509\n",
      "Epoch 1339/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2952 - acc: 0.8758 - val_loss: 0.3505 - val_acc: 0.8523\n",
      "Epoch 1340/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2973 - acc: 0.8762 - val_loss: 0.3501 - val_acc: 0.8503\n",
      "Epoch 1341/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2963 - acc: 0.8780 - val_loss: 0.3497 - val_acc: 0.8496\n",
      "Epoch 1342/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2938 - acc: 0.8774 - val_loss: 0.3511 - val_acc: 0.8503\n",
      "Epoch 1343/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2952 - acc: 0.8771 - val_loss: 0.3511 - val_acc: 0.8503\n",
      "Epoch 1344/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2947 - acc: 0.8794 - val_loss: 0.3502 - val_acc: 0.8530\n",
      "Epoch 1345/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2959 - acc: 0.8752 - val_loss: 0.3502 - val_acc: 0.8489\n",
      "Epoch 1346/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2919 - acc: 0.8780 - val_loss: 0.3506 - val_acc: 0.8503\n",
      "Epoch 1347/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2963 - acc: 0.8735 - val_loss: 0.3505 - val_acc: 0.8509\n",
      "Epoch 1348/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2958 - acc: 0.8773 - val_loss: 0.3509 - val_acc: 0.8496\n",
      "Epoch 1349/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2937 - acc: 0.8750 - val_loss: 0.3502 - val_acc: 0.8516\n",
      "Epoch 1350/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2930 - acc: 0.8768 - val_loss: 0.3501 - val_acc: 0.8516\n",
      "Epoch 1351/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2947 - acc: 0.8768 - val_loss: 0.3505 - val_acc: 0.8496\n",
      "Epoch 1352/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2877 - acc: 0.8805 - val_loss: 0.3511 - val_acc: 0.8496\n",
      "Epoch 1353/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2978 - acc: 0.8762 - val_loss: 0.3511 - val_acc: 0.8516\n",
      "Epoch 1354/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2951 - acc: 0.8768 - val_loss: 0.3506 - val_acc: 0.8530\n",
      "Epoch 1355/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2926 - acc: 0.8781 - val_loss: 0.3510 - val_acc: 0.8496\n",
      "Epoch 1356/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2962 - acc: 0.8771 - val_loss: 0.3502 - val_acc: 0.8503\n",
      "Epoch 1357/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2879 - acc: 0.8799 - val_loss: 0.3502 - val_acc: 0.8509\n",
      "Epoch 1358/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2934 - acc: 0.8766 - val_loss: 0.3503 - val_acc: 0.8503\n",
      "Epoch 1359/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2930 - acc: 0.8776 - val_loss: 0.3508 - val_acc: 0.8516\n",
      "Epoch 1360/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2970 - acc: 0.8744 - val_loss: 0.3503 - val_acc: 0.8489\n",
      "Epoch 1361/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2948 - acc: 0.8759 - val_loss: 0.3499 - val_acc: 0.8516\n",
      "Epoch 1362/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2945 - acc: 0.8765 - val_loss: 0.3498 - val_acc: 0.8509\n",
      "Epoch 1363/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2937 - acc: 0.8793 - val_loss: 0.3507 - val_acc: 0.8530\n",
      "Epoch 1364/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2939 - acc: 0.8773 - val_loss: 0.3497 - val_acc: 0.8496\n",
      "Epoch 1365/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2941 - acc: 0.8814 - val_loss: 0.3506 - val_acc: 0.8523\n",
      "Epoch 1366/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2931 - acc: 0.8773 - val_loss: 0.3502 - val_acc: 0.8516\n",
      "Epoch 1367/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2938 - acc: 0.8775 - val_loss: 0.3499 - val_acc: 0.8509\n",
      "Epoch 1368/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2923 - acc: 0.8794 - val_loss: 0.3502 - val_acc: 0.8523\n",
      "Epoch 1369/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2940 - acc: 0.8770 - val_loss: 0.3504 - val_acc: 0.8537\n",
      "Epoch 1370/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2938 - acc: 0.8772 - val_loss: 0.3509 - val_acc: 0.8503\n",
      "Epoch 1371/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2948 - acc: 0.8754 - val_loss: 0.3508 - val_acc: 0.8516\n",
      "Epoch 1372/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2891 - acc: 0.8793 - val_loss: 0.3505 - val_acc: 0.8530\n",
      "Epoch 1373/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2944 - acc: 0.8780 - val_loss: 0.3502 - val_acc: 0.8523\n",
      "Epoch 1374/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2923 - acc: 0.8790 - val_loss: 0.3514 - val_acc: 0.8509\n",
      "Epoch 1375/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2929 - acc: 0.8764 - val_loss: 0.3497 - val_acc: 0.8516\n",
      "Epoch 1376/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2949 - acc: 0.8770 - val_loss: 0.3501 - val_acc: 0.8503\n",
      "Epoch 1377/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2927 - acc: 0.8776 - val_loss: 0.3503 - val_acc: 0.8503\n",
      "Epoch 1378/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2952 - acc: 0.8767 - val_loss: 0.3499 - val_acc: 0.8509\n",
      "Epoch 1379/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2971 - acc: 0.8777 - val_loss: 0.3489 - val_acc: 0.8523\n",
      "Epoch 1380/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2921 - acc: 0.8790 - val_loss: 0.3502 - val_acc: 0.8503\n",
      "Epoch 1381/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2952 - acc: 0.8744 - val_loss: 0.3508 - val_acc: 0.8509\n",
      "Epoch 1382/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2923 - acc: 0.8787 - val_loss: 0.3508 - val_acc: 0.8523\n",
      "Epoch 1383/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2947 - acc: 0.8778 - val_loss: 0.3505 - val_acc: 0.8516\n",
      "Epoch 1384/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2931 - acc: 0.8790 - val_loss: 0.3503 - val_acc: 0.8543\n",
      "Epoch 1385/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2947 - acc: 0.8776 - val_loss: 0.3501 - val_acc: 0.8523\n",
      "Epoch 1386/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2952 - acc: 0.8771 - val_loss: 0.3505 - val_acc: 0.8516\n",
      "Epoch 1387/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2940 - acc: 0.8791 - val_loss: 0.3507 - val_acc: 0.8516\n",
      "Epoch 1388/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2921 - acc: 0.8799 - val_loss: 0.3509 - val_acc: 0.8523\n",
      "Epoch 1389/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2937 - acc: 0.8769 - val_loss: 0.3498 - val_acc: 0.8543\n",
      "Epoch 1390/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2915 - acc: 0.8798 - val_loss: 0.3494 - val_acc: 0.8530\n",
      "Epoch 1391/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2909 - acc: 0.8820 - val_loss: 0.3498 - val_acc: 0.8543\n",
      "Epoch 1392/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2937 - acc: 0.8791 - val_loss: 0.3500 - val_acc: 0.8523\n",
      "Epoch 1393/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2929 - acc: 0.8798 - val_loss: 0.3498 - val_acc: 0.8543\n",
      "Epoch 1394/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2939 - acc: 0.8798 - val_loss: 0.3508 - val_acc: 0.8489\n",
      "Epoch 1395/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2923 - acc: 0.8780 - val_loss: 0.3501 - val_acc: 0.8537\n",
      "Epoch 1396/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2944 - acc: 0.8761 - val_loss: 0.3497 - val_acc: 0.8557\n",
      "Epoch 1397/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2970 - acc: 0.8761 - val_loss: 0.3497 - val_acc: 0.8570\n",
      "Epoch 1398/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2905 - acc: 0.8774 - val_loss: 0.3502 - val_acc: 0.8543\n",
      "Epoch 1399/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2931 - acc: 0.8780 - val_loss: 0.3499 - val_acc: 0.8543\n",
      "Epoch 1400/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2909 - acc: 0.8784 - val_loss: 0.3504 - val_acc: 0.8543\n",
      "Epoch 1401/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2946 - acc: 0.8765 - val_loss: 0.3505 - val_acc: 0.8530\n",
      "Epoch 1402/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2951 - acc: 0.8749 - val_loss: 0.3499 - val_acc: 0.8509\n",
      "Epoch 1403/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2928 - acc: 0.8788 - val_loss: 0.3495 - val_acc: 0.8550\n",
      "Epoch 1404/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2929 - acc: 0.8786 - val_loss: 0.3498 - val_acc: 0.8530\n",
      "Epoch 1405/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2901 - acc: 0.8811 - val_loss: 0.3493 - val_acc: 0.8523\n",
      "Epoch 1406/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2906 - acc: 0.8814 - val_loss: 0.3504 - val_acc: 0.8509\n",
      "Epoch 1407/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2911 - acc: 0.8799 - val_loss: 0.3491 - val_acc: 0.8537\n",
      "Epoch 1408/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2937 - acc: 0.8787 - val_loss: 0.3499 - val_acc: 0.8543\n",
      "Epoch 1409/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2930 - acc: 0.8800 - val_loss: 0.3488 - val_acc: 0.8550\n",
      "Epoch 1410/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2914 - acc: 0.8784 - val_loss: 0.3499 - val_acc: 0.8523\n",
      "Epoch 1411/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2949 - acc: 0.8769 - val_loss: 0.3496 - val_acc: 0.8564\n",
      "Epoch 1412/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2906 - acc: 0.8791 - val_loss: 0.3499 - val_acc: 0.8537\n",
      "Epoch 1413/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2900 - acc: 0.8786 - val_loss: 0.3502 - val_acc: 0.8523\n",
      "Epoch 1414/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2902 - acc: 0.8814 - val_loss: 0.3499 - val_acc: 0.8509\n",
      "Epoch 1415/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2969 - acc: 0.8756 - val_loss: 0.3496 - val_acc: 0.8516\n",
      "Epoch 1416/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2952 - acc: 0.8757 - val_loss: 0.3498 - val_acc: 0.8523\n",
      "Epoch 1417/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2947 - acc: 0.8766 - val_loss: 0.3493 - val_acc: 0.8530\n",
      "Epoch 1418/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2932 - acc: 0.8796 - val_loss: 0.3500 - val_acc: 0.8543\n",
      "Epoch 1419/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2945 - acc: 0.8756 - val_loss: 0.3504 - val_acc: 0.8543\n",
      "Epoch 1420/10000\n",
      "13284/13284 [==============================] - 0s 26us/sample - loss: 0.2934 - acc: 0.8787 - val_loss: 0.3497 - val_acc: 0.8543\n",
      "Epoch 1421/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2940 - acc: 0.8776 - val_loss: 0.3494 - val_acc: 0.8523\n",
      "Epoch 1422/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2913 - acc: 0.8804 - val_loss: 0.3493 - val_acc: 0.8543\n",
      "Epoch 1423/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2974 - acc: 0.8777 - val_loss: 0.3495 - val_acc: 0.8550\n",
      "Epoch 1424/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2912 - acc: 0.8813 - val_loss: 0.3498 - val_acc: 0.8523\n",
      "Epoch 1425/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2898 - acc: 0.8809 - val_loss: 0.3503 - val_acc: 0.8523\n",
      "Epoch 1426/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2896 - acc: 0.8802 - val_loss: 0.3502 - val_acc: 0.8530\n",
      "Epoch 1427/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2941 - acc: 0.8755 - val_loss: 0.3498 - val_acc: 0.8543\n",
      "Epoch 1428/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2896 - acc: 0.8796 - val_loss: 0.3489 - val_acc: 0.8530\n",
      "Epoch 1429/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2937 - acc: 0.8804 - val_loss: 0.3487 - val_acc: 0.8537\n",
      "Epoch 1430/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2936 - acc: 0.8769 - val_loss: 0.3496 - val_acc: 0.8537\n",
      "Epoch 1431/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2932 - acc: 0.8806 - val_loss: 0.3490 - val_acc: 0.8557\n",
      "Epoch 1432/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2926 - acc: 0.8781 - val_loss: 0.3497 - val_acc: 0.8543\n",
      "Epoch 1433/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2919 - acc: 0.8796 - val_loss: 0.3495 - val_acc: 0.8550\n",
      "Epoch 1434/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2925 - acc: 0.8782 - val_loss: 0.3495 - val_acc: 0.8537\n",
      "Epoch 1435/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2915 - acc: 0.8802 - val_loss: 0.3505 - val_acc: 0.8516\n",
      "Epoch 1436/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2943 - acc: 0.8784 - val_loss: 0.3492 - val_acc: 0.8557\n",
      "Epoch 1437/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2877 - acc: 0.8785 - val_loss: 0.3492 - val_acc: 0.8523\n",
      "Epoch 1438/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2921 - acc: 0.8790 - val_loss: 0.3492 - val_acc: 0.8543\n",
      "Epoch 1439/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2948 - acc: 0.8773 - val_loss: 0.3495 - val_acc: 0.8543\n",
      "Epoch 1440/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2919 - acc: 0.8796 - val_loss: 0.3495 - val_acc: 0.8530\n",
      "Epoch 1441/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2943 - acc: 0.8786 - val_loss: 0.3491 - val_acc: 0.8564\n",
      "Epoch 1442/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2893 - acc: 0.8802 - val_loss: 0.3492 - val_acc: 0.8530\n",
      "Epoch 1443/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2926 - acc: 0.8808 - val_loss: 0.3487 - val_acc: 0.8557\n",
      "Epoch 1444/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2916 - acc: 0.8799 - val_loss: 0.3498 - val_acc: 0.8516\n",
      "Epoch 1445/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2909 - acc: 0.8807 - val_loss: 0.3486 - val_acc: 0.8557\n",
      "Epoch 1446/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2921 - acc: 0.8805 - val_loss: 0.3491 - val_acc: 0.8530\n",
      "Epoch 1447/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2919 - acc: 0.8808 - val_loss: 0.3488 - val_acc: 0.8557\n",
      "Epoch 1448/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2891 - acc: 0.8802 - val_loss: 0.3497 - val_acc: 0.8530\n",
      "Epoch 1449/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2913 - acc: 0.8796 - val_loss: 0.3492 - val_acc: 0.8523\n",
      "Epoch 1450/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2936 - acc: 0.8778 - val_loss: 0.3495 - val_acc: 0.8537\n",
      "Epoch 1451/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2908 - acc: 0.8820 - val_loss: 0.3491 - val_acc: 0.8570\n",
      "Epoch 1452/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2916 - acc: 0.8777 - val_loss: 0.3494 - val_acc: 0.8543\n",
      "Epoch 1453/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2922 - acc: 0.8784 - val_loss: 0.3490 - val_acc: 0.8570\n",
      "Epoch 1454/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2894 - acc: 0.8818 - val_loss: 0.3495 - val_acc: 0.8530\n",
      "Epoch 1455/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2919 - acc: 0.8799 - val_loss: 0.3491 - val_acc: 0.8557\n",
      "Epoch 1456/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2945 - acc: 0.8756 - val_loss: 0.3491 - val_acc: 0.8530\n",
      "Epoch 1457/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2905 - acc: 0.8811 - val_loss: 0.3487 - val_acc: 0.8564\n",
      "Epoch 1458/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2922 - acc: 0.8804 - val_loss: 0.3490 - val_acc: 0.8550\n",
      "Epoch 1459/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2900 - acc: 0.8821 - val_loss: 0.3488 - val_acc: 0.8550\n",
      "Epoch 1460/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2931 - acc: 0.8808 - val_loss: 0.3493 - val_acc: 0.8564\n",
      "Epoch 1461/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2934 - acc: 0.8796 - val_loss: 0.3483 - val_acc: 0.8570\n",
      "Epoch 1462/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2924 - acc: 0.8789 - val_loss: 0.3486 - val_acc: 0.8550\n",
      "Epoch 1463/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2910 - acc: 0.8802 - val_loss: 0.3485 - val_acc: 0.8557\n",
      "Epoch 1464/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2869 - acc: 0.8830 - val_loss: 0.3488 - val_acc: 0.8550\n",
      "Epoch 1465/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2893 - acc: 0.8808 - val_loss: 0.3486 - val_acc: 0.8564\n",
      "Epoch 1466/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2924 - acc: 0.8798 - val_loss: 0.3489 - val_acc: 0.8550\n",
      "Epoch 1467/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2872 - acc: 0.8835 - val_loss: 0.3492 - val_acc: 0.8543\n",
      "Epoch 1468/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2913 - acc: 0.8816 - val_loss: 0.3486 - val_acc: 0.8557\n",
      "Epoch 1469/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2909 - acc: 0.8803 - val_loss: 0.3496 - val_acc: 0.8530\n",
      "Epoch 1470/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2867 - acc: 0.8830 - val_loss: 0.3490 - val_acc: 0.8570\n",
      "Epoch 1471/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2885 - acc: 0.8821 - val_loss: 0.3484 - val_acc: 0.8564\n",
      "Epoch 1472/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2892 - acc: 0.8816 - val_loss: 0.3483 - val_acc: 0.8543\n",
      "Epoch 1473/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2882 - acc: 0.8835 - val_loss: 0.3495 - val_acc: 0.8537\n",
      "Epoch 1474/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2916 - acc: 0.8799 - val_loss: 0.3490 - val_acc: 0.8537\n",
      "Epoch 1475/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2955 - acc: 0.8786 - val_loss: 0.3489 - val_acc: 0.8550\n",
      "Epoch 1476/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2894 - acc: 0.8805 - val_loss: 0.3482 - val_acc: 0.8550\n",
      "Epoch 1477/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2932 - acc: 0.8783 - val_loss: 0.3480 - val_acc: 0.8584\n",
      "Epoch 1478/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2884 - acc: 0.8815 - val_loss: 0.3492 - val_acc: 0.8543\n",
      "Epoch 1479/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2908 - acc: 0.8811 - val_loss: 0.3491 - val_acc: 0.8564\n",
      "Epoch 1480/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2944 - acc: 0.8782 - val_loss: 0.3490 - val_acc: 0.8537\n",
      "Epoch 1481/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2915 - acc: 0.8811 - val_loss: 0.3487 - val_acc: 0.8537\n",
      "Epoch 1482/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2893 - acc: 0.8821 - val_loss: 0.3494 - val_acc: 0.8530\n",
      "Epoch 1483/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2922 - acc: 0.8805 - val_loss: 0.3483 - val_acc: 0.8584\n",
      "Epoch 1484/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2882 - acc: 0.8818 - val_loss: 0.3481 - val_acc: 0.8550\n",
      "Epoch 1485/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2912 - acc: 0.8811 - val_loss: 0.3481 - val_acc: 0.8577\n",
      "Epoch 1486/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2883 - acc: 0.8814 - val_loss: 0.3488 - val_acc: 0.8523\n",
      "Epoch 1487/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2896 - acc: 0.8823 - val_loss: 0.3482 - val_acc: 0.8550\n",
      "Epoch 1488/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2899 - acc: 0.8826 - val_loss: 0.3482 - val_acc: 0.8537 0s - loss: 0.2910 - acc: 0.\n",
      "Epoch 1489/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2880 - acc: 0.8797 - val_loss: 0.3480 - val_acc: 0.8543\n",
      "Epoch 1490/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2884 - acc: 0.8820 - val_loss: 0.3482 - val_acc: 0.8564\n",
      "Epoch 1491/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2915 - acc: 0.8796 - val_loss: 0.3489 - val_acc: 0.8550\n",
      "Epoch 1492/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2919 - acc: 0.8779 - val_loss: 0.3486 - val_acc: 0.8550\n",
      "Epoch 1493/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2922 - acc: 0.8820 - val_loss: 0.3485 - val_acc: 0.8557\n",
      "Epoch 1494/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2921 - acc: 0.8796 - val_loss: 0.3486 - val_acc: 0.8537\n",
      "Epoch 1495/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2832 - acc: 0.8841 - val_loss: 0.3486 - val_acc: 0.8577\n",
      "Epoch 1496/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2908 - acc: 0.8810 - val_loss: 0.3480 - val_acc: 0.8564\n",
      "Epoch 1497/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2901 - acc: 0.8800 - val_loss: 0.3480 - val_acc: 0.8557\n",
      "Epoch 1498/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2880 - acc: 0.8821 - val_loss: 0.3490 - val_acc: 0.8537\n",
      "Epoch 1499/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2886 - acc: 0.8821 - val_loss: 0.3484 - val_acc: 0.8557\n",
      "Epoch 1500/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2908 - acc: 0.8782 - val_loss: 0.3488 - val_acc: 0.8550\n",
      "Epoch 1501/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2907 - acc: 0.8807 - val_loss: 0.3481 - val_acc: 0.8570\n",
      "Epoch 1502/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2939 - acc: 0.8783 - val_loss: 0.3489 - val_acc: 0.8550\n",
      "Epoch 1503/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2938 - acc: 0.8783 - val_loss: 0.3485 - val_acc: 0.8523\n",
      "Epoch 1504/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2859 - acc: 0.8823 - val_loss: 0.3487 - val_acc: 0.8557\n",
      "Epoch 1505/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2885 - acc: 0.8815 - val_loss: 0.3477 - val_acc: 0.8598\n",
      "Epoch 1506/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2912 - acc: 0.8784 - val_loss: 0.3480 - val_acc: 0.8591\n",
      "Epoch 1507/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2889 - acc: 0.8804 - val_loss: 0.3480 - val_acc: 0.8570\n",
      "Epoch 1508/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2917 - acc: 0.8814 - val_loss: 0.3486 - val_acc: 0.8550\n",
      "Epoch 1509/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2873 - acc: 0.8832 - val_loss: 0.3490 - val_acc: 0.8557\n",
      "Epoch 1510/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2869 - acc: 0.8810 - val_loss: 0.3485 - val_acc: 0.8564\n",
      "Epoch 1511/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2858 - acc: 0.8839 - val_loss: 0.3490 - val_acc: 0.8543\n",
      "Epoch 1512/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2887 - acc: 0.8819 - val_loss: 0.3484 - val_acc: 0.8537\n",
      "Epoch 1513/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2888 - acc: 0.8832 - val_loss: 0.3483 - val_acc: 0.8584\n",
      "Epoch 1514/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2881 - acc: 0.8805 - val_loss: 0.3477 - val_acc: 0.8577\n",
      "Epoch 1515/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2930 - acc: 0.8793 - val_loss: 0.3482 - val_acc: 0.8577\n",
      "Epoch 1516/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2881 - acc: 0.8822 - val_loss: 0.3493 - val_acc: 0.8577\n",
      "Epoch 1517/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2860 - acc: 0.8812 - val_loss: 0.3485 - val_acc: 0.8543\n",
      "Epoch 1518/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.2894 - acc: 0.879 - 0s 29us/sample - loss: 0.2889 - acc: 0.8804 - val_loss: 0.3485 - val_acc: 0.8550\n",
      "Epoch 1519/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2890 - acc: 0.8808 - val_loss: 0.3487 - val_acc: 0.8577\n",
      "Epoch 1520/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2867 - acc: 0.8839 - val_loss: 0.3483 - val_acc: 0.8604\n",
      "Epoch 1521/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2880 - acc: 0.8811 - val_loss: 0.3486 - val_acc: 0.8570\n",
      "Epoch 1522/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2866 - acc: 0.8814 - val_loss: 0.3482 - val_acc: 0.8557\n",
      "Epoch 1523/10000\n",
      "13284/13284 [==============================] - 0s 32us/sample - loss: 0.2873 - acc: 0.8827 - val_loss: 0.3491 - val_acc: 0.8550\n",
      "Epoch 1524/10000\n",
      "13284/13284 [==============================] - 0s 32us/sample - loss: 0.2843 - acc: 0.8818 - val_loss: 0.3485 - val_acc: 0.8584\n",
      "Epoch 1525/10000\n",
      "13284/13284 [==============================] - 0s 32us/sample - loss: 0.2893 - acc: 0.8806 - val_loss: 0.3479 - val_acc: 0.8577\n",
      "Epoch 1526/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2854 - acc: 0.8828 - val_loss: 0.3485 - val_acc: 0.8584\n",
      "Epoch 1527/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2860 - acc: 0.8829 - val_loss: 0.3485 - val_acc: 0.8570\n",
      "Epoch 1528/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2878 - acc: 0.8822 - val_loss: 0.3478 - val_acc: 0.8570\n",
      "Epoch 1529/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2888 - acc: 0.8823 - val_loss: 0.3483 - val_acc: 0.8564\n",
      "Epoch 1530/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2881 - acc: 0.8819 - val_loss: 0.3477 - val_acc: 0.8570\n",
      "Epoch 1531/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2861 - acc: 0.8823 - val_loss: 0.3480 - val_acc: 0.8577\n",
      "Epoch 1532/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2863 - acc: 0.8834 - val_loss: 0.3479 - val_acc: 0.8564\n",
      "Epoch 1533/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2869 - acc: 0.8817 - val_loss: 0.3486 - val_acc: 0.8598\n",
      "Epoch 1534/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2870 - acc: 0.8805 - val_loss: 0.3481 - val_acc: 0.8557\n",
      "Epoch 1535/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2871 - acc: 0.8811 - val_loss: 0.3488 - val_acc: 0.8564\n",
      "Epoch 1536/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2862 - acc: 0.8835 - val_loss: 0.3475 - val_acc: 0.8557\n",
      "Epoch 1537/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2874 - acc: 0.8825 - val_loss: 0.3483 - val_acc: 0.8537\n",
      "Epoch 1538/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2867 - acc: 0.8827 - val_loss: 0.3476 - val_acc: 0.8584\n",
      "Epoch 1539/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2828 - acc: 0.8854 - val_loss: 0.3488 - val_acc: 0.8550\n",
      "Epoch 1540/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2867 - acc: 0.8839 - val_loss: 0.3483 - val_acc: 0.8564\n",
      "Epoch 1541/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2814 - acc: 0.8866 - val_loss: 0.3483 - val_acc: 0.8564\n",
      "Epoch 1542/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2859 - acc: 0.8844 - val_loss: 0.3482 - val_acc: 0.8557\n",
      "Epoch 1543/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2863 - acc: 0.8845 - val_loss: 0.3479 - val_acc: 0.8577\n",
      "Epoch 1544/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2867 - acc: 0.8819 - val_loss: 0.3483 - val_acc: 0.8550\n",
      "Epoch 1545/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2863 - acc: 0.8823 - val_loss: 0.3479 - val_acc: 0.8564\n",
      "Epoch 1546/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2866 - acc: 0.8824 - val_loss: 0.3482 - val_acc: 0.8570\n",
      "Epoch 1547/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2829 - acc: 0.8839 - val_loss: 0.3485 - val_acc: 0.8564\n",
      "Epoch 1548/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2862 - acc: 0.8844 - val_loss: 0.3479 - val_acc: 0.8591\n",
      "Epoch 1549/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2888 - acc: 0.8825 - val_loss: 0.3474 - val_acc: 0.8591\n",
      "Epoch 1550/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2911 - acc: 0.8799 - val_loss: 0.3482 - val_acc: 0.8557\n",
      "Epoch 1551/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2861 - acc: 0.8826 - val_loss: 0.3474 - val_acc: 0.8584\n",
      "Epoch 1552/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2892 - acc: 0.8820 - val_loss: 0.3478 - val_acc: 0.8570\n",
      "Epoch 1553/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2863 - acc: 0.8815 - val_loss: 0.3480 - val_acc: 0.8557\n",
      "Epoch 1554/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2870 - acc: 0.8835 - val_loss: 0.3486 - val_acc: 0.8550\n",
      "Epoch 1555/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2839 - acc: 0.8843 - val_loss: 0.3474 - val_acc: 0.8577\n",
      "Epoch 1556/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2888 - acc: 0.8818 - val_loss: 0.3474 - val_acc: 0.8577\n",
      "Epoch 1557/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2833 - acc: 0.8844 - val_loss: 0.3490 - val_acc: 0.8537\n",
      "Epoch 1558/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2878 - acc: 0.8810 - val_loss: 0.3469 - val_acc: 0.8584\n",
      "Epoch 1559/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2890 - acc: 0.8809 - val_loss: 0.3476 - val_acc: 0.8564\n",
      "Epoch 1560/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2876 - acc: 0.8826 - val_loss: 0.3473 - val_acc: 0.8577\n",
      "Epoch 1561/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2860 - acc: 0.8824 - val_loss: 0.3473 - val_acc: 0.8598\n",
      "Epoch 1562/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2870 - acc: 0.8825 - val_loss: 0.3489 - val_acc: 0.8557\n",
      "Epoch 1563/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2870 - acc: 0.8802 - val_loss: 0.3472 - val_acc: 0.8564\n",
      "Epoch 1564/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2838 - acc: 0.8824 - val_loss: 0.3470 - val_acc: 0.8550\n",
      "Epoch 1565/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2848 - acc: 0.8826 - val_loss: 0.3476 - val_acc: 0.8557\n",
      "Epoch 1566/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2867 - acc: 0.8802 - val_loss: 0.3475 - val_acc: 0.8584\n",
      "Epoch 1567/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2850 - acc: 0.8826 - val_loss: 0.3481 - val_acc: 0.8570\n",
      "Epoch 1568/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2845 - acc: 0.8818 - val_loss: 0.3467 - val_acc: 0.8604\n",
      "Epoch 1569/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2852 - acc: 0.8841 - val_loss: 0.3471 - val_acc: 0.8570\n",
      "Epoch 1570/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2809 - acc: 0.8864 - val_loss: 0.3481 - val_acc: 0.8570\n",
      "Epoch 1571/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2854 - acc: 0.8838 - val_loss: 0.3468 - val_acc: 0.8570\n",
      "Epoch 1572/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2862 - acc: 0.8831 - val_loss: 0.3472 - val_acc: 0.8584\n",
      "Epoch 1573/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2823 - acc: 0.8832 - val_loss: 0.3482 - val_acc: 0.8577\n",
      "Epoch 1574/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2829 - acc: 0.8814 - val_loss: 0.3468 - val_acc: 0.8591\n",
      "Epoch 1575/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2861 - acc: 0.8821 - val_loss: 0.3473 - val_acc: 0.8598\n",
      "Epoch 1576/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2849 - acc: 0.8840 - val_loss: 0.3475 - val_acc: 0.8564\n",
      "Epoch 1577/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2837 - acc: 0.8839 - val_loss: 0.3475 - val_acc: 0.8557\n",
      "Epoch 1578/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2844 - acc: 0.8835 - val_loss: 0.3469 - val_acc: 0.8591\n",
      "Epoch 1579/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2844 - acc: 0.8862 - val_loss: 0.3472 - val_acc: 0.8598\n",
      "Epoch 1580/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2841 - acc: 0.8837 - val_loss: 0.3475 - val_acc: 0.8591\n",
      "Epoch 1581/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2853 - acc: 0.8835 - val_loss: 0.3468 - val_acc: 0.8584\n",
      "Epoch 1582/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2868 - acc: 0.8837 - val_loss: 0.3470 - val_acc: 0.8591\n",
      "Epoch 1583/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2841 - acc: 0.8834 - val_loss: 0.3475 - val_acc: 0.8584\n",
      "Epoch 1584/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2866 - acc: 0.8824 - val_loss: 0.3474 - val_acc: 0.8604\n",
      "Epoch 1585/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2873 - acc: 0.8823 - val_loss: 0.3484 - val_acc: 0.8577\n",
      "Epoch 1586/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2802 - acc: 0.8847 - val_loss: 0.3478 - val_acc: 0.8577\n",
      "Epoch 1587/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2847 - acc: 0.8842 - val_loss: 0.3477 - val_acc: 0.8577\n",
      "Epoch 1588/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2822 - acc: 0.8829 - val_loss: 0.3475 - val_acc: 0.8570\n",
      "Epoch 1589/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2862 - acc: 0.8817 - val_loss: 0.3472 - val_acc: 0.8577\n",
      "Epoch 1590/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2862 - acc: 0.8831 - val_loss: 0.3469 - val_acc: 0.8577\n",
      "Epoch 1591/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2843 - acc: 0.8833 - val_loss: 0.3476 - val_acc: 0.8598\n",
      "Epoch 1592/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2854 - acc: 0.8835 - val_loss: 0.3481 - val_acc: 0.8584\n",
      "Epoch 1593/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2811 - acc: 0.8847 - val_loss: 0.3475 - val_acc: 0.8598\n",
      "Epoch 1594/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2845 - acc: 0.8831 - val_loss: 0.3477 - val_acc: 0.8591\n",
      "Epoch 1595/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2829 - acc: 0.8857 - val_loss: 0.3471 - val_acc: 0.8604\n",
      "Epoch 1596/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2871 - acc: 0.8829 - val_loss: 0.3476 - val_acc: 0.8604\n",
      "Epoch 1597/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2850 - acc: 0.8823 - val_loss: 0.3480 - val_acc: 0.8598\n",
      "Epoch 1598/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2851 - acc: 0.8809 - val_loss: 0.3479 - val_acc: 0.8591\n",
      "Epoch 1599/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2851 - acc: 0.8842 - val_loss: 0.3475 - val_acc: 0.8584\n",
      "Epoch 1600/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2887 - acc: 0.8794 - val_loss: 0.3482 - val_acc: 0.8564\n",
      "Epoch 1601/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2866 - acc: 0.8830 - val_loss: 0.3467 - val_acc: 0.8591\n",
      "Epoch 1602/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2843 - acc: 0.8838 - val_loss: 0.3468 - val_acc: 0.8577\n",
      "Epoch 1603/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2832 - acc: 0.8843 - val_loss: 0.3472 - val_acc: 0.8577\n",
      "Epoch 1604/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2840 - acc: 0.8819 - val_loss: 0.3472 - val_acc: 0.8598\n",
      "Epoch 1605/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2825 - acc: 0.8856 - val_loss: 0.3478 - val_acc: 0.8577\n",
      "Epoch 1606/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2815 - acc: 0.8845 - val_loss: 0.3469 - val_acc: 0.8598\n",
      "Epoch 1607/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2845 - acc: 0.8823 - val_loss: 0.3470 - val_acc: 0.8604\n",
      "Epoch 1608/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2818 - acc: 0.8844 - val_loss: 0.3473 - val_acc: 0.8584\n",
      "Epoch 1609/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2854 - acc: 0.8828 - val_loss: 0.3474 - val_acc: 0.8591\n",
      "Epoch 1610/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2815 - acc: 0.8835 - val_loss: 0.3477 - val_acc: 0.8570\n",
      "Epoch 1611/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2814 - acc: 0.8838 - val_loss: 0.3478 - val_acc: 0.8584\n",
      "Epoch 1612/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2853 - acc: 0.8797 - val_loss: 0.3490 - val_acc: 0.8564\n",
      "Epoch 1613/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2876 - acc: 0.8817 - val_loss: 0.3474 - val_acc: 0.8604\n",
      "Epoch 1614/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2793 - acc: 0.8857 - val_loss: 0.3479 - val_acc: 0.8577\n",
      "Epoch 1615/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2827 - acc: 0.8844 - val_loss: 0.3476 - val_acc: 0.8591\n",
      "Epoch 1616/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2857 - acc: 0.8833 - val_loss: 0.3472 - val_acc: 0.8604\n",
      "Epoch 1617/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2823 - acc: 0.8829 - val_loss: 0.3473 - val_acc: 0.8584\n",
      "Epoch 1618/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2861 - acc: 0.8830 - val_loss: 0.3476 - val_acc: 0.8591\n",
      "Epoch 1619/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2861 - acc: 0.8826 - val_loss: 0.3466 - val_acc: 0.8631\n",
      "Epoch 1620/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2797 - acc: 0.8854 - val_loss: 0.3470 - val_acc: 0.8604\n",
      "Epoch 1621/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2831 - acc: 0.8846 - val_loss: 0.3471 - val_acc: 0.8598\n",
      "Epoch 1622/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2848 - acc: 0.8832 - val_loss: 0.3470 - val_acc: 0.8591\n",
      "Epoch 1623/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2835 - acc: 0.8830 - val_loss: 0.3476 - val_acc: 0.8598\n",
      "Epoch 1624/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2840 - acc: 0.8836 - val_loss: 0.3474 - val_acc: 0.8598\n",
      "Epoch 1625/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2836 - acc: 0.8824 - val_loss: 0.3482 - val_acc: 0.8577\n",
      "Epoch 1626/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2828 - acc: 0.8848 - val_loss: 0.3474 - val_acc: 0.8591\n",
      "Epoch 1627/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2826 - acc: 0.8838 - val_loss: 0.3466 - val_acc: 0.8591\n",
      "Epoch 1628/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2796 - acc: 0.8865 - val_loss: 0.3480 - val_acc: 0.8604\n",
      "Epoch 1629/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2852 - acc: 0.8817 - val_loss: 0.3473 - val_acc: 0.8584\n",
      "Epoch 1630/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2817 - acc: 0.8832 - val_loss: 0.3485 - val_acc: 0.8570\n",
      "Epoch 1631/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2800 - acc: 0.8863 - val_loss: 0.3469 - val_acc: 0.8598\n",
      "Epoch 1632/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2815 - acc: 0.8847 - val_loss: 0.3470 - val_acc: 0.8611\n",
      "Epoch 1633/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2823 - acc: 0.8829 - val_loss: 0.3475 - val_acc: 0.8604\n",
      "Epoch 1634/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2822 - acc: 0.8854 - val_loss: 0.3473 - val_acc: 0.8564\n",
      "Epoch 1635/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2834 - acc: 0.8817 - val_loss: 0.3472 - val_acc: 0.8570\n",
      "Epoch 1636/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2816 - acc: 0.8845 - val_loss: 0.3470 - val_acc: 0.8598\n",
      "Epoch 1637/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2877 - acc: 0.8838 - val_loss: 0.3472 - val_acc: 0.8584\n",
      "Epoch 1638/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2825 - acc: 0.8841 - val_loss: 0.3475 - val_acc: 0.8584\n",
      "Epoch 1639/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2815 - acc: 0.8837 - val_loss: 0.3467 - val_acc: 0.8598\n",
      "Epoch 1640/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2815 - acc: 0.8853 - val_loss: 0.3472 - val_acc: 0.8604\n",
      "Epoch 1641/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2843 - acc: 0.8844 - val_loss: 0.3472 - val_acc: 0.8604\n",
      "Epoch 1642/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2804 - acc: 0.8850 - val_loss: 0.3474 - val_acc: 0.8577\n",
      "Epoch 1643/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2805 - acc: 0.8853 - val_loss: 0.3480 - val_acc: 0.8584\n",
      "Epoch 1644/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2817 - acc: 0.8844 - val_loss: 0.3486 - val_acc: 0.8598\n",
      "Epoch 1645/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2839 - acc: 0.8847 - val_loss: 0.3475 - val_acc: 0.8591\n",
      "Epoch 1646/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2821 - acc: 0.8844 - val_loss: 0.3476 - val_acc: 0.8604\n",
      "Epoch 1647/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2846 - acc: 0.8828 - val_loss: 0.3470 - val_acc: 0.8598\n",
      "Epoch 1648/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2845 - acc: 0.8826 - val_loss: 0.3479 - val_acc: 0.8577\n",
      "Epoch 1649/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2801 - acc: 0.8852 - val_loss: 0.3471 - val_acc: 0.8611\n",
      "Epoch 1650/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2838 - acc: 0.8830 - val_loss: 0.3475 - val_acc: 0.8570\n",
      "Epoch 1651/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2821 - acc: 0.8839 - val_loss: 0.3472 - val_acc: 0.8598\n",
      "Epoch 1652/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2848 - acc: 0.8810 - val_loss: 0.3468 - val_acc: 0.8618\n",
      "Epoch 1653/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2831 - acc: 0.8835 - val_loss: 0.3464 - val_acc: 0.8611\n",
      "Epoch 1654/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2789 - acc: 0.8854 - val_loss: 0.3478 - val_acc: 0.8598\n",
      "Epoch 1655/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2822 - acc: 0.8830 - val_loss: 0.3470 - val_acc: 0.8584\n",
      "Epoch 1656/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2850 - acc: 0.8850 - val_loss: 0.3476 - val_acc: 0.8584\n",
      "Epoch 1657/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2832 - acc: 0.8847 - val_loss: 0.3479 - val_acc: 0.8591\n",
      "Epoch 1658/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2829 - acc: 0.8837 - val_loss: 0.3475 - val_acc: 0.8577\n",
      "Epoch 1659/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2827 - acc: 0.8822 - val_loss: 0.3474 - val_acc: 0.8570\n",
      "Epoch 1660/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2802 - acc: 0.8847 - val_loss: 0.3472 - val_acc: 0.8591\n",
      "Epoch 1661/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2823 - acc: 0.8826 - val_loss: 0.3477 - val_acc: 0.8577\n",
      "Epoch 1662/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2839 - acc: 0.8844 - val_loss: 0.3474 - val_acc: 0.8570\n",
      "Epoch 1663/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2833 - acc: 0.8843 - val_loss: 0.3469 - val_acc: 0.8591\n",
      "Epoch 1664/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2831 - acc: 0.8846 - val_loss: 0.3473 - val_acc: 0.8577\n",
      "Epoch 1665/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2820 - acc: 0.8838 - val_loss: 0.3469 - val_acc: 0.8591\n",
      "Epoch 1666/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2777 - acc: 0.8849 - val_loss: 0.3477 - val_acc: 0.8584\n",
      "Epoch 1667/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2869 - acc: 0.8804 - val_loss: 0.3474 - val_acc: 0.8584\n",
      "Epoch 1668/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2810 - acc: 0.8832 - val_loss: 0.3473 - val_acc: 0.8577\n",
      "Epoch 1669/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2837 - acc: 0.8845 - val_loss: 0.3477 - val_acc: 0.8584\n",
      "Epoch 1670/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2817 - acc: 0.8832 - val_loss: 0.3479 - val_acc: 0.8557\n",
      "Epoch 1671/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2802 - acc: 0.8832 - val_loss: 0.3474 - val_acc: 0.8584\n",
      "Epoch 1672/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2798 - acc: 0.8829 - val_loss: 0.3476 - val_acc: 0.8577\n",
      "Epoch 1673/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2790 - acc: 0.8841 - val_loss: 0.3476 - val_acc: 0.8598\n",
      "Epoch 1674/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2825 - acc: 0.8807 - val_loss: 0.3479 - val_acc: 0.8591\n",
      "Epoch 1675/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2790 - acc: 0.8875 - val_loss: 0.3483 - val_acc: 0.8564\n",
      "Epoch 1676/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2790 - acc: 0.8853 - val_loss: 0.3487 - val_acc: 0.8557\n",
      "Epoch 1677/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2774 - acc: 0.8857 - val_loss: 0.3480 - val_acc: 0.8577\n",
      "Epoch 1678/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2785 - acc: 0.8856 - val_loss: 0.3483 - val_acc: 0.8584\n",
      "Epoch 1679/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2791 - acc: 0.8860 - val_loss: 0.3473 - val_acc: 0.8591\n",
      "Epoch 1680/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2834 - acc: 0.8847 - val_loss: 0.3480 - val_acc: 0.8598\n",
      "Epoch 1681/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2805 - acc: 0.8846 - val_loss: 0.3476 - val_acc: 0.8570\n",
      "Epoch 1682/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2781 - acc: 0.8870 - val_loss: 0.3479 - val_acc: 0.8591\n",
      "Epoch 1683/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2812 - acc: 0.8850 - val_loss: 0.3495 - val_acc: 0.8577\n",
      "Epoch 1684/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2845 - acc: 0.8813 - val_loss: 0.3480 - val_acc: 0.8604\n",
      "Epoch 1685/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2807 - acc: 0.8869 - val_loss: 0.3477 - val_acc: 0.8591\n",
      "Epoch 1686/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2815 - acc: 0.8830 - val_loss: 0.3475 - val_acc: 0.8584\n",
      "Epoch 1687/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2793 - acc: 0.8851 - val_loss: 0.3475 - val_acc: 0.8577\n",
      "Epoch 1688/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2820 - acc: 0.8838 - val_loss: 0.3471 - val_acc: 0.8611\n",
      "Epoch 1689/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2805 - acc: 0.8848 - val_loss: 0.3480 - val_acc: 0.8598\n",
      "Epoch 1690/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2791 - acc: 0.8862 - val_loss: 0.3489 - val_acc: 0.8550\n",
      "Epoch 1691/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2816 - acc: 0.8821 - val_loss: 0.3480 - val_acc: 0.8577\n",
      "Epoch 1692/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2827 - acc: 0.8833 - val_loss: 0.3471 - val_acc: 0.8591\n",
      "Epoch 1693/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2794 - acc: 0.8850 - val_loss: 0.3480 - val_acc: 0.8584\n",
      "Epoch 1694/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2789 - acc: 0.8862 - val_loss: 0.3475 - val_acc: 0.8584\n",
      "Epoch 1695/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2807 - acc: 0.8847 - val_loss: 0.3475 - val_acc: 0.8584\n",
      "Epoch 1696/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2808 - acc: 0.8835 - val_loss: 0.3475 - val_acc: 0.8591\n",
      "Epoch 1697/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.2788 - acc: 0.886 - 0s 28us/sample - loss: 0.2789 - acc: 0.8855 - val_loss: 0.3467 - val_acc: 0.8584\n",
      "Epoch 1698/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2776 - acc: 0.8855 - val_loss: 0.3477 - val_acc: 0.8550\n",
      "Epoch 1699/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2800 - acc: 0.8843 - val_loss: 0.3472 - val_acc: 0.8570\n",
      "Epoch 1700/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2806 - acc: 0.8841 - val_loss: 0.3474 - val_acc: 0.8570\n",
      "Epoch 1701/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2782 - acc: 0.8854 - val_loss: 0.3474 - val_acc: 0.8584\n",
      "Epoch 1702/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2815 - acc: 0.8826 - val_loss: 0.3474 - val_acc: 0.8570\n",
      "Epoch 1703/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2809 - acc: 0.8845 - val_loss: 0.3475 - val_acc: 0.8577\n",
      "Epoch 1704/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2814 - acc: 0.8811 - val_loss: 0.3474 - val_acc: 0.8598\n",
      "Epoch 1705/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2849 - acc: 0.8821 - val_loss: 0.3471 - val_acc: 0.8604\n",
      "Epoch 1706/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2786 - acc: 0.8844 - val_loss: 0.3473 - val_acc: 0.8577\n",
      "Epoch 1707/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2808 - acc: 0.8829 - val_loss: 0.3479 - val_acc: 0.8570\n",
      "Epoch 1708/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2818 - acc: 0.8833 - val_loss: 0.3479 - val_acc: 0.8577\n",
      "Epoch 1709/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2777 - acc: 0.8864 - val_loss: 0.3475 - val_acc: 0.8591\n",
      "Epoch 1710/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2777 - acc: 0.8857 - val_loss: 0.3476 - val_acc: 0.8611\n",
      "Epoch 1711/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2797 - acc: 0.8841 - val_loss: 0.3475 - val_acc: 0.8577\n",
      "Epoch 1712/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2769 - acc: 0.8860 - val_loss: 0.3477 - val_acc: 0.8584\n",
      "Epoch 1713/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2794 - acc: 0.8839 - val_loss: 0.3473 - val_acc: 0.8591\n",
      "Epoch 1714/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2773 - acc: 0.8851 - val_loss: 0.3477 - val_acc: 0.8584\n",
      "Epoch 1715/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2833 - acc: 0.8834 - val_loss: 0.3467 - val_acc: 0.8584\n",
      "Epoch 1716/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2815 - acc: 0.8840 - val_loss: 0.3478 - val_acc: 0.8570\n",
      "Epoch 1717/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2791 - acc: 0.8841 - val_loss: 0.3481 - val_acc: 0.8550\n",
      "Epoch 1718/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2776 - acc: 0.8847 - val_loss: 0.3471 - val_acc: 0.8618\n",
      "Epoch 1719/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2819 - acc: 0.8832 - val_loss: 0.3473 - val_acc: 0.8577\n",
      "Epoch 1720/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2783 - acc: 0.8860 - val_loss: 0.3472 - val_acc: 0.8598\n",
      "Epoch 1721/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2835 - acc: 0.8835 - val_loss: 0.3477 - val_acc: 0.8584\n",
      "Epoch 1722/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2750 - acc: 0.8858 - val_loss: 0.3472 - val_acc: 0.8577\n",
      "Epoch 1723/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2753 - acc: 0.8876 - val_loss: 0.3474 - val_acc: 0.8618\n",
      "Epoch 1724/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2803 - acc: 0.8847 - val_loss: 0.3471 - val_acc: 0.8598\n",
      "Epoch 1725/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2787 - acc: 0.8829 - val_loss: 0.3480 - val_acc: 0.8577\n",
      "Epoch 1726/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2822 - acc: 0.8827 - val_loss: 0.3469 - val_acc: 0.8611\n",
      "Epoch 1727/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2802 - acc: 0.8835 - val_loss: 0.3469 - val_acc: 0.8570\n",
      "Epoch 1728/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2769 - acc: 0.8858 - val_loss: 0.3474 - val_acc: 0.8591\n",
      "Epoch 1729/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2795 - acc: 0.8826 - val_loss: 0.3466 - val_acc: 0.8611\n",
      "Epoch 1730/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2814 - acc: 0.8824 - val_loss: 0.3465 - val_acc: 0.8604\n",
      "Epoch 1731/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2822 - acc: 0.8818 - val_loss: 0.3475 - val_acc: 0.8611\n",
      "Epoch 1732/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2786 - acc: 0.8835 - val_loss: 0.3473 - val_acc: 0.8591\n",
      "Epoch 1733/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2793 - acc: 0.8844 - val_loss: 0.3481 - val_acc: 0.8584\n",
      "Epoch 1734/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2765 - acc: 0.8850 - val_loss: 0.3460 - val_acc: 0.8618\n",
      "Epoch 1735/10000\n",
      "13284/13284 [==============================] - 1s 49us/sample - loss: 0.2791 - acc: 0.8854 - val_loss: 0.3470 - val_acc: 0.8598\n",
      "Epoch 1736/10000\n",
      "13284/13284 [==============================] - 1s 51us/sample - loss: 0.2778 - acc: 0.8851 - val_loss: 0.3467 - val_acc: 0.8584\n",
      "Epoch 1737/10000\n",
      "13284/13284 [==============================] - 1s 50us/sample - loss: 0.2790 - acc: 0.8839 - val_loss: 0.3474 - val_acc: 0.8591\n",
      "Epoch 1738/10000\n",
      "13284/13284 [==============================] - 1s 50us/sample - loss: 0.2783 - acc: 0.8850 - val_loss: 0.3474 - val_acc: 0.8591\n",
      "Epoch 1739/10000\n",
      "13284/13284 [==============================] - 1s 50us/sample - loss: 0.2765 - acc: 0.8866 - val_loss: 0.3487 - val_acc: 0.8564\n",
      "Epoch 1740/10000\n",
      "13284/13284 [==============================] - 1s 51us/sample - loss: 0.2772 - acc: 0.8850 - val_loss: 0.3471 - val_acc: 0.8584\n",
      "Epoch 1741/10000\n",
      "13284/13284 [==============================] - 1s 51us/sample - loss: 0.2830 - acc: 0.8831 - val_loss: 0.3475 - val_acc: 0.8584\n",
      "Epoch 1742/10000\n",
      "13284/13284 [==============================] - 1s 51us/sample - loss: 0.2783 - acc: 0.8847 - val_loss: 0.3477 - val_acc: 0.8577\n",
      "Epoch 1743/10000\n",
      "13284/13284 [==============================] - 1s 51us/sample - loss: 0.2792 - acc: 0.8851 - val_loss: 0.3477 - val_acc: 0.8604\n",
      "Epoch 1744/10000\n",
      "13284/13284 [==============================] - 1s 51us/sample - loss: 0.2752 - acc: 0.8859 - val_loss: 0.3477 - val_acc: 0.8537\n",
      "Epoch 1745/10000\n",
      "13284/13284 [==============================] - 1s 51us/sample - loss: 0.2778 - acc: 0.8842 - val_loss: 0.3475 - val_acc: 0.8584\n",
      "Epoch 1746/10000\n",
      "13284/13284 [==============================] - 1s 52us/sample - loss: 0.2820 - acc: 0.8865 - val_loss: 0.3468 - val_acc: 0.8598\n",
      "Epoch 1747/10000\n",
      "13284/13284 [==============================] - 0s 33us/sample - loss: 0.2793 - acc: 0.8840 - val_loss: 0.3463 - val_acc: 0.8618\n",
      "Epoch 1748/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2783 - acc: 0.8847 - val_loss: 0.3473 - val_acc: 0.8584\n",
      "Epoch 1749/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2766 - acc: 0.8886 - val_loss: 0.3472 - val_acc: 0.8604\n",
      "Epoch 1750/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2798 - acc: 0.8844 - val_loss: 0.3471 - val_acc: 0.8591\n",
      "Epoch 1751/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2800 - acc: 0.8850 - val_loss: 0.3470 - val_acc: 0.8604\n",
      "Epoch 1752/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2762 - acc: 0.8863 - val_loss: 0.3468 - val_acc: 0.8604\n",
      "Epoch 1753/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2843 - acc: 0.8805 - val_loss: 0.3476 - val_acc: 0.8584\n",
      "Epoch 1754/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2775 - acc: 0.8849 - val_loss: 0.3472 - val_acc: 0.8618\n",
      "Epoch 1755/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2794 - acc: 0.8844 - val_loss: 0.3473 - val_acc: 0.8611\n",
      "Epoch 1756/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2815 - acc: 0.8852 - val_loss: 0.3469 - val_acc: 0.8598\n",
      "Epoch 1757/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2808 - acc: 0.8847 - val_loss: 0.3478 - val_acc: 0.8591\n",
      "Epoch 1758/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2821 - acc: 0.8828 - val_loss: 0.3476 - val_acc: 0.8618\n",
      "Epoch 1759/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2763 - acc: 0.8872 - val_loss: 0.3470 - val_acc: 0.8611\n",
      "Epoch 1760/10000\n",
      "13284/13284 [==============================] - 1s 44us/sample - loss: 0.2795 - acc: 0.8855 - val_loss: 0.3476 - val_acc: 0.8584\n",
      "Epoch 1761/10000\n",
      "13284/13284 [==============================] - 1s 49us/sample - loss: 0.2765 - acc: 0.8872 - val_loss: 0.3475 - val_acc: 0.8591\n",
      "Epoch 1762/10000\n",
      "13284/13284 [==============================] - 1s 46us/sample - loss: 0.2762 - acc: 0.8844 - val_loss: 0.3473 - val_acc: 0.8598\n",
      "Epoch 1763/10000\n",
      "13284/13284 [==============================] - 1s 47us/sample - loss: 0.2829 - acc: 0.8797 - val_loss: 0.3468 - val_acc: 0.8591\n",
      "Epoch 1764/10000\n",
      "13284/13284 [==============================] - 1s 48us/sample - loss: 0.2754 - acc: 0.8868 - val_loss: 0.3484 - val_acc: 0.8584\n",
      "Epoch 1765/10000\n",
      "13284/13284 [==============================] - 1s 50us/sample - loss: 0.2754 - acc: 0.8865 - val_loss: 0.3501 - val_acc: 0.8570\n",
      "Epoch 1766/10000\n",
      "13284/13284 [==============================] - 1s 50us/sample - loss: 0.2751 - acc: 0.8882 - val_loss: 0.3470 - val_acc: 0.8584\n",
      "Epoch 1767/10000\n",
      "13284/13284 [==============================] - 1s 48us/sample - loss: 0.2783 - acc: 0.8844 - val_loss: 0.3467 - val_acc: 0.8598\n",
      "Epoch 1768/10000\n",
      "13284/13284 [==============================] - 1s 51us/sample - loss: 0.2776 - acc: 0.8863 - val_loss: 0.3466 - val_acc: 0.8625\n",
      "Epoch 1769/10000\n",
      "13284/13284 [==============================] - 1s 46us/sample - loss: 0.2811 - acc: 0.8837 - val_loss: 0.3470 - val_acc: 0.8584\n",
      "Epoch 1770/10000\n",
      "13284/13284 [==============================] - 1s 46us/sample - loss: 0.2763 - acc: 0.8855 - val_loss: 0.3476 - val_acc: 0.8604\n",
      "Epoch 1771/10000\n",
      "13284/13284 [==============================] - 1s 47us/sample - loss: 0.2813 - acc: 0.8830 - val_loss: 0.3468 - val_acc: 0.8604\n",
      "Epoch 1772/10000\n",
      "13284/13284 [==============================] - 1s 42us/sample - loss: 0.2782 - acc: 0.8832 - val_loss: 0.3463 - val_acc: 0.8631\n",
      "Epoch 1773/10000\n",
      "13284/13284 [==============================] - 1s 39us/sample - loss: 0.2793 - acc: 0.8854 - val_loss: 0.3471 - val_acc: 0.8625\n",
      "Epoch 1774/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2750 - acc: 0.8873 - val_loss: 0.3474 - val_acc: 0.8604\n",
      "Epoch 1775/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2757 - acc: 0.8857 - val_loss: 0.3475 - val_acc: 0.8591\n",
      "Epoch 1776/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2779 - acc: 0.8847 - val_loss: 0.3468 - val_acc: 0.8591\n",
      "Epoch 1777/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2746 - acc: 0.8884 - val_loss: 0.3477 - val_acc: 0.8618\n",
      "Epoch 1778/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2776 - acc: 0.8860 - val_loss: 0.3464 - val_acc: 0.8604\n",
      "Epoch 1779/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2839 - acc: 0.8826 - val_loss: 0.3470 - val_acc: 0.8598\n",
      "Epoch 1780/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2827 - acc: 0.8823 - val_loss: 0.3464 - val_acc: 0.8611\n",
      "Epoch 1781/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2771 - acc: 0.8853 - val_loss: 0.3474 - val_acc: 0.8618\n",
      "Epoch 1782/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2794 - acc: 0.8831 - val_loss: 0.3466 - val_acc: 0.8625\n",
      "Epoch 1783/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2785 - acc: 0.8846 - val_loss: 0.3478 - val_acc: 0.8598\n",
      "Epoch 1784/10000\n",
      "13284/13284 [==============================] - 0s 32us/sample - loss: 0.2747 - acc: 0.8843 - val_loss: 0.3477 - val_acc: 0.8598\n",
      "Epoch 1785/10000\n",
      "13284/13284 [==============================] - 0s 32us/sample - loss: 0.2794 - acc: 0.8844 - val_loss: 0.3463 - val_acc: 0.8625\n",
      "Epoch 1786/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2743 - acc: 0.8876 - val_loss: 0.3474 - val_acc: 0.8584\n",
      "Epoch 1787/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2777 - acc: 0.8847 - val_loss: 0.3475 - val_acc: 0.8598\n",
      "Epoch 1788/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2792 - acc: 0.8845 - val_loss: 0.3474 - val_acc: 0.8618\n",
      "Epoch 1789/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2785 - acc: 0.8847 - val_loss: 0.3470 - val_acc: 0.8638\n",
      "Epoch 1790/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.2789 - acc: 0.885 - 0s 29us/sample - loss: 0.2779 - acc: 0.8856 - val_loss: 0.3468 - val_acc: 0.8611\n",
      "Epoch 1791/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2779 - acc: 0.8876 - val_loss: 0.3463 - val_acc: 0.8604\n",
      "Epoch 1792/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2763 - acc: 0.8890 - val_loss: 0.3465 - val_acc: 0.8611\n",
      "Epoch 1793/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2729 - acc: 0.8873 - val_loss: 0.3474 - val_acc: 0.8584\n",
      "Epoch 1794/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2769 - acc: 0.8873 - val_loss: 0.3469 - val_acc: 0.8625\n",
      "Epoch 1795/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2776 - acc: 0.8842 - val_loss: 0.3461 - val_acc: 0.8604\n",
      "Epoch 1796/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2748 - acc: 0.8861 - val_loss: 0.3471 - val_acc: 0.8584\n",
      "Epoch 1797/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2750 - acc: 0.8860 - val_loss: 0.3470 - val_acc: 0.8591\n",
      "Epoch 1798/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2744 - acc: 0.8843 - val_loss: 0.3464 - val_acc: 0.8604\n",
      "Epoch 1799/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2758 - acc: 0.8879 - val_loss: 0.3468 - val_acc: 0.8598\n",
      "Epoch 1800/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2817 - acc: 0.8835 - val_loss: 0.3466 - val_acc: 0.8598\n",
      "Epoch 1801/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2789 - acc: 0.8837 - val_loss: 0.3472 - val_acc: 0.8604\n",
      "Epoch 1802/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2782 - acc: 0.8839 - val_loss: 0.3468 - val_acc: 0.8611\n",
      "Epoch 1803/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2769 - acc: 0.8857 - val_loss: 0.3474 - val_acc: 0.8611\n",
      "Epoch 1804/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2795 - acc: 0.8847 - val_loss: 0.3472 - val_acc: 0.8604\n",
      "Epoch 1805/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2741 - acc: 0.8864 - val_loss: 0.3474 - val_acc: 0.8611\n",
      "Epoch 1806/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2798 - acc: 0.8854 - val_loss: 0.3469 - val_acc: 0.8598\n",
      "Epoch 1807/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2741 - acc: 0.8878 - val_loss: 0.3471 - val_acc: 0.8618\n",
      "Epoch 1808/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2766 - acc: 0.8828 - val_loss: 0.3464 - val_acc: 0.8611\n",
      "Epoch 1809/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2791 - acc: 0.8850 - val_loss: 0.3472 - val_acc: 0.8631\n",
      "Epoch 1810/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2790 - acc: 0.8841 - val_loss: 0.3467 - val_acc: 0.8625\n",
      "Epoch 1811/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2764 - acc: 0.8866 - val_loss: 0.3473 - val_acc: 0.8618\n",
      "Epoch 1812/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2792 - acc: 0.8842 - val_loss: 0.3471 - val_acc: 0.8631\n",
      "Epoch 1813/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2767 - acc: 0.8857 - val_loss: 0.3461 - val_acc: 0.8645\n",
      "Epoch 1814/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2764 - acc: 0.8859 - val_loss: 0.3464 - val_acc: 0.8631\n",
      "Epoch 1815/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2799 - acc: 0.8833 - val_loss: 0.3463 - val_acc: 0.8631\n",
      "Epoch 1816/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2763 - acc: 0.8869 - val_loss: 0.3478 - val_acc: 0.8611\n",
      "Epoch 1817/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2753 - acc: 0.8864 - val_loss: 0.3475 - val_acc: 0.8625\n",
      "Epoch 1818/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2753 - acc: 0.8859 - val_loss: 0.3467 - val_acc: 0.8618\n",
      "Epoch 1819/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2767 - acc: 0.8843 - val_loss: 0.3466 - val_acc: 0.8625\n",
      "Epoch 1820/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2750 - acc: 0.8870 - val_loss: 0.3469 - val_acc: 0.8611\n",
      "Epoch 1821/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2772 - acc: 0.8823 - val_loss: 0.3464 - val_acc: 0.8631\n",
      "Epoch 1822/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2774 - acc: 0.8858 - val_loss: 0.3470 - val_acc: 0.8618\n",
      "Epoch 1823/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2771 - acc: 0.8851 - val_loss: 0.3463 - val_acc: 0.8631\n",
      "Epoch 1824/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2765 - acc: 0.8853 - val_loss: 0.3472 - val_acc: 0.8618\n",
      "Epoch 1825/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2751 - acc: 0.8887 - val_loss: 0.3476 - val_acc: 0.8618\n",
      "Epoch 1826/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2747 - acc: 0.8878 - val_loss: 0.3468 - val_acc: 0.8625\n",
      "Epoch 1827/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2755 - acc: 0.8864 - val_loss: 0.3466 - val_acc: 0.8631\n",
      "Epoch 1828/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2750 - acc: 0.8867 - val_loss: 0.3466 - val_acc: 0.8631\n",
      "Epoch 1829/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2747 - acc: 0.8867 - val_loss: 0.3458 - val_acc: 0.8638\n",
      "Epoch 1830/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2768 - acc: 0.8850 - val_loss: 0.3461 - val_acc: 0.8591\n",
      "Epoch 1831/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2708 - acc: 0.8883 - val_loss: 0.3471 - val_acc: 0.8584\n",
      "Epoch 1832/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2775 - acc: 0.8858 - val_loss: 0.3470 - val_acc: 0.8618\n",
      "Epoch 1833/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2772 - acc: 0.8863 - val_loss: 0.3464 - val_acc: 0.8638\n",
      "Epoch 1834/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2786 - acc: 0.8848 - val_loss: 0.3457 - val_acc: 0.8645\n",
      "Epoch 1835/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2738 - acc: 0.8887 - val_loss: 0.3465 - val_acc: 0.8625\n",
      "Epoch 1836/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2744 - acc: 0.8884 - val_loss: 0.3468 - val_acc: 0.8638\n",
      "Epoch 1837/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2779 - acc: 0.8855 - val_loss: 0.3461 - val_acc: 0.8645\n",
      "Epoch 1838/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2759 - acc: 0.8857 - val_loss: 0.3461 - val_acc: 0.8652\n",
      "Epoch 1839/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2740 - acc: 0.8878 - val_loss: 0.3464 - val_acc: 0.8604\n",
      "Epoch 1840/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2802 - acc: 0.8846 - val_loss: 0.3464 - val_acc: 0.8625\n",
      "Epoch 1841/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2737 - acc: 0.8875 - val_loss: 0.3472 - val_acc: 0.8611\n",
      "Epoch 1842/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2770 - acc: 0.8838 - val_loss: 0.3459 - val_acc: 0.8645\n",
      "Epoch 1843/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2735 - acc: 0.8875 - val_loss: 0.3461 - val_acc: 0.8645\n",
      "Epoch 1844/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2753 - acc: 0.8869 - val_loss: 0.3480 - val_acc: 0.8591\n",
      "Epoch 1845/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2724 - acc: 0.8897 - val_loss: 0.3462 - val_acc: 0.8625\n",
      "Epoch 1846/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2717 - acc: 0.8867 - val_loss: 0.3469 - val_acc: 0.8631\n",
      "Epoch 1847/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2739 - acc: 0.8881 - val_loss: 0.3461 - val_acc: 0.8652\n",
      "Epoch 1848/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2793 - acc: 0.8852 - val_loss: 0.3459 - val_acc: 0.8659\n",
      "Epoch 1849/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2770 - acc: 0.8865 - val_loss: 0.3460 - val_acc: 0.8625\n",
      "Epoch 1850/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2745 - acc: 0.8890 - val_loss: 0.3461 - val_acc: 0.8631\n",
      "Epoch 1851/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2783 - acc: 0.8842 - val_loss: 0.3456 - val_acc: 0.8618\n",
      "Epoch 1852/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2765 - acc: 0.8865 - val_loss: 0.3461 - val_acc: 0.8638\n",
      "Epoch 1853/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2752 - acc: 0.8876 - val_loss: 0.3465 - val_acc: 0.8652\n",
      "Epoch 1854/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2747 - acc: 0.8854 - val_loss: 0.3456 - val_acc: 0.8638\n",
      "Epoch 1855/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2756 - acc: 0.8847 - val_loss: 0.3468 - val_acc: 0.8625\n",
      "Epoch 1856/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2739 - acc: 0.8893 - val_loss: 0.3452 - val_acc: 0.8652\n",
      "Epoch 1857/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2716 - acc: 0.8858 - val_loss: 0.3461 - val_acc: 0.8631\n",
      "Epoch 1858/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2783 - acc: 0.8845 - val_loss: 0.3459 - val_acc: 0.8659\n",
      "Epoch 1859/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2767 - acc: 0.8881 - val_loss: 0.3460 - val_acc: 0.8659\n",
      "Epoch 1860/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2720 - acc: 0.8908 - val_loss: 0.3464 - val_acc: 0.8618\n",
      "Epoch 1861/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2741 - acc: 0.8872 - val_loss: 0.3463 - val_acc: 0.8652\n",
      "Epoch 1862/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2704 - acc: 0.8864 - val_loss: 0.3467 - val_acc: 0.8652\n",
      "Epoch 1863/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2742 - acc: 0.8881 - val_loss: 0.3469 - val_acc: 0.8659\n",
      "Epoch 1864/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2710 - acc: 0.8895 - val_loss: 0.3464 - val_acc: 0.8638\n",
      "Epoch 1865/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2739 - acc: 0.8876 - val_loss: 0.3463 - val_acc: 0.8652\n",
      "Epoch 1866/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2759 - acc: 0.8878 - val_loss: 0.3462 - val_acc: 0.8618\n",
      "Epoch 1867/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2776 - acc: 0.8861 - val_loss: 0.3460 - val_acc: 0.8652\n",
      "Epoch 1868/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2774 - acc: 0.8835 - val_loss: 0.3455 - val_acc: 0.8659\n",
      "Epoch 1869/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2759 - acc: 0.8864 - val_loss: 0.3463 - val_acc: 0.8645\n",
      "Epoch 1870/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2743 - acc: 0.8880 - val_loss: 0.3459 - val_acc: 0.8645\n",
      "Epoch 1871/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2721 - acc: 0.8859 - val_loss: 0.3469 - val_acc: 0.8645\n",
      "Epoch 1872/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2770 - acc: 0.8848 - val_loss: 0.3468 - val_acc: 0.8652\n",
      "Epoch 1873/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2745 - acc: 0.8866 - val_loss: 0.3455 - val_acc: 0.8645\n",
      "Epoch 1874/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2763 - acc: 0.8854 - val_loss: 0.3459 - val_acc: 0.8638\n",
      "Epoch 1875/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2778 - acc: 0.8869 - val_loss: 0.3460 - val_acc: 0.8645\n",
      "Epoch 1876/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2720 - acc: 0.8878 - val_loss: 0.3460 - val_acc: 0.8645\n",
      "Epoch 1877/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2731 - acc: 0.8899 - val_loss: 0.3460 - val_acc: 0.8659\n",
      "Epoch 1878/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2707 - acc: 0.8887 - val_loss: 0.3460 - val_acc: 0.8645\n",
      "Epoch 1879/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2685 - acc: 0.8921 - val_loss: 0.3458 - val_acc: 0.8638\n",
      "Epoch 1880/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2765 - acc: 0.8879 - val_loss: 0.3472 - val_acc: 0.8645\n",
      "Epoch 1881/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2738 - acc: 0.8866 - val_loss: 0.3455 - val_acc: 0.8652\n",
      "Epoch 1882/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2733 - acc: 0.8895 - val_loss: 0.3460 - val_acc: 0.8659\n",
      "Epoch 1883/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2742 - acc: 0.8877 - val_loss: 0.3456 - val_acc: 0.8618\n",
      "Epoch 1884/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2757 - acc: 0.8858 - val_loss: 0.3462 - val_acc: 0.8659\n",
      "Epoch 1885/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2731 - acc: 0.8895 - val_loss: 0.3464 - val_acc: 0.8659\n",
      "Epoch 1886/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2736 - acc: 0.8875 - val_loss: 0.3458 - val_acc: 0.8625\n",
      "Epoch 1887/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2749 - acc: 0.8869 - val_loss: 0.3459 - val_acc: 0.8659\n",
      "Epoch 1888/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2714 - acc: 0.8889 - val_loss: 0.3462 - val_acc: 0.8659\n",
      "Epoch 1889/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2720 - acc: 0.8887 - val_loss: 0.3460 - val_acc: 0.8652\n",
      "Epoch 1890/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2756 - acc: 0.8854 - val_loss: 0.3469 - val_acc: 0.8665\n",
      "Epoch 1891/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2718 - acc: 0.8893 - val_loss: 0.3464 - val_acc: 0.8659\n",
      "Epoch 1892/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2803 - acc: 0.8831 - val_loss: 0.3465 - val_acc: 0.8645\n",
      "Epoch 1893/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2743 - acc: 0.8882 - val_loss: 0.3453 - val_acc: 0.8652\n",
      "Epoch 1894/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2697 - acc: 0.8896 - val_loss: 0.3461 - val_acc: 0.8645\n",
      "Epoch 1895/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2728 - acc: 0.8871 - val_loss: 0.3456 - val_acc: 0.8652\n",
      "Epoch 1896/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2752 - acc: 0.8861 - val_loss: 0.3461 - val_acc: 0.8638\n",
      "Epoch 1897/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2740 - acc: 0.8898 - val_loss: 0.3459 - val_acc: 0.8672\n",
      "Epoch 1898/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2749 - acc: 0.8882 - val_loss: 0.3460 - val_acc: 0.8645\n",
      "Epoch 1899/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2696 - acc: 0.8885 - val_loss: 0.3458 - val_acc: 0.8645\n",
      "Epoch 1900/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2739 - acc: 0.8866 - val_loss: 0.3452 - val_acc: 0.8652\n",
      "Epoch 1901/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2767 - acc: 0.8869 - val_loss: 0.3461 - val_acc: 0.8638\n",
      "Epoch 1902/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2792 - acc: 0.8866 - val_loss: 0.3456 - val_acc: 0.8645\n",
      "Epoch 1903/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2737 - acc: 0.8896 - val_loss: 0.3459 - val_acc: 0.8645\n",
      "Epoch 1904/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2710 - acc: 0.8873 - val_loss: 0.3461 - val_acc: 0.8659\n",
      "Epoch 1905/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2732 - acc: 0.8897 - val_loss: 0.3458 - val_acc: 0.8638\n",
      "Epoch 1906/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2777 - acc: 0.8863 - val_loss: 0.3459 - val_acc: 0.8611\n",
      "Epoch 1907/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2711 - acc: 0.8897 - val_loss: 0.3459 - val_acc: 0.8604\n",
      "Epoch 1908/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2730 - acc: 0.8887 - val_loss: 0.3457 - val_acc: 0.8631\n",
      "Epoch 1909/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2729 - acc: 0.8881 - val_loss: 0.3459 - val_acc: 0.8618\n",
      "Epoch 1910/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2715 - acc: 0.8884 - val_loss: 0.3458 - val_acc: 0.8645\n",
      "Epoch 1911/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2716 - acc: 0.8878 - val_loss: 0.3462 - val_acc: 0.8631\n",
      "Epoch 1912/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2735 - acc: 0.8867 - val_loss: 0.3455 - val_acc: 0.8638\n",
      "Epoch 1913/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2691 - acc: 0.8888 - val_loss: 0.3457 - val_acc: 0.8625\n",
      "Epoch 1914/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2728 - acc: 0.8863 - val_loss: 0.3464 - val_acc: 0.8631\n",
      "Epoch 1915/10000\n",
      "13284/13284 [==============================] - 0s 30us/sample - loss: 0.2739 - acc: 0.8875 - val_loss: 0.3474 - val_acc: 0.8638\n",
      "Epoch 1916/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2688 - acc: 0.8900 - val_loss: 0.3466 - val_acc: 0.8611\n",
      "Epoch 1917/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2710 - acc: 0.8896 - val_loss: 0.3465 - val_acc: 0.8645\n",
      "Epoch 1918/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2743 - acc: 0.8867 - val_loss: 0.3464 - val_acc: 0.8611\n",
      "Epoch 1919/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2720 - acc: 0.8888 - val_loss: 0.3462 - val_acc: 0.8631\n",
      "Epoch 1920/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2714 - acc: 0.8899 - val_loss: 0.3465 - val_acc: 0.8652\n",
      "Epoch 1921/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2755 - acc: 0.8885 - val_loss: 0.3459 - val_acc: 0.8638\n",
      "Epoch 1922/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2741 - acc: 0.8881 - val_loss: 0.3466 - val_acc: 0.8659\n",
      "Epoch 1923/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2743 - acc: 0.8865 - val_loss: 0.3469 - val_acc: 0.8659\n",
      "Epoch 1924/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2711 - acc: 0.8909 - val_loss: 0.3472 - val_acc: 0.8659\n",
      "Epoch 1925/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2728 - acc: 0.8884 - val_loss: 0.3461 - val_acc: 0.8652\n",
      "Epoch 1926/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2678 - acc: 0.8905 - val_loss: 0.3466 - val_acc: 0.8645\n",
      "Epoch 1927/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2744 - acc: 0.8869 - val_loss: 0.3465 - val_acc: 0.8652\n",
      "Epoch 1928/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2706 - acc: 0.8902 - val_loss: 0.3467 - val_acc: 0.8665\n",
      "Epoch 1929/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2749 - acc: 0.8869 - val_loss: 0.3458 - val_acc: 0.8645\n",
      "Epoch 1930/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2746 - acc: 0.8895 - val_loss: 0.3462 - val_acc: 0.8625\n",
      "Epoch 1931/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2716 - acc: 0.8898 - val_loss: 0.3465 - val_acc: 0.8645\n",
      "Epoch 1932/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2766 - acc: 0.8873 - val_loss: 0.3468 - val_acc: 0.8659\n",
      "Epoch 1933/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2717 - acc: 0.8886 - val_loss: 0.3462 - val_acc: 0.8652\n",
      "Epoch 1934/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2691 - acc: 0.8912 - val_loss: 0.3454 - val_acc: 0.8638\n",
      "Epoch 1935/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2719 - acc: 0.8909 - val_loss: 0.3456 - val_acc: 0.8625\n",
      "Epoch 1936/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2706 - acc: 0.8881 - val_loss: 0.3459 - val_acc: 0.8652\n",
      "Epoch 1937/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2783 - acc: 0.8860 - val_loss: 0.3457 - val_acc: 0.8659\n",
      "Epoch 1938/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.2667 - acc: 0.891 - 0s 29us/sample - loss: 0.2707 - acc: 0.8904 - val_loss: 0.3449 - val_acc: 0.8625\n",
      "Epoch 1939/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2670 - acc: 0.8940 - val_loss: 0.3453 - val_acc: 0.8631\n",
      "Epoch 1940/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2710 - acc: 0.8898 - val_loss: 0.3459 - val_acc: 0.8618\n",
      "Epoch 1941/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2695 - acc: 0.8890 - val_loss: 0.3458 - val_acc: 0.8645\n",
      "Epoch 1942/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2726 - acc: 0.8869 - val_loss: 0.3461 - val_acc: 0.8652\n",
      "Epoch 1943/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2737 - acc: 0.8877 - val_loss: 0.3458 - val_acc: 0.8652\n",
      "Epoch 1944/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2730 - acc: 0.8875 - val_loss: 0.3461 - val_acc: 0.8659\n",
      "Epoch 1945/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2710 - acc: 0.8882 - val_loss: 0.3453 - val_acc: 0.8631\n",
      "Epoch 1946/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2670 - acc: 0.8904 - val_loss: 0.3454 - val_acc: 0.8652\n",
      "Epoch 1947/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2742 - acc: 0.8877 - val_loss: 0.3461 - val_acc: 0.8659\n",
      "Epoch 1948/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2698 - acc: 0.8906 - val_loss: 0.3463 - val_acc: 0.8652\n",
      "Epoch 1949/10000\n",
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2693 - acc: 0.8922 - val_loss: 0.3457 - val_acc: 0.8659\n",
      "Epoch 1950/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2728 - acc: 0.8886 - val_loss: 0.3456 - val_acc: 0.8659\n",
      "Epoch 1951/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2707 - acc: 0.8904 - val_loss: 0.3454 - val_acc: 0.8659\n",
      "Epoch 1952/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2689 - acc: 0.8917 - val_loss: 0.3456 - val_acc: 0.8659\n",
      "Epoch 1953/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2747 - acc: 0.8892 - val_loss: 0.3461 - val_acc: 0.8645\n",
      "Epoch 1954/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2721 - acc: 0.8890 - val_loss: 0.3445 - val_acc: 0.8672\n",
      "Epoch 1955/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2723 - acc: 0.8886 - val_loss: 0.3451 - val_acc: 0.8659\n",
      "Epoch 1956/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2735 - acc: 0.8897 - val_loss: 0.3454 - val_acc: 0.8659\n",
      "Epoch 1957/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2716 - acc: 0.8869 - val_loss: 0.3457 - val_acc: 0.8631\n",
      "Epoch 1958/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2726 - acc: 0.8883 - val_loss: 0.3461 - val_acc: 0.8665\n",
      "Epoch 1959/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2754 - acc: 0.8872 - val_loss: 0.3457 - val_acc: 0.8631\n",
      "Epoch 1960/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2742 - acc: 0.8889 - val_loss: 0.3453 - val_acc: 0.8631\n",
      "Epoch 1961/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2706 - acc: 0.8887 - val_loss: 0.3460 - val_acc: 0.8625\n",
      "Epoch 1962/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2706 - acc: 0.8898 - val_loss: 0.3447 - val_acc: 0.8659\n",
      "Epoch 1963/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2689 - acc: 0.8919 - val_loss: 0.3456 - val_acc: 0.8638\n",
      "Epoch 1964/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2713 - acc: 0.8907 - val_loss: 0.3441 - val_acc: 0.8659\n",
      "Epoch 1965/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2699 - acc: 0.8913 - val_loss: 0.3441 - val_acc: 0.8672\n",
      "Epoch 1966/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2721 - acc: 0.8871 - val_loss: 0.3444 - val_acc: 0.8665\n",
      "Epoch 1967/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2755 - acc: 0.8875 - val_loss: 0.3450 - val_acc: 0.8659\n",
      "Epoch 1968/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2687 - acc: 0.8932 - val_loss: 0.3455 - val_acc: 0.8638\n",
      "Epoch 1969/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2736 - acc: 0.8898 - val_loss: 0.3453 - val_acc: 0.8652\n",
      "Epoch 1970/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2746 - acc: 0.8879 - val_loss: 0.3449 - val_acc: 0.8645\n",
      "Epoch 1971/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2701 - acc: 0.8910 - val_loss: 0.3458 - val_acc: 0.8665\n",
      "Epoch 1972/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2727 - acc: 0.8882 - val_loss: 0.3446 - val_acc: 0.8652\n",
      "Epoch 1973/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2700 - acc: 0.8899 - val_loss: 0.3458 - val_acc: 0.8659\n",
      "Epoch 1974/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2734 - acc: 0.8886 - val_loss: 0.3454 - val_acc: 0.8652\n",
      "Epoch 1975/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2740 - acc: 0.8884 - val_loss: 0.3457 - val_acc: 0.8645\n",
      "Epoch 1976/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2714 - acc: 0.8914 - val_loss: 0.3451 - val_acc: 0.8659\n",
      "Epoch 1977/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2673 - acc: 0.8905 - val_loss: 0.3444 - val_acc: 0.8659\n",
      "Epoch 1978/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 31us/sample - loss: 0.2683 - acc: 0.8884 - val_loss: 0.3453 - val_acc: 0.8659\n",
      "Epoch 1979/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2706 - acc: 0.8905 - val_loss: 0.3452 - val_acc: 0.8659\n",
      "Epoch 1980/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2713 - acc: 0.8918 - val_loss: 0.3462 - val_acc: 0.8625\n",
      "Epoch 1981/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2705 - acc: 0.8904 - val_loss: 0.3460 - val_acc: 0.8631\n",
      "Epoch 1982/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2694 - acc: 0.8902 - val_loss: 0.3449 - val_acc: 0.8638\n",
      "Epoch 1983/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2734 - acc: 0.8904 - val_loss: 0.3455 - val_acc: 0.8652\n",
      "Epoch 1984/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2700 - acc: 0.8881 - val_loss: 0.3456 - val_acc: 0.8652\n",
      "Epoch 1985/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2718 - acc: 0.8907 - val_loss: 0.3461 - val_acc: 0.8659\n",
      "Epoch 1986/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2676 - acc: 0.8947 - val_loss: 0.3447 - val_acc: 0.8652\n",
      "Epoch 1987/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2783 - acc: 0.8878 - val_loss: 0.3457 - val_acc: 0.8638\n",
      "Epoch 1988/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2705 - acc: 0.8901 - val_loss: 0.3448 - val_acc: 0.8659\n",
      "Epoch 1989/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2696 - acc: 0.8904 - val_loss: 0.3456 - val_acc: 0.8665\n",
      "Epoch 1990/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2739 - acc: 0.8901 - val_loss: 0.3442 - val_acc: 0.8652\n",
      "Epoch 1991/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2670 - acc: 0.8932 - val_loss: 0.3458 - val_acc: 0.8645\n",
      "Epoch 1992/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2742 - acc: 0.8893 - val_loss: 0.3446 - val_acc: 0.8672\n",
      "Epoch 1993/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2731 - acc: 0.8881 - val_loss: 0.3454 - val_acc: 0.8679\n",
      "Epoch 1994/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2693 - acc: 0.8910 - val_loss: 0.3458 - val_acc: 0.8665\n",
      "Epoch 1995/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2712 - acc: 0.8913 - val_loss: 0.3453 - val_acc: 0.8679\n",
      "Epoch 1996/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2689 - acc: 0.8901 - val_loss: 0.3443 - val_acc: 0.8665\n",
      "Epoch 1997/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2685 - acc: 0.8920 - val_loss: 0.3447 - val_acc: 0.8672\n",
      "Epoch 1998/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2677 - acc: 0.8921 - val_loss: 0.3455 - val_acc: 0.8659\n",
      "Epoch 1999/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2683 - acc: 0.8913 - val_loss: 0.3441 - val_acc: 0.8672\n",
      "Epoch 2000/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2686 - acc: 0.8910 - val_loss: 0.3442 - val_acc: 0.8652\n",
      "Epoch 2001/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2687 - acc: 0.8917 - val_loss: 0.3451 - val_acc: 0.8652\n",
      "Epoch 2002/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2704 - acc: 0.8894 - val_loss: 0.3455 - val_acc: 0.8659\n",
      "Epoch 2003/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2747 - acc: 0.8881 - val_loss: 0.3443 - val_acc: 0.8652\n",
      "Epoch 2004/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2675 - acc: 0.8931 - val_loss: 0.3447 - val_acc: 0.8652\n",
      "Epoch 2005/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2687 - acc: 0.8886 - val_loss: 0.3450 - val_acc: 0.8679\n",
      "Epoch 2006/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2728 - acc: 0.8905 - val_loss: 0.3461 - val_acc: 0.8652\n",
      "Epoch 2007/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2687 - acc: 0.8908 - val_loss: 0.3445 - val_acc: 0.8665\n",
      "Epoch 2008/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2689 - acc: 0.8934 - val_loss: 0.3448 - val_acc: 0.8672\n",
      "Epoch 2009/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2697 - acc: 0.8924 - val_loss: 0.3444 - val_acc: 0.8665\n",
      "Epoch 2010/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2679 - acc: 0.8924 - val_loss: 0.3445 - val_acc: 0.8672\n",
      "Epoch 2011/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2697 - acc: 0.8919 - val_loss: 0.3449 - val_acc: 0.8665\n",
      "Epoch 2012/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2684 - acc: 0.8914 - val_loss: 0.3444 - val_acc: 0.8665\n",
      "Epoch 2013/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2719 - acc: 0.8917 - val_loss: 0.3450 - val_acc: 0.8652\n",
      "Epoch 2014/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2709 - acc: 0.8893 - val_loss: 0.3446 - val_acc: 0.8652\n",
      "Epoch 2015/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2698 - acc: 0.8912 - val_loss: 0.3447 - val_acc: 0.8652\n",
      "Epoch 2016/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2679 - acc: 0.8905 - val_loss: 0.3439 - val_acc: 0.8679\n",
      "Epoch 2017/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2695 - acc: 0.8912 - val_loss: 0.3447 - val_acc: 0.8686\n",
      "Epoch 2018/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2713 - acc: 0.8908 - val_loss: 0.3455 - val_acc: 0.8665\n",
      "Epoch 2019/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2721 - acc: 0.8902 - val_loss: 0.3448 - val_acc: 0.8672\n",
      "Epoch 2020/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2710 - acc: 0.8893 - val_loss: 0.3446 - val_acc: 0.8679\n",
      "Epoch 2021/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2682 - acc: 0.8914 - val_loss: 0.3442 - val_acc: 0.8672\n",
      "Epoch 2022/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2687 - acc: 0.8915 - val_loss: 0.3447 - val_acc: 0.8659\n",
      "Epoch 2023/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2646 - acc: 0.8918 - val_loss: 0.3448 - val_acc: 0.8665\n",
      "Epoch 2024/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2710 - acc: 0.8907 - val_loss: 0.3453 - val_acc: 0.8672\n",
      "Epoch 2025/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2680 - acc: 0.8903 - val_loss: 0.3458 - val_acc: 0.8645\n",
      "Epoch 2026/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2695 - acc: 0.8906 - val_loss: 0.3458 - val_acc: 0.8672\n",
      "Epoch 2027/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2699 - acc: 0.8913 - val_loss: 0.3452 - val_acc: 0.8679\n",
      "Epoch 2028/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2702 - acc: 0.8894 - val_loss: 0.3447 - val_acc: 0.8665\n",
      "Epoch 2029/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2672 - acc: 0.8911 - val_loss: 0.3456 - val_acc: 0.8652\n",
      "Epoch 2030/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2720 - acc: 0.8890 - val_loss: 0.3449 - val_acc: 0.8652\n",
      "Epoch 2031/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2734 - acc: 0.8887 - val_loss: 0.3452 - val_acc: 0.8652\n",
      "Epoch 2032/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2716 - acc: 0.8888 - val_loss: 0.3447 - val_acc: 0.8652\n",
      "Epoch 2033/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2684 - acc: 0.8888 - val_loss: 0.3464 - val_acc: 0.8645\n",
      "Epoch 2034/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2710 - acc: 0.8892 - val_loss: 0.3454 - val_acc: 0.8665\n",
      "Epoch 2035/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2676 - acc: 0.8935 - val_loss: 0.3449 - val_acc: 0.8665\n",
      "Epoch 2036/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2660 - acc: 0.8923 - val_loss: 0.3446 - val_acc: 0.8659\n",
      "Epoch 2037/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2676 - acc: 0.8896 - val_loss: 0.3451 - val_acc: 0.8665\n",
      "Epoch 2038/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2687 - acc: 0.8911 - val_loss: 0.3458 - val_acc: 0.8652\n",
      "Epoch 2039/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2689 - acc: 0.8897 - val_loss: 0.3447 - val_acc: 0.8659\n",
      "Epoch 2040/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2690 - acc: 0.8924 - val_loss: 0.3452 - val_acc: 0.8672\n",
      "Epoch 2041/10000\n",
      "13284/13284 [==============================] - ETA: 0s - loss: 0.2723 - acc: 0.889 - 0s 28us/sample - loss: 0.2710 - acc: 0.8896 - val_loss: 0.3450 - val_acc: 0.8672\n",
      "Epoch 2042/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2661 - acc: 0.8914 - val_loss: 0.3457 - val_acc: 0.8665\n",
      "Epoch 2043/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2692 - acc: 0.8904 - val_loss: 0.3449 - val_acc: 0.8679\n",
      "Epoch 2044/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2665 - acc: 0.8924 - val_loss: 0.3444 - val_acc: 0.8659\n",
      "Epoch 2045/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2656 - acc: 0.8908 - val_loss: 0.3445 - val_acc: 0.8665\n",
      "Epoch 2046/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2706 - acc: 0.8917 - val_loss: 0.3442 - val_acc: 0.8672\n",
      "Epoch 2047/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2681 - acc: 0.8902 - val_loss: 0.3450 - val_acc: 0.8679\n",
      "Epoch 2048/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2707 - acc: 0.8894 - val_loss: 0.3450 - val_acc: 0.8665\n",
      "Epoch 2049/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2664 - acc: 0.8928 - val_loss: 0.3452 - val_acc: 0.8672\n",
      "Epoch 2050/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2681 - acc: 0.8927 - val_loss: 0.3445 - val_acc: 0.8672\n",
      "Epoch 2051/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2699 - acc: 0.8907 - val_loss: 0.3452 - val_acc: 0.8672\n",
      "Epoch 2052/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2706 - acc: 0.8914 - val_loss: 0.3444 - val_acc: 0.8679\n",
      "Epoch 2053/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2641 - acc: 0.8945 - val_loss: 0.3449 - val_acc: 0.8672\n",
      "Epoch 2054/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2678 - acc: 0.8916 - val_loss: 0.3446 - val_acc: 0.8659\n",
      "Epoch 2055/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2703 - acc: 0.8888 - val_loss: 0.3453 - val_acc: 0.8665\n",
      "Epoch 2056/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2695 - acc: 0.8911 - val_loss: 0.3455 - val_acc: 0.8659\n",
      "Epoch 2057/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2668 - acc: 0.8917 - val_loss: 0.3460 - val_acc: 0.8645\n",
      "Epoch 2058/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2691 - acc: 0.8917 - val_loss: 0.3458 - val_acc: 0.8665\n",
      "Epoch 2059/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2706 - acc: 0.8918 - val_loss: 0.3453 - val_acc: 0.8652\n",
      "Epoch 2060/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2669 - acc: 0.8933 - val_loss: 0.3463 - val_acc: 0.8652\n",
      "Epoch 2061/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2692 - acc: 0.8906 - val_loss: 0.3460 - val_acc: 0.8686\n",
      "Epoch 2062/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2664 - acc: 0.8920 - val_loss: 0.3453 - val_acc: 0.8679\n",
      "Epoch 2063/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2668 - acc: 0.8899 - val_loss: 0.3451 - val_acc: 0.8665\n",
      "Epoch 2064/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2702 - acc: 0.8927 - val_loss: 0.3459 - val_acc: 0.8659\n",
      "Epoch 2065/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2683 - acc: 0.8900 - val_loss: 0.3461 - val_acc: 0.8665\n",
      "Epoch 2066/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2685 - acc: 0.8914 - val_loss: 0.3451 - val_acc: 0.8672\n",
      "Epoch 2067/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2688 - acc: 0.8918 - val_loss: 0.3445 - val_acc: 0.8699\n",
      "Epoch 2068/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2686 - acc: 0.8923 - val_loss: 0.3448 - val_acc: 0.8679\n",
      "Epoch 2069/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2708 - acc: 0.8887 - val_loss: 0.3454 - val_acc: 0.8652\n",
      "Epoch 2070/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2691 - acc: 0.8901 - val_loss: 0.3446 - val_acc: 0.8679\n",
      "Epoch 2071/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2681 - acc: 0.8930 - val_loss: 0.3449 - val_acc: 0.8672\n",
      "Epoch 2072/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2686 - acc: 0.8903 - val_loss: 0.3454 - val_acc: 0.8679\n",
      "Epoch 2073/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2687 - acc: 0.8924 - val_loss: 0.3466 - val_acc: 0.8665\n",
      "Epoch 2074/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2681 - acc: 0.8913 - val_loss: 0.3451 - val_acc: 0.8686\n",
      "Epoch 2075/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2697 - acc: 0.8927 - val_loss: 0.3451 - val_acc: 0.8686\n",
      "Epoch 2076/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2699 - acc: 0.8908 - val_loss: 0.3457 - val_acc: 0.8659\n",
      "Epoch 2077/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2649 - acc: 0.8939 - val_loss: 0.3463 - val_acc: 0.8665\n",
      "Epoch 2078/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2617 - acc: 0.8954 - val_loss: 0.3454 - val_acc: 0.8679\n",
      "Epoch 2079/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2687 - acc: 0.8925 - val_loss: 0.3455 - val_acc: 0.8679\n",
      "Epoch 2080/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2667 - acc: 0.8922 - val_loss: 0.3450 - val_acc: 0.8672\n",
      "Epoch 2081/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2660 - acc: 0.8925 - val_loss: 0.3445 - val_acc: 0.8686\n",
      "Epoch 2082/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2667 - acc: 0.8935 - val_loss: 0.3449 - val_acc: 0.8659\n",
      "Epoch 2083/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2677 - acc: 0.8930 - val_loss: 0.3445 - val_acc: 0.8686\n",
      "Epoch 2084/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2681 - acc: 0.8929 - val_loss: 0.3449 - val_acc: 0.8672\n",
      "Epoch 2085/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2652 - acc: 0.8952 - val_loss: 0.3451 - val_acc: 0.8672\n",
      "Epoch 2086/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2659 - acc: 0.8926 - val_loss: 0.3453 - val_acc: 0.8679\n",
      "Epoch 2087/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2730 - acc: 0.8878 - val_loss: 0.3449 - val_acc: 0.8659\n",
      "Epoch 2088/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2669 - acc: 0.8923 - val_loss: 0.3451 - val_acc: 0.8659\n",
      "Epoch 2089/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2646 - acc: 0.8937 - val_loss: 0.3448 - val_acc: 0.8679\n",
      "Epoch 2090/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2664 - acc: 0.8934 - val_loss: 0.3446 - val_acc: 0.8679\n",
      "Epoch 2091/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2689 - acc: 0.8898 - val_loss: 0.3450 - val_acc: 0.8679\n",
      "Epoch 2092/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2667 - acc: 0.8899 - val_loss: 0.3454 - val_acc: 0.8679\n",
      "Epoch 2093/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2650 - acc: 0.8927 - val_loss: 0.3454 - val_acc: 0.8679\n",
      "Epoch 2094/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2662 - acc: 0.8948 - val_loss: 0.3450 - val_acc: 0.8679\n",
      "Epoch 2095/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2645 - acc: 0.8930 - val_loss: 0.3454 - val_acc: 0.8679\n",
      "Epoch 2096/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2697 - acc: 0.8910 - val_loss: 0.3449 - val_acc: 0.8679\n",
      "Epoch 2097/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2652 - acc: 0.8942 - val_loss: 0.3452 - val_acc: 0.8679\n",
      "Epoch 2098/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2673 - acc: 0.8911 - val_loss: 0.3446 - val_acc: 0.8692\n",
      "Epoch 2099/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2699 - acc: 0.8910 - val_loss: 0.3450 - val_acc: 0.8692\n",
      "Epoch 2100/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2667 - acc: 0.8926 - val_loss: 0.3449 - val_acc: 0.8686\n",
      "Epoch 2101/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2669 - acc: 0.8925 - val_loss: 0.3441 - val_acc: 0.8699\n",
      "Epoch 2102/10000\n",
      "13284/13284 [==============================] - 0s 29us/sample - loss: 0.2679 - acc: 0.8924 - val_loss: 0.3451 - val_acc: 0.8665\n",
      "Epoch 2103/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2642 - acc: 0.8936 - val_loss: 0.3448 - val_acc: 0.8672\n",
      "Epoch 2104/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2696 - acc: 0.8934 - val_loss: 0.3448 - val_acc: 0.8679\n",
      "Epoch 2105/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2658 - acc: 0.8951 - val_loss: 0.3446 - val_acc: 0.8679\n",
      "Epoch 2106/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2660 - acc: 0.8937 - val_loss: 0.3448 - val_acc: 0.8692\n",
      "Epoch 2107/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2633 - acc: 0.8954 - val_loss: 0.3459 - val_acc: 0.8686\n",
      "Epoch 2108/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2664 - acc: 0.8914 - val_loss: 0.3452 - val_acc: 0.8672\n",
      "Epoch 2109/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2668 - acc: 0.8907 - val_loss: 0.3449 - val_acc: 0.8686\n",
      "Epoch 2110/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2683 - acc: 0.8932 - val_loss: 0.3450 - val_acc: 0.8686\n",
      "Epoch 2111/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2665 - acc: 0.8931 - val_loss: 0.3459 - val_acc: 0.8672\n",
      "Epoch 2112/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2684 - acc: 0.8887 - val_loss: 0.3459 - val_acc: 0.8679\n",
      "Epoch 2113/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2658 - acc: 0.8931 - val_loss: 0.3449 - val_acc: 0.8665\n",
      "Epoch 2114/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2655 - acc: 0.8930 - val_loss: 0.3458 - val_acc: 0.8679\n",
      "Epoch 2115/10000\n",
      "13284/13284 [==============================] - 0s 27us/sample - loss: 0.2646 - acc: 0.8948 - val_loss: 0.3454 - val_acc: 0.8652\n",
      "Epoch 2116/10000\n",
      "13284/13284 [==============================] - 0s 28us/sample - loss: 0.2651 - acc: 0.8929 - val_loss: 0.3458 - val_acc: 0.8652\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)\n",
    "history = model.fit(x=X_train, y=y_train, batch_size=32, epochs=10000, verbose=1, validation_split=0.1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640/1640 [==============================] - 0s 14us/sample - loss: 0.3246 - acc: 0.8732\n",
      "Test Score: 0.32459155982587395\n",
      "Test ACC: 0.87317073\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x=X_test, y=y_test, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test ACC:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extraction + machinelearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR214</th>\n",
       "      <th>VAR217</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13746</th>\n",
       "      <td>-0.06089</td>\n",
       "      <td>0.3584</td>\n",
       "      <td>-0.14236</td>\n",
       "      <td>0.08314</td>\n",
       "      <td>-0.00841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>-0.18202</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>-0.05455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20634</td>\n",
       "      <td>0.04837</td>\n",
       "      <td>0.13177</td>\n",
       "      <td>0.08977</td>\n",
       "      <td>0.27230</td>\n",
       "      <td>-0.04413</td>\n",
       "      <td>0.02582</td>\n",
       "      <td>0.17679</td>\n",
       "      <td>-0.24452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>-0.03367</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.33054</td>\n",
       "      <td>-0.18907</td>\n",
       "      <td>0.50606</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.31240</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.55700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22173</td>\n",
       "      <td>0.19258</td>\n",
       "      <td>-0.16388</td>\n",
       "      <td>-0.16951</td>\n",
       "      <td>-0.18113</td>\n",
       "      <td>-0.10811</td>\n",
       "      <td>-0.10341</td>\n",
       "      <td>-0.36850</td>\n",
       "      <td>0.29112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-0.03627</td>\n",
       "      <td>0.8279</td>\n",
       "      <td>0.13692</td>\n",
       "      <td>0.00587</td>\n",
       "      <td>0.47595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9115</td>\n",
       "      <td>0.17639</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.69387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02776</td>\n",
       "      <td>0.08458</td>\n",
       "      <td>-0.11550</td>\n",
       "      <td>-0.00113</td>\n",
       "      <td>-0.10418</td>\n",
       "      <td>-0.04688</td>\n",
       "      <td>-0.09820</td>\n",
       "      <td>-0.00405</td>\n",
       "      <td>0.42762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12658</th>\n",
       "      <td>0.12792</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>-0.09195</td>\n",
       "      <td>0.07691</td>\n",
       "      <td>0.02707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>-0.15978</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.18952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.09354</td>\n",
       "      <td>-0.09128</td>\n",
       "      <td>0.01816</td>\n",
       "      <td>0.06437</td>\n",
       "      <td>0.02745</td>\n",
       "      <td>0.31398</td>\n",
       "      <td>0.00316</td>\n",
       "      <td>0.15535</td>\n",
       "      <td>0.15747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>-0.03910</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.08382</td>\n",
       "      <td>-0.04888</td>\n",
       "      <td>0.20399</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2904</td>\n",
       "      <td>0.06168</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.54524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20188</td>\n",
       "      <td>0.05998</td>\n",
       "      <td>-0.10335</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>-0.08759</td>\n",
       "      <td>-0.07035</td>\n",
       "      <td>-0.04952</td>\n",
       "      <td>0.13356</td>\n",
       "      <td>0.26567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>-0.05588</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>-0.01794</td>\n",
       "      <td>0.02727</td>\n",
       "      <td>0.30702</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>-0.07124</td>\n",
       "      <td>0.7522</td>\n",
       "      <td>0.49023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00627</td>\n",
       "      <td>-0.02105</td>\n",
       "      <td>0.01838</td>\n",
       "      <td>0.04953</td>\n",
       "      <td>0.00744</td>\n",
       "      <td>-0.05669</td>\n",
       "      <td>0.00900</td>\n",
       "      <td>-0.07454</td>\n",
       "      <td>0.43960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.00779</td>\n",
       "      <td>0.8573</td>\n",
       "      <td>0.09643</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.57101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.27440</td>\n",
       "      <td>0.3652</td>\n",
       "      <td>0.54342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30241</td>\n",
       "      <td>0.22383</td>\n",
       "      <td>-0.08010</td>\n",
       "      <td>-0.14624</td>\n",
       "      <td>-0.05792</td>\n",
       "      <td>-0.06233</td>\n",
       "      <td>-0.11014</td>\n",
       "      <td>-0.38185</td>\n",
       "      <td>0.27649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>0.01185</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.19087</td>\n",
       "      <td>-0.11105</td>\n",
       "      <td>0.15742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2971</td>\n",
       "      <td>0.17121</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.45311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22073</td>\n",
       "      <td>-0.22339</td>\n",
       "      <td>-0.11848</td>\n",
       "      <td>-0.09278</td>\n",
       "      <td>-0.07028</td>\n",
       "      <td>-0.03942</td>\n",
       "      <td>-0.14239</td>\n",
       "      <td>-0.30948</td>\n",
       "      <td>0.23604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8005</th>\n",
       "      <td>0.24850</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>-0.01819</td>\n",
       "      <td>-0.09128</td>\n",
       "      <td>0.36717</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3084</td>\n",
       "      <td>0.10080</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.52156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21994</td>\n",
       "      <td>-0.08585</td>\n",
       "      <td>-0.02396</td>\n",
       "      <td>-0.08080</td>\n",
       "      <td>-0.05183</td>\n",
       "      <td>0.05814</td>\n",
       "      <td>0.54887</td>\n",
       "      <td>-0.19343</td>\n",
       "      <td>0.55406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>-0.04679</td>\n",
       "      <td>0.4967</td>\n",
       "      <td>0.36460</td>\n",
       "      <td>-0.19120</td>\n",
       "      <td>0.56688</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.28359</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.73938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05099</td>\n",
       "      <td>0.14370</td>\n",
       "      <td>-0.19827</td>\n",
       "      <td>-0.17938</td>\n",
       "      <td>-0.22846</td>\n",
       "      <td>-0.11877</td>\n",
       "      <td>-0.14230</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>0.36332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16400 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008   VAR009  \\\n",
       "13746 -0.06089  0.3584 -0.14236  0.08314 -0.00841       0  0.2965 -0.18202   \n",
       "1193  -0.03367  0.8111  0.33054 -0.18907  0.50606       0  0.4886  0.31240   \n",
       "451   -0.03627  0.8279  0.13692  0.00587  0.47595       0  0.9115  0.17639   \n",
       "12658  0.12792  0.1166 -0.09195  0.07691  0.02707       0  0.1782 -0.15978   \n",
       "2863  -0.03910  0.3933  0.08382 -0.04888  0.20399       0  0.2904  0.06168   \n",
       "...        ...     ...      ...      ...      ...     ...     ...      ...   \n",
       "6067  -0.05588  0.5902 -0.01794  0.02727  0.30702       0  0.4811 -0.07124   \n",
       "303    0.00779  0.8573  0.09643 -0.17238  0.57101       0  0.5401  0.27440   \n",
       "4734   0.01185  0.7955  0.19087 -0.11105  0.15742       0  0.2971  0.17121   \n",
       "8005   0.24850  0.9405 -0.01819 -0.09128  0.36717       1  0.3084  0.10080   \n",
       "1139  -0.04679  0.4967  0.36460 -0.19120  0.56688       0  0.7083  0.28359   \n",
       "\n",
       "       VAR010   VAR011  ...   VAR214   VAR217   VAR220   VAR221   VAR223  \\\n",
       "13746  0.9334 -0.05455  ... -0.20634  0.04837  0.13177  0.08977  0.27230   \n",
       "1193   0.1540  0.55700  ...  0.22173  0.19258 -0.16388 -0.16951 -0.18113   \n",
       "451    0.8451  0.69387  ... -0.02776  0.08458 -0.11550 -0.00113 -0.10418   \n",
       "12658  0.4563  0.18952  ... -0.09354 -0.09128  0.01816  0.06437  0.02745   \n",
       "2863   0.8853  0.54524  ... -0.20188  0.05998 -0.10335 -0.04549 -0.08759   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "6067   0.7522  0.49023  ... -0.00627 -0.02105  0.01838  0.04953  0.00744   \n",
       "303    0.3652  0.54342  ...  0.30241  0.22383 -0.08010 -0.14624 -0.05792   \n",
       "4734   0.7251  0.45311  ...  0.22073 -0.22339 -0.11848 -0.09278 -0.07028   \n",
       "8005   0.0370  0.52156  ...  0.21994 -0.08585 -0.02396 -0.08080 -0.05183   \n",
       "1139   0.0091  0.73938  ...  0.05099  0.14370 -0.19827 -0.17938 -0.22846   \n",
       "\n",
       "        VAR224   VAR225   VAR226   VAR227  MRC_ID_DI  \n",
       "13746 -0.04413  0.02582  0.17679 -0.24452          1  \n",
       "1193  -0.10811 -0.10341 -0.36850  0.29112          0  \n",
       "451   -0.04688 -0.09820 -0.00405  0.42762          0  \n",
       "12658  0.31398  0.00316  0.15535  0.15747          1  \n",
       "2863  -0.07035 -0.04952  0.13356  0.26567          0  \n",
       "...        ...      ...      ...      ...        ...  \n",
       "6067  -0.05669  0.00900 -0.07454  0.43960          0  \n",
       "303   -0.06233 -0.11014 -0.38185  0.27649          0  \n",
       "4734  -0.03942 -0.14239 -0.30948  0.23604          0  \n",
       "8005   0.05814  0.54887 -0.19343  0.55406          0  \n",
       "1139  -0.11877 -0.14230 -0.19967  0.36332          0  \n",
       "\n",
       "[16400 rows x 189 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16400, 188) (16400,)\n"
     ]
    }
   ],
   "source": [
    "X=df2.loc[:,'VAR002':'VAR227']\n",
    "y=df2.loc[:,'MRC_ID_DI']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9840, 188) (3280, 188) (3280, 188)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 나누기 - 6:2:2 비율\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "accuracy of poly: 0.8371951219512195\n",
      "==========================================\n",
      "accuracy of rbf: 0.8289634146341464\n",
      "==========================================\n",
      "accuracy of sigmoid: 0.6597560975609756\n"
     ]
    }
   ],
   "source": [
    "# 여러 가지 kernel을 사용해 SVM 학습하고 accuracy 계산하기\n",
    "kernels = ['poly','rbf','sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(\"==========================================\") \n",
    "    model = SVC(kernel = kernel)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred_val = model.predict(x_val)\n",
    "    print(f\"accuracy of {kernel}: {accuracy_score(y_val, pred_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9240853658536585\n"
     ]
    }
   ],
   "source": [
    "# 여러 가지 kernel을 사용해 SVM 학습하고 accuracy 계산하기\n",
    "model = SVC(kernel = 'poly', C=10000, gamma=0.01) # 파라이터값 그리드서치한 결과임 \n",
    "model.fit(x_train, y_train)\n",
    "new_pred_test = model.predict(x_test)\n",
    "print(f'accuracy: {accuracy_score(y_test, new_pred_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores :[0.92378049 0.91463415 0.94359756 0.93216463 0.94054878 0.91615854\n",
      " 0.91692073 0.92378049 0.9214939  0.92378049]\n",
      "cross validation mean scores :0.93\n"
     ]
    }
   ],
   "source": [
    "# kfold 반복자 StratifiedKFold(동일한 분포아닌경우)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf=StratifiedKFold(n_splits=10,shuffle =True,random_state=0)\n",
    "\n",
    "\n",
    "scores = cross_val_score(model,x_train,y_train,cv=skf)\n",
    "print('cross validation scores :{}'.format(scores))\n",
    "print('cross validation mean scores :{:.2f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores :[0.9222561  0.91920732 0.91539634 0.92378049 0.92987805 0.9222561\n",
      " 0.91844512 0.92301829 0.92835366 0.93597561]\n",
      "cross validation mean scores :0.92\n"
     ]
    }
   ],
   "source": [
    "#kfold 반복자 kfold(동일한 분포 가진경우 )\n",
    "from sklearn.model_selection import KFold\n",
    "k=KFold(n_splits=10,shuffle =True,random_state=0)\n",
    "scores = cross_val_score(model,x_train,y_train,cv=k)\n",
    "print('cross validation scores :{}'.format(scores))\n",
    "print('cross validation mean scores :{:.2f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9411585365853659\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier를 사용해 분류기 학습 및 정확도 계산하기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, random_state=1)\n",
    "rf_clf.fit(x_train, y_train)\n",
    "pred_test_rf = rf_clf.predict(x_test)\n",
    "print(f'accuracy: {accuracy_score(y_test, pred_test_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores :[0.93445122 0.93521341 0.93140244 0.94054878 0.93445122 0.93597561\n",
      " 0.93902439 0.9382622  0.94512195 0.93597561]\n",
      "cross validation mean scores :0.94\n"
     ]
    }
   ],
   "source": [
    "#kfold 반복자 kfold(동일한 분포 가진경우 )\n",
    "from sklearn.model_selection import KFold\n",
    "k=KFold(n_splits=10,shuffle =True,random_state=0)\n",
    "scores = cross_val_score(rf_clf,x_train,y_train,cv=k) # train이 맞을까 ? \n",
    "print('cross validation scores :{}'.format(scores))\n",
    "print('cross validation mean scores :{:.2f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [None, 10],\n",
       "                         'max_features': ['auto', 0.2, 0.5],\n",
       "                         'max_samples': [1000], 'min_samples_leaf': [1, 5],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV를 이용해 최적의 조합을 찾고 그 때의 정확도 계산하기\n",
    "n_estimators = [100, 200, 300]\n",
    "max_featrues = ['auto', 0.2, 0.5]\n",
    "min_samples_leaf = [1, 5]\n",
    "max_depth = [None, 10]\n",
    "max_samples = [1000]\n",
    "\n",
    "param_grid = {'n_estimators' : n_estimators, 'max_features': max_featrues, \n",
    "              'min_samples_leaf': min_samples_leaf, 'max_depth': max_depth, \n",
    "              'max_samples': max_samples}\n",
    "\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=4, scoring='accuracy')\n",
    "\n",
    "rf_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': 0.5, 'max_samples': 1000, 'min_samples_leaf': 1, 'n_estimators': 300}\n",
      "accuracy: 0.8210365853658537\n"
     ]
    }
   ],
   "source": [
    "print(rf_grid.best_params_)\n",
    "pred_test_rf_grid = rf_grid.predict(x_test)\n",
    "print(f'accuracy: {accuracy_score(y_test, pred_test_rf_grid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mKeyboardInterrupt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#kfold 반복자 kfold(동일한 분포 가진경우 )\n",
    "from sklearn.model_selection import KFold\n",
    "k=KFold(n_splits=10,shuffle =True,random_state=0)\n",
    "scores = cross_val_score(rf_grid,x_train,y_train,cv=k)\n",
    "print('cross validation scores :{}'.format(scores))\n",
    "print('cross validation mean scores :{:.2f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
