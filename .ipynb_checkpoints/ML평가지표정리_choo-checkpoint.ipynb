{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_name = os.path.join(os.getcwd(), 'DATASET', 'samp_cst_feat.csv')\n",
    "df_x = pd.read_csv(x_name)\n",
    "\n",
    "y_name = os.path.join(os.getcwd(), 'DATASET', 'samp_train.csv')\n",
    "df_y = pd.read_csv(y_name)\n",
    "\n",
    "df = pd.merge(df_x, df_y, on='cst_id_di')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cst_id_di</th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90000000089</td>\n",
       "      <td>-0.06610</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>-0.13607</td>\n",
       "      <td>0.10945</td>\n",
       "      <td>0.06557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>-0.18965</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19113</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>0.09471</td>\n",
       "      <td>0.27091</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0.02938</td>\n",
       "      <td>0.17105</td>\n",
       "      <td>0.12537</td>\n",
       "      <td>0.22197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000000176</td>\n",
       "      <td>-0.09537</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>-0.13541</td>\n",
       "      <td>0.17331</td>\n",
       "      <td>-0.19657</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>-0.23104</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19437</td>\n",
       "      <td>0.06538</td>\n",
       "      <td>0.16309</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>-0.01107</td>\n",
       "      <td>0.12413</td>\n",
       "      <td>0.29702</td>\n",
       "      <td>-0.31717</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000000210</td>\n",
       "      <td>-0.01048</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.37797</td>\n",
       "      <td>-0.10970</td>\n",
       "      <td>0.52032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.32632</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.52084</td>\n",
       "      <td>-0.18568</td>\n",
       "      <td>-0.09755</td>\n",
       "      <td>-0.56565</td>\n",
       "      <td>-0.17840</td>\n",
       "      <td>-0.06314</td>\n",
       "      <td>-0.17111</td>\n",
       "      <td>-0.32239</td>\n",
       "      <td>0.33962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000000212</td>\n",
       "      <td>0.05194</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.04611</td>\n",
       "      <td>-0.16512</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.26845</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01934</td>\n",
       "      <td>-0.05172</td>\n",
       "      <td>-0.13245</td>\n",
       "      <td>-0.16357</td>\n",
       "      <td>-0.05697</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>-0.04022</td>\n",
       "      <td>0.31213</td>\n",
       "      <td>-0.00559</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90000000213</td>\n",
       "      <td>-0.08536</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>-0.12288</td>\n",
       "      <td>0.10023</td>\n",
       "      <td>-0.43414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>-0.25575</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23122</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.09206</td>\n",
       "      <td>0.46971</td>\n",
       "      <td>0.07964</td>\n",
       "      <td>-0.04698</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.22588</td>\n",
       "      <td>-0.34868</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10119</th>\n",
       "      <td>90000460112</td>\n",
       "      <td>-0.06606</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>-0.09743</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.10111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>-0.02041</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33881</td>\n",
       "      <td>-0.01692</td>\n",
       "      <td>-0.01823</td>\n",
       "      <td>0.21720</td>\n",
       "      <td>-0.08346</td>\n",
       "      <td>-0.07835</td>\n",
       "      <td>0.02321</td>\n",
       "      <td>0.32967</td>\n",
       "      <td>-0.25995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>90000460117</td>\n",
       "      <td>-0.03031</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.07041</td>\n",
       "      <td>-0.02519</td>\n",
       "      <td>0.58013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.06676</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19384</td>\n",
       "      <td>-0.02383</td>\n",
       "      <td>-0.02448</td>\n",
       "      <td>-0.05019</td>\n",
       "      <td>-0.02869</td>\n",
       "      <td>-0.05401</td>\n",
       "      <td>0.01670</td>\n",
       "      <td>-0.15880</td>\n",
       "      <td>0.48301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>90000460233</td>\n",
       "      <td>-0.05351</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.36925</td>\n",
       "      <td>-0.10039</td>\n",
       "      <td>0.51159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.35016</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.45312</td>\n",
       "      <td>-0.17163</td>\n",
       "      <td>-0.08674</td>\n",
       "      <td>-0.40260</td>\n",
       "      <td>-0.15903</td>\n",
       "      <td>-0.10292</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.31895</td>\n",
       "      <td>0.40357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>90000460310</td>\n",
       "      <td>-0.00562</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.04581</td>\n",
       "      <td>-0.05390</td>\n",
       "      <td>0.20481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.11319</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01754</td>\n",
       "      <td>-0.01479</td>\n",
       "      <td>-0.03898</td>\n",
       "      <td>-0.01363</td>\n",
       "      <td>0.06974</td>\n",
       "      <td>-0.03815</td>\n",
       "      <td>-0.04371</td>\n",
       "      <td>0.11433</td>\n",
       "      <td>-0.01931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>90000460313</td>\n",
       "      <td>-0.06814</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>-0.04318</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>-0.08842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>-0.02036</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08257</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.08881</td>\n",
       "      <td>0.01272</td>\n",
       "      <td>-0.01391</td>\n",
       "      <td>-0.05940</td>\n",
       "      <td>0.44214</td>\n",
       "      <td>0.22888</td>\n",
       "      <td>-0.09918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10124 rows × 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cst_id_di   VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  \\\n",
       "0      90000000089 -0.06610  0.5280 -0.13607  0.10945  0.06557       0   \n",
       "1      90000000176 -0.09537  0.1347 -0.13541  0.17331 -0.19657       0   \n",
       "2      90000000210 -0.01048  0.8360  0.37797 -0.10970  0.52032       1   \n",
       "3      90000000212  0.05194  0.7505  0.04611 -0.16512  0.07413       0   \n",
       "4      90000000213 -0.08536  0.3767 -0.12288  0.10023 -0.43414       0   \n",
       "...            ...      ...     ...      ...      ...      ...     ...   \n",
       "10119  90000460112 -0.06606  0.6615 -0.09743 -0.03240  0.10111       0   \n",
       "10120  90000460117 -0.03031  0.0143  0.07041 -0.02519  0.58013       0   \n",
       "10121  90000460233 -0.05351  0.3121  0.36925 -0.10039  0.51159       0   \n",
       "10122  90000460310 -0.00562  0.2286  0.04581 -0.05390  0.20481       0   \n",
       "10123  90000460313 -0.06814  0.6968 -0.04318  0.11340 -0.08842       0   \n",
       "\n",
       "       VAR008   VAR009  VAR010  ...   VAR219   VAR220   VAR221   VAR222  \\\n",
       "0      0.7702 -0.18965  0.1981  ...  0.19113  0.05449  0.09471  0.27091   \n",
       "1      0.0616 -0.23104  0.4940  ...  0.19437  0.06538  0.16309  0.30207   \n",
       "2      0.3257  0.32632  0.7343  ... -0.52084 -0.18568 -0.09755 -0.56565   \n",
       "3      0.5322  0.26845  0.7327  ... -0.01934 -0.05172 -0.13245 -0.16357   \n",
       "4      0.5468 -0.25575  0.9644  ...  0.23122  0.07913  0.09206  0.46971   \n",
       "...       ...      ...     ...  ...      ...      ...      ...      ...   \n",
       "10119  0.9722 -0.02041  0.6966  ...  0.33881 -0.01692 -0.01823  0.21720   \n",
       "10120  0.0330  0.06676  0.8251  ... -0.19384 -0.02383 -0.02448 -0.05019   \n",
       "10121  0.2582  0.35016  0.4638  ... -0.45312 -0.17163 -0.08674 -0.40260   \n",
       "10122  0.5957  0.11319  0.2527  ...  0.01754 -0.01479 -0.03898 -0.01363   \n",
       "10123  0.1151 -0.02036  0.8465  ...  0.08257  0.00120  0.08881  0.01272   \n",
       "\n",
       "        VAR223   VAR224   VAR225   VAR226   VAR227  MRC_ID_DI  \n",
       "0      0.01931  0.02938  0.17105  0.12537  0.22197          0  \n",
       "1      0.06053 -0.01107  0.12413  0.29702 -0.31717          8  \n",
       "2     -0.17840 -0.06314 -0.17111 -0.32239  0.33962          0  \n",
       "3     -0.05697  0.01587 -0.04022  0.31213 -0.00559          5  \n",
       "4      0.07964 -0.04698  0.03581  0.22588 -0.34868          6  \n",
       "...        ...      ...      ...      ...      ...        ...  \n",
       "10119 -0.08346 -0.07835  0.02321  0.32967 -0.25995          7  \n",
       "10120 -0.02869 -0.05401  0.01670 -0.15880  0.48301          0  \n",
       "10121 -0.15903 -0.10292 -0.11742 -0.31895  0.40357          0  \n",
       "10122  0.06974 -0.03815 -0.04371  0.11433 -0.01931          0  \n",
       "10123 -0.01391 -0.05940  0.44214  0.22888 -0.09918          0  \n",
       "\n",
       "[10124 rows x 228 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IDPL\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.MRC_ID_DI[df.MRC_ID_DI > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['MRC_ID_DI'], axis=1)\n",
    "y = df['MRC_ID_DI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 정확도 : 0.7728\n",
      "RandomForest 정확도 : 0.8267\n",
      "LogisticRegression 정확도 : 0.8099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "#DTC 학습 예측 평가\n",
    "\n",
    "dt_clf.fit(X_train,y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print('DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy_score(y_test,dt_pred)))\n",
    "\n",
    "#RandomForest 학습 예측 평가\n",
    "\n",
    "rf_clf.fit(X_train,y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('RandomForest 정확도 : {0:.4f}'.format(accuracy_score(y_test,rf_pred)))\n",
    "\n",
    "#LogisticRegression 학습 예측 평가\n",
    "\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lf_pred = lr_clf.predict(X_test)\n",
    "print('LogisticRegression 정확도 : {0:.4f}'.format(accuracy_score(y_test,lf_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeCliassifeir KFold\n",
      "교차검증 0 정확도 : 0.7679\n",
      "교차검증 1 정확도 : 0.7635\n",
      "교차검증 2 정확도 : 0.7812\n",
      "교차검증 3 정확도 : 0.7649\n",
      "교차검증 4 정확도 : 0.7831\n",
      "평균 정확도 : 0.7721\n",
      "RandomForest KFold\n",
      "교차검증 0 정확도 : 0.8449\n",
      "교차검증 1 정확도 : 0.8365\n",
      "교차검증 2 정확도 : 0.8286\n",
      "교차검증 3 정확도 : 0.8247\n",
      "교차검증 4 정확도 : 0.8419\n",
      "평균 정확도 : 0.8353\n",
      "Logistic Regression KFold\n",
      "교차검증 0 정확도 : 0.8198\n",
      "교차검증 1 정확도 : 0.8069\n",
      "교차검증 2 정확도 : 0.8089\n",
      "교차검증 3 정확도 : 0.7936\n",
      "교차검증 4 정확도 : 0.8207\n",
      "평균 정확도 : 0.8100\n"
     ]
    }
   ],
   "source": [
    "#교차검증으로 결정트리모델을 평가한다.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf,folds=5):\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores =[]\n",
    "    \n",
    "    for iter_count,(train_index,test_index) in enumerate(kfold.split(X)):\n",
    "        X_train,X_test = X.values[train_index],X.values[test_index]\n",
    "        y_train,y_test = y.values[train_index],y.values[test_index]\n",
    "        \n",
    "        clf.fit(X_train,y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test,predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차검증 {0} 정확도 : {1:.4f}\".format(iter_count,accuracy))\n",
    "    \n",
    "    mean_score=np.mean(scores)\n",
    "    print(\"평균 정확도 : {0:.4f}\".format(mean_score))\n",
    "print('DecisionTreeCliassifeir KFold')\n",
    "exec_kfold(dt_clf,folds=5)\n",
    "print('RandomForest KFold')\n",
    "exec_kfold(rf_clf,folds=5)\n",
    "print('Logistic Regression KFold')\n",
    "exec_kfold(lr_clf,folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[1583   56]\n",
      " [ 287   99]]\n",
      "정확도 : 0.8306,정밀도 :0.6387, 재현율 :0.2565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'정밀도 재현율을 positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가지표\\n재현율이 중요지표인 경우는 실제 positive 양성 데이터를 negative 로 잘못판단하면 업무상 큰 영향이 발생\\n하는 경우 '"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오차 행렬\n",
    "# 성능 지표로 잘 활용되는데, 학습된 분류모델이 예측을 수행하면서 얼마나 헷갈리고 있는지 함께 보여주는 지표\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,precision_score,recall_score\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "def get_clf_eval(y_test,pred):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    #ROC_AUC print 추가\n",
    "    print('정확도 : {0:.4f},정밀도 :{1:.4f}, 재현율 :{2:.4f}'.format(accuracy,precision,recall))\n",
    "\n",
    "rf_clf.fit(X_train,y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "get_clf_eval(y_test,rf_pred)\n",
    "\n",
    "\"\"\" [0][0] : TN, 예측값을 negative 값 0으로 예측했고, 실제 값 역시 0\n",
    "    [0][1] : FP, 예측값을 positive 값 1로 예측했는데, 실제 값은 0\n",
    "    [1][0] : FN, 예측값을 negative 값 0으로 예측했는데, 실제 값은 positive 1\n",
    "    [1][1] : TP, 예측값을 positive 값 1 로 예측했는데, 실제 값 역시 1\n",
    "\"\"\"\n",
    "\"\"\"정확도는 예측값과 실제 값이 얼마나 동일한가에 대한 비율만으로 결정된다.\n",
    "즉, 오차 행렬에서 True 에 해당하는 값이 TN, TP에 좌우된다는 것\n",
    "불균형한 이진 분류 데이터 세트에서는 positive 데이터 건수가 작아지기 때문에 데이터에 기반한 ML 알고리즘은 \n",
    "positive 보다는 negetive로 에측 정확도가 높아지는 경향이 발생한다. \n",
    "결과적으로 정확도 지표는 비대칭한 데이터 세트에서 positive 에 대한 예측 정확도를 판단하지 못한채 negative에 \n",
    "대한 예측 정확도 만으로 분류의 정확도가 매우 높게 나타나는 수치적인 판단 오류가 발생\"\"\"\n",
    "\n",
    "\"\"\"정밀도 재현율을 positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가지표\n",
    "재현율이 중요지표인 경우는 실제 positive 양성 데이터를 negative 로 잘못판단하면 업무상 큰 영향이 발생\n",
    "하는 경우 \"\"\"\n",
    "\n",
    "# 가장 좋은 성능 평가는 재현율과 정밀도 모두 높은 수치를 얻는 것,,ㅅㅂ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba() 의 결과 shape :(2025, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ":  [[0.97 0.03]\n",
      " [0.96 0.04]\n",
      " [1.   0.  ]]\n",
      "두 개의 class 중에서 더 큰 확률로 클래스 값으로 예측\n",
      " [[0.97 0.03 0.  ]\n",
      " [0.96 0.04 0.  ]\n",
      " [1.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = rf_clf.predict_proba(X_test)\n",
    "pred = rf_clf.predict(X_test)\n",
    "print('pred_proba() 의 결과 shape :{0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n: ',pred_proba[:3])\n",
    "\n",
    "pred_proba_result = np.concatenate([pred_proba,pred.reshape(-1,1)],axis=1)\n",
    "print('두 개의 class 중에서 더 큰 확률로 클래스 값으로 예측\\n',pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[1489  150]\n",
      " [ 195  191]]\n",
      "정확도 : 0.8296,정밀도 :0.5601, 재현율 :0.4948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "custom_threshold=0.4 # 0.4로 하면 positive 예측을 더 너그럽게 하기 때문에 임계값을 낮출수록 true 값 증가\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict=binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test,custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
