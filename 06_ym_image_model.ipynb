{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "seed_value= 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython = get_ipython()\n",
    "\n",
    "def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,\n",
    "                      exception_only=False, running_compiled_code=False):\n",
    "       etype, value, tb = sys.exc_info()\n",
    "       return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
    "\n",
    "ipython.showtraceback = hide_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "master_path = os.path.join(os.getcwd(), '데이터SET', f\"{'[Track1_데이터2] samp_train'}.csv\")\n",
    "master = pd.read_csv(master_path)\n",
    "master.MRC_ID_DI[master.MRC_ID_DI > 0 ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img_path = os.path.join(os.getcwd(), 'image4')\n",
    "\n",
    "y = []\n",
    "X = []\n",
    "\n",
    "for i in range(len(master)):\n",
    "    path = os.path.join(img_path, str(master.iloc[i, 0]) +'.png')\n",
    "    label = master.iloc[i, 1]\n",
    "    X.append(path)\n",
    "    y.append(label)\n",
    "        \n",
    "X = np.array(X)       \n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['X_test'] = X_test\n",
    "test['y_test'] = y_test\n",
    "\n",
    "train = pd.DataFrame()\n",
    "train['X_train'] = X_train\n",
    "train['y_train'] = y_train\n",
    "\n",
    "train_0 = train[train['y_train'] == 0].sample(frac=1)\n",
    "train_1 = train[train['y_train'] == 1].sample(frac=1)\n",
    "\n",
    "sample_size = len(train_0) if len(train_0) < len(train_1) else len(train_1)\n",
    "\n",
    "train_f = pd.concat([train_0.head(sample_size), train_1.head(sample_size)]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "y_train = []\n",
    "X_train = []\n",
    "\n",
    "for i in range(len(train_f)):\n",
    "    label = train_f.iloc[i, 1]\n",
    "    img = Image.open(train_f.iloc[i, 0])\n",
    "    data = np.asarray(img)\n",
    "    X_train.append(data)\n",
    "    y_train.append(label)\n",
    "        \n",
    "X_train = np.array(X_train)       \n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1, stratify = y_train)\n",
    "\n",
    "y_test = []\n",
    "X_test = []\n",
    "\n",
    "for i in range(len(test)):\n",
    "    label = test.iloc[i, 1]\n",
    "    img = Image.open(test.iloc[i, 0])\n",
    "    data = np.asarray(img)\n",
    "    X_test.append(data)\n",
    "    y_test.append(label)\n",
    "        \n",
    "X_test = np.array(X_test)       \n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "y_val = tf.keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_channel = 331, 331, 3\n",
    "\n",
    "base_model = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 331, 331, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 165, 165, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 165, 165, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 165, 165, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 163, 163, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 163, 163, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 163, 163, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 163, 163, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 163, 163, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 163, 163, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 163, 163, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 163, 163, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 82, 82, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 82, 82, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 82, 82, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 82, 82, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 82, 82, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 82, 82, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 82, 82, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 82, 82, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 82, 82, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 82, 82, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 41, 41, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 41, 41, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 41, 41, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 41, 41, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 41, 41, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 41, 41, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 41, 41, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 41, 41, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 41, 41, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 41, 41, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 21, 21, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 21, 21, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 21, 21, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 21, 21, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 21, 21, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 21, 21, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 21, 21, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 21, 21, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 21, 21, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 21, 21, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 21, 21, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 21, 21, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 21, 21, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 21, 21, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 21, 21, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 21, 21, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 21, 21, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 21, 21, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 21, 21, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 21, 21, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 21, 21, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 21, 21, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 21, 21, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 21, 21, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 21, 21, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 21, 21, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 21, 21, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 21, 21, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 21, 21, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 21, 21, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 21, 21, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 21, 21, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 21, 21, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 21, 21, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 21, 21, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 21, 21, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 21, 21, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 21, 21, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 21, 21, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 21, 21, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 21, 21, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 21, 21, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 21, 21, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 21, 21, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 21, 21, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 21, 21, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 21, 21, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 21, 21, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 21, 21, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 21, 21, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 21, 21, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 21, 21, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 21, 21, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 21, 21, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 21, 21, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 21, 21, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 21, 21, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 21, 21, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 21, 21, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 21, 21, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 21, 21, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 21, 21, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 21, 21, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 21, 21, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 21, 21, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 21, 21, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 21, 21, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 21, 21, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 21, 21, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 21, 21, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 21, 21, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 21, 21, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 21, 21, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 21, 21, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 21, 21, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 21, 21, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 21, 21, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 21, 21, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 21, 21, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 21, 21, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 21, 21, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 21, 21, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 21, 21, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 21, 21, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 21, 21, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 21, 21, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 21, 21, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 21, 21, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 21, 21, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 21, 21, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 11, 11, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 11, 11, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 11, 11, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 11, 11, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 11, 11, 1536) 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 11, 11, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 11, 11, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 11, 11, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 11, 11, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 11, 11, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 2)            495618      block14_sepconv2_act[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 21,357,098\n",
      "Trainable params: 21,302,570\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "add_model = tf.keras.Sequential()\n",
    "add_model.add(tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:]))\n",
    "add_model.add(tf.keras.layers.Dropout(rate = 0.8))\n",
    "#add_model.add(tf.keras.layers.Dropout(rate = 0.8))\n",
    "\n",
    "#add_model.add(tf.keras.layers.Dropout(rate = 0.8))\n",
    "#add_model.add(tf.keras.layers.Dense(units=8, activation=tf.nn.relu))\n",
    "add_model.add(tf.keras.layers.Dense(units=2, activation=tf.nn.softmax))\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.00000001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-31b79369e6ad>:28: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1557 steps, validate for 174 steps\n",
      "Epoch 1/2000\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "1557/1557 [==============================] - 182s 117ms/step - loss: 0.9438 - accuracy: 0.5217 - val_loss: 0.7450 - val_accuracy: 0.5303\n",
      "Epoch 2/2000\n",
      "1557/1557 [==============================] - 176s 113ms/step - loss: 0.9410 - accuracy: 0.5014 - val_loss: 0.7374 - val_accuracy: 0.5130\n",
      "Epoch 3/2000\n",
      "1557/1557 [==============================] - 177s 114ms/step - loss: 0.9406 - accuracy: 0.5069 - val_loss: 0.7354 - val_accuracy: 0.5043\n",
      "Epoch 4/2000\n",
      "1557/1557 [==============================] - 177s 114ms/step - loss: 0.9268 - accuracy: 0.5230 - val_loss: 0.7335 - val_accuracy: 0.5274\n",
      "Epoch 5/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.9212 - accuracy: 0.5307 - val_loss: 0.7337 - val_accuracy: 0.5159\n",
      "Epoch 6/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.9193 - accuracy: 0.5172 - val_loss: 0.7235 - val_accuracy: 0.5303\n",
      "Epoch 7/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.9333 - accuracy: 0.5210 - val_loss: 0.7205 - val_accuracy: 0.5360\n",
      "Epoch 8/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.9063 - accuracy: 0.5355 - val_loss: 0.7155 - val_accuracy: 0.5360\n",
      "Epoch 9/2000\n",
      "1557/1557 [==============================] - 177s 114ms/step - loss: 0.8866 - accuracy: 0.5255 - val_loss: 0.7161 - val_accuracy: 0.5562\n",
      "Epoch 10/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8864 - accuracy: 0.5326 - val_loss: 0.7134 - val_accuracy: 0.5418\n",
      "Epoch 11/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8976 - accuracy: 0.5390 - val_loss: 0.7238 - val_accuracy: 0.5504\n",
      "Epoch 12/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8647 - accuracy: 0.5435 - val_loss: 0.7086 - val_accuracy: 0.5648\n",
      "Epoch 13/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.9006 - accuracy: 0.5394 - val_loss: 0.7032 - val_accuracy: 0.5591\n",
      "Epoch 14/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8933 - accuracy: 0.5291 - val_loss: 0.7046 - val_accuracy: 0.5677\n",
      "Epoch 15/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8767 - accuracy: 0.5397 - val_loss: 0.7018 - val_accuracy: 0.5562\n",
      "Epoch 16/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8593 - accuracy: 0.5442 - val_loss: 0.7064 - val_accuracy: 0.5591\n",
      "Epoch 17/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8791 - accuracy: 0.5281 - val_loss: 0.6971 - val_accuracy: 0.5648\n",
      "Epoch 18/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8797 - accuracy: 0.5352 - val_loss: 0.6996 - val_accuracy: 0.5620\n",
      "Epoch 19/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8580 - accuracy: 0.5561 - val_loss: 0.6962 - val_accuracy: 0.5793\n",
      "Epoch 20/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8659 - accuracy: 0.5384 - val_loss: 0.6930 - val_accuracy: 0.5793\n",
      "Epoch 21/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8613 - accuracy: 0.5528 - val_loss: 0.6913 - val_accuracy: 0.5735\n",
      "Epoch 22/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8717 - accuracy: 0.5461 - val_loss: 0.6876 - val_accuracy: 0.5908\n",
      "Epoch 23/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.8485 - accuracy: 0.5532 - val_loss: 0.6848 - val_accuracy: 0.5764\n",
      "Epoch 24/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8434 - accuracy: 0.5596 - val_loss: 0.6902 - val_accuracy: 0.5793\n",
      "Epoch 25/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8323 - accuracy: 0.5641 - val_loss: 0.6826 - val_accuracy: 0.5850\n",
      "Epoch 26/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8387 - accuracy: 0.5564 - val_loss: 0.6763 - val_accuracy: 0.5908\n",
      "Epoch 27/2000\n",
      "1557/1557 [==============================] - 178s 115ms/step - loss: 0.8271 - accuracy: 0.5644 - val_loss: 0.6841 - val_accuracy: 0.6110\n",
      "Epoch 28/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8137 - accuracy: 0.5827 - val_loss: 0.6748 - val_accuracy: 0.5994\n",
      "Epoch 29/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8538 - accuracy: 0.5525 - val_loss: 0.6810 - val_accuracy: 0.5994\n",
      "Epoch 30/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8295 - accuracy: 0.5702 - val_loss: 0.6719 - val_accuracy: 0.5850\n",
      "Epoch 31/2000\n",
      "1557/1557 [==============================] - 178s 115ms/step - loss: 0.8350 - accuracy: 0.5760 - val_loss: 0.6697 - val_accuracy: 0.5965\n",
      "Epoch 32/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8272 - accuracy: 0.5577 - val_loss: 0.6666 - val_accuracy: 0.6110\n",
      "Epoch 33/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8266 - accuracy: 0.5740 - val_loss: 0.6721 - val_accuracy: 0.6052\n",
      "Epoch 34/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8257 - accuracy: 0.5740 - val_loss: 0.6822 - val_accuracy: 0.6110\n",
      "Epoch 35/2000\n",
      "1557/1557 [==============================] - 180s 116ms/step - loss: 0.8340 - accuracy: 0.5747 - val_loss: 0.6633 - val_accuracy: 0.5965\n",
      "Epoch 36/2000\n",
      "1557/1557 [==============================] - 178s 115ms/step - loss: 0.8206 - accuracy: 0.5814 - val_loss: 0.6642 - val_accuracy: 0.6023\n",
      "Epoch 37/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.8043 - accuracy: 0.5872 - val_loss: 0.6559 - val_accuracy: 0.6196\n",
      "Epoch 38/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.8160 - accuracy: 0.5785 - val_loss: 0.6692 - val_accuracy: 0.6167\n",
      "Epoch 39/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.8352 - accuracy: 0.5737 - val_loss: 0.6601 - val_accuracy: 0.6052\n",
      "Epoch 40/2000\n",
      "1557/1557 [==============================] - 178s 115ms/step - loss: 0.8362 - accuracy: 0.5785 - val_loss: 0.6551 - val_accuracy: 0.6167\n",
      "Epoch 41/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.8156 - accuracy: 0.5721 - val_loss: 0.6610 - val_accuracy: 0.6254\n",
      "Epoch 42/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.7828 - accuracy: 0.6007 - val_loss: 0.6545 - val_accuracy: 0.6311\n",
      "Epoch 43/2000\n",
      "1557/1557 [==============================] - 178s 115ms/step - loss: 0.8059 - accuracy: 0.5907 - val_loss: 0.6488 - val_accuracy: 0.6369\n",
      "Epoch 44/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.8014 - accuracy: 0.5911 - val_loss: 0.6672 - val_accuracy: 0.6340\n",
      "Epoch 45/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.7877 - accuracy: 0.5975 - val_loss: 0.6473 - val_accuracy: 0.6254\n",
      "Epoch 46/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.7894 - accuracy: 0.6023 - val_loss: 0.6491 - val_accuracy: 0.6369\n",
      "Epoch 47/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.7908 - accuracy: 0.5949 - val_loss: 0.6475 - val_accuracy: 0.6225\n",
      "Epoch 48/2000\n",
      "1557/1557 [==============================] - 178s 115ms/step - loss: 0.7889 - accuracy: 0.5978 - val_loss: 0.6426 - val_accuracy: 0.6196\n",
      "Epoch 49/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.7720 - accuracy: 0.6081 - val_loss: 0.6462 - val_accuracy: 0.6340\n",
      "Epoch 50/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1557/1557 [==============================] - 178s 115ms/step - loss: 0.7716 - accuracy: 0.5911 - val_loss: 0.6491 - val_accuracy: 0.6311\n",
      "Epoch 51/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7894 - accuracy: 0.5940 - val_loss: 0.6506 - val_accuracy: 0.6513\n",
      "Epoch 52/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.8035 - accuracy: 0.5907 - val_loss: 0.6501 - val_accuracy: 0.6484\n",
      "Epoch 53/2000\n",
      "1557/1557 [==============================] - 178s 115ms/step - loss: 0.7777 - accuracy: 0.6094 - val_loss: 0.6457 - val_accuracy: 0.6311\n",
      "Epoch 54/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7729 - accuracy: 0.6091 - val_loss: 0.6345 - val_accuracy: 0.6484\n",
      "Epoch 55/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7830 - accuracy: 0.5981 - val_loss: 0.6341 - val_accuracy: 0.6484\n",
      "Epoch 56/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7716 - accuracy: 0.6081 - val_loss: 0.6361 - val_accuracy: 0.6513\n",
      "Epoch 57/2000\n",
      "1557/1557 [==============================] - 178s 115ms/step - loss: 0.7743 - accuracy: 0.5978 - val_loss: 0.6395 - val_accuracy: 0.6369\n",
      "Epoch 58/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7689 - accuracy: 0.6148 - val_loss: 0.6384 - val_accuracy: 0.6427\n",
      "Epoch 59/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7876 - accuracy: 0.6075 - val_loss: 0.6313 - val_accuracy: 0.6455\n",
      "Epoch 60/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7782 - accuracy: 0.6039 - val_loss: 0.6402 - val_accuracy: 0.6686\n",
      "Epoch 61/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7602 - accuracy: 0.6123 - val_loss: 0.6309 - val_accuracy: 0.6484\n",
      "Epoch 62/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7604 - accuracy: 0.6190 - val_loss: 0.6340 - val_accuracy: 0.6571\n",
      "Epoch 63/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7577 - accuracy: 0.6209 - val_loss: 0.6426 - val_accuracy: 0.6513\n",
      "Epoch 64/2000\n",
      "1557/1557 [==============================] - 178s 115ms/step - loss: 0.7543 - accuracy: 0.6142 - val_loss: 0.6282 - val_accuracy: 0.6599\n",
      "Epoch 65/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7545 - accuracy: 0.6119 - val_loss: 0.6304 - val_accuracy: 0.6542\n",
      "Epoch 66/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7545 - accuracy: 0.6181 - val_loss: 0.6403 - val_accuracy: 0.6744\n",
      "Epoch 67/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.7376 - accuracy: 0.6325 - val_loss: 0.6365 - val_accuracy: 0.6599\n",
      "Epoch 68/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.7558 - accuracy: 0.6235 - val_loss: 0.6334 - val_accuracy: 0.6686\n",
      "Epoch 69/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7598 - accuracy: 0.6187 - val_loss: 0.6232 - val_accuracy: 0.6599\n",
      "Epoch 70/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7677 - accuracy: 0.6177 - val_loss: 0.6276 - val_accuracy: 0.6715\n",
      "Epoch 71/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7501 - accuracy: 0.6148 - val_loss: 0.6324 - val_accuracy: 0.6599\n",
      "Epoch 72/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7375 - accuracy: 0.6277 - val_loss: 0.6276 - val_accuracy: 0.6657\n",
      "Epoch 73/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7506 - accuracy: 0.6174 - val_loss: 0.6217 - val_accuracy: 0.6657\n",
      "Epoch 74/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7515 - accuracy: 0.6216 - val_loss: 0.6173 - val_accuracy: 0.6657\n",
      "Epoch 75/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7406 - accuracy: 0.6357 - val_loss: 0.6191 - val_accuracy: 0.6686\n",
      "Epoch 76/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7587 - accuracy: 0.6264 - val_loss: 0.6245 - val_accuracy: 0.6657\n",
      "Epoch 77/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7521 - accuracy: 0.6319 - val_loss: 0.6176 - val_accuracy: 0.6599\n",
      "Epoch 78/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7626 - accuracy: 0.6168 - val_loss: 0.6121 - val_accuracy: 0.6657\n",
      "Epoch 79/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7576 - accuracy: 0.6299 - val_loss: 0.6154 - val_accuracy: 0.6657\n",
      "Epoch 80/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.7305 - accuracy: 0.6332 - val_loss: 0.6104 - val_accuracy: 0.6801\n",
      "Epoch 81/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7619 - accuracy: 0.6200 - val_loss: 0.6169 - val_accuracy: 0.6715\n",
      "Epoch 82/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7338 - accuracy: 0.6325 - val_loss: 0.6069 - val_accuracy: 0.6744\n",
      "Epoch 83/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7326 - accuracy: 0.6270 - val_loss: 0.6150 - val_accuracy: 0.6686\n",
      "Epoch 84/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7331 - accuracy: 0.6226 - val_loss: 0.6177 - val_accuracy: 0.6772\n",
      "Epoch 85/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7265 - accuracy: 0.6364 - val_loss: 0.6157 - val_accuracy: 0.6801\n",
      "Epoch 86/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7317 - accuracy: 0.6418 - val_loss: 0.6094 - val_accuracy: 0.6542\n",
      "Epoch 87/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7169 - accuracy: 0.6447 - val_loss: 0.6123 - val_accuracy: 0.6801\n",
      "Epoch 88/2000\n",
      "1557/1557 [==============================] - 178s 114ms/step - loss: 0.7335 - accuracy: 0.6335 - val_loss: 0.6140 - val_accuracy: 0.6744\n",
      "Epoch 89/2000\n",
      "1557/1557 [==============================] - 179s 115ms/step - loss: 0.7334 - accuracy: 0.6312 - val_loss: 0.6157 - val_accuracy: 0.6715\n",
      "Epoch 90/2000\n",
      "1453/1557 [==========================>...] - ETA: 11s - loss: 0.7342 - accuracy: 0.6355"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "epochs = 2000\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1/255.)#,\n",
    "        #rotation_range=30, \n",
    "        #width_shift_range=0.1,\n",
    "        #height_shift_range=0.1, \n",
    "        #horizontal_flip=True)\n",
    "train_datagen.fit(X_train)\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1/255.)#,\n",
    "        #rotation_range=30, \n",
    "        #width_shift_range=0.1,\n",
    "        #height_shift_range=0.1, \n",
    "        #horizontal_flip=True)\n",
    "val_datagen.fit(X_val)\n",
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_datagen.flow(X_val, y_val, batch_size=batch_size),\n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "# callbacks=[tf.keras.callbacks.ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model auc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1/255.)#,\n",
    "        #rotation_range=30, \n",
    "        #width_shift_range=0.1,\n",
    "        #height_shift_range=0.1, \n",
    "        #horizontal_flip=True)\n",
    "test_datagen.fit(X_test)\n",
    "\n",
    "score = model.evaluate(test_datagen.flow(X_test, y_test, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_datagen.flow(X_test, batch_size=batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIFT(preds, y_test): # >=2.5\n",
    "    condition = y_test.astype(bool) #preds에 정답인 예측 score만 남긴다.\n",
    "    c = np.extract(condition, preds)\n",
    "    b = np.argsort(-c)[:len(c)//5] #예측 score 상위 20%\n",
    "    \n",
    "    lift_20 = preds[b] \n",
    "    \n",
    "    lift_20_flat = np.argmax(lift_20, axis=1) #값을 확률에서 0, 1값으로 바꾼다. \n",
    "    y_test_flat = np.argmax(y_test, axis=1)\n",
    "    lift_20_1 = lift_20_flat[lift_20_flat == 1] #1인 경우만 남긴다. \n",
    "    y_1 = y_test_flat[y_test_flat == 1]\n",
    "    \n",
    "    lift_score = (len(lift_20_1)/len(lift_20_flat))/(len(y_1)/len(y_test_flat))\n",
    "    print('LIFT Accuracy: ',  lift_score)\n",
    "    return lift_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_score = LIFT(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.AUC()\n",
    "m.update_state(y_test, preds)\n",
    "auroc_score = m.result().numpy()\n",
    "print(auroc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = (lift_score/5)*0.7 + (auroc_score)*0.3\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
