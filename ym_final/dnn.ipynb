{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "#physical_devices = tf.config.list_physical_devices('GPU') \n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "seed_value= 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython = get_ipython()\n",
    "\n",
    "def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,\n",
    "                      exception_only=False, running_compiled_code=False):\n",
    "       etype, value, tb = sys.exc_info()\n",
    "       return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
    "\n",
    "ipython.showtraceback = hide_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_name = os.path.join(os.getcwd(), 'raw', 'SCDC_Track1_2차', f\"{'cst_feat_jan'}.csv\")\n",
    "df_x = pd.read_csv(x_name, index_col=0)\n",
    "\n",
    "y_name = os.path.join(os.getcwd(), 'raw', 'SCDC_Track1_2차', f\"{'train'}.csv\")\n",
    "df_y = pd.read_csv(y_name, index_col=0)\n",
    "\n",
    "v_name = os.path.join(os.getcwd(), 'raw', 'SCDC_Track1_2차', f\"{'val'}.csv\")\n",
    "df_v = pd.read_csv(v_name, index_col=0)\n",
    "\n",
    "df_yv = pd.concat([df_y, df_v])\n",
    "df = pd.merge(df_x, df_yv, on='cst_id_di')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['MRC_ID_DI'], axis=1)\n",
    "y = df['MRC_ID_DI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=1, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train\n",
    "train['cst_id_di'] = y_train.index\n",
    "train = train.set_index('cst_id_di')\n",
    "train['MRC_ID_DI'] = y_train\n",
    "\n",
    "train_0 = train[train['MRC_ID_DI'] == 0].sample(frac=1)\n",
    "train_1 = train[train['MRC_ID_DI'] == 1].sample(frac=1)\n",
    "train_2 = train[train['MRC_ID_DI'] == 2].sample(frac=1)\n",
    "train_3 = train[train['MRC_ID_DI'] == 3].sample(frac=1)\n",
    "train_4 = train[train['MRC_ID_DI'] == 4].sample(frac=1)\n",
    "train_5 = train[train['MRC_ID_DI'] == 5].sample(frac=1)\n",
    "train_6 = train[train['MRC_ID_DI'] == 6].sample(frac=1)\n",
    "train_7 = train[train['MRC_ID_DI'] == 7].sample(frac=1)\n",
    "train_8 = train[train['MRC_ID_DI'] == 8].sample(frac=1)\n",
    "train_9 = train[train['MRC_ID_DI'] == 9].sample(frac=1)\n",
    "train_10 = train[train['MRC_ID_DI'] == 10].sample(frac=1)\n",
    "\n",
    "sample_size = min(len(train_0),len(train_1), len(train_2), len(train_3), len(train_4), len(train_5), len(train_6), len(train_7),\n",
    "                 len(train_8), len(train_9), len(train_10))\n",
    "\n",
    "train_f = pd.concat([train_0.head(sample_size), train_1.head(sample_size), train_2.head(sample_size), train_3.head(sample_size),\n",
    "                    train_4.head(sample_size), train_5.head(sample_size), train_6.head(sample_size), train_7.head(sample_size), \n",
    "                    train_8.head(sample_size), train_9.head(sample_size), train_10.head(sample_size)]).sample(frac=1)\n",
    "\n",
    "X_train = train_f.drop(columns = ['MRC_ID_DI'], axis=1)\n",
    "y_train = train_f['MRC_ID_DI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_selection\n",
    "\n",
    "select = sklearn.feature_selection.SelectKBest(k=45)\n",
    "selected_features = select.fit(X_train, y_train)\n",
    "indices_selected = selected_features.get_support(indices=True)\n",
    "colnames_selected = [X_train.columns[i] for i in indices_selected]\n",
    "\n",
    "X_train = X_train[colnames_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X_train = X_train.astype(np.float16)\n",
    "combos = list(combinations(list(X_train.columns), 2))\n",
    "colnames = list(X_train.columns) + ['_'.join(x) for x in combos]\n",
    "\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = colnames\n",
    "\n",
    "\n",
    "noint_indicies = [i for i, x in enumerate(list((X_train == 0).all())) if x]\n",
    "X_train = X_train.drop(X_train.columns[noint_indicies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train\n",
    "train['cst_id_di'] = y_train.index\n",
    "train = train.set_index('cst_id_di')\n",
    "train['MRC_ID_DI'] = y_train\n",
    "\n",
    "X_train = train.drop(columns = ['MRC_ID_DI'], axis=1)\n",
    "y_train = train['MRC_ID_DI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_selection\n",
    "\n",
    "select = sklearn.feature_selection.SelectKBest(k=331)\n",
    "selected_features = select.fit(X_train, y_train)\n",
    "indices_selected = selected_features.get_support(indices=True)\n",
    "colnames_selected = [X_train.columns[i] for i in indices_selected]\n",
    "\n",
    "X_train = X_train[colnames_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X_test = X_test.astype(np.float16)\n",
    "combos = list(combinations(list(X_test.columns), 2))\n",
    "colnames = list(X_test.columns) + ['_'.join(x) for x in combos]\n",
    "\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "X_test = poly.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = colnames\n",
    "\n",
    "\n",
    "noint_indicies = [i for i, x in enumerate(list((X_test == 0).all())) if x]\n",
    "X_test = X_test.drop(X_test.columns[noint_indicies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_test\n",
    "test['cst_id_di'] = y_test.index\n",
    "test = test.set_index('cst_id_di')\n",
    "test['MRC_ID_DI'] = y_test\n",
    "\n",
    "X_test = test.drop(columns = ['MRC_ID_DI'], axis=1)\n",
    "y_test = test['MRC_ID_DI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[colnames_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = tf.keras.Input(dtype = tf.float32, shape = (len(X_train.columns),))\n",
    "\n",
    "dense_layer_1_1 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(input_)\n",
    "dense_layer_1_2 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_1)\n",
    "dense_layer_1_3 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_2)\n",
    "dense_layer_1_4 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(dense_layer_1_3)\n",
    "\n",
    "dropout_1_5 = tf.keras.layers.Dropout(rate = 0.2)(dense_layer_1_1)\n",
    "\n",
    "output = tf.keras.layers.Dense(units = 11, activation = tf.nn.softmax)(dropout_1_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=input_, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.00005), \n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40)\n",
    "history = model.fit(x=X_train, y=y_train, batch_size=32, epochs=10000, verbose=1, validation_split=0.1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x=X_test, y=y_test, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test ACC:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIFT(preds, y_test, cls): # >=2.5\n",
    "\n",
    "    n_score = preds[:, cls]\n",
    "    ind = np.argsort(-n_score)[:len(n_score)//5] #예측 score 상위 20%\n",
    "    \n",
    "    y_20 = y_test[ind]\n",
    "    y_20_flat = y_20[:, cls]\n",
    "    y_20_final = np.count_nonzero(y_20_flat == 1)\n",
    "    \n",
    "    y_test_flat = np.argmax(y_test, axis=1)\n",
    "    y_test_final = y_test_flat[y_test_flat == cls] \n",
    "    lift = (y_20_final/len(y_20))/ (len(y_test_final)/len(y_test))\n",
    "    print('LIFT Accuracy: ',  lift)\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_score = [0, 0, 0]\n",
    "lift_score[0] = LIFT(preds, y_test, 3)\n",
    "lift_score[1] = LIFT(preds, y_test, 4)\n",
    "lift_score[2] = LIFT(preds, y_test, 7)\n",
    "avg_lift = sum(lift_score) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in [3, 4, 7]:\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "avg_auroc = sum([roc_auc[3], roc_auc[4], roc_auc[7]]) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = (avg_lift)*0.7 + (avg_auroc)*0.3\n",
    "print(avg_lift, avg_auroc, final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#331- 0.2381"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
