{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_name = os.path.join(os.getcwd(), '데이터SET', f\"{'[Track1_데이터3] samp_cst_feat'}.csv\")\n",
    "df_x = pd.read_csv(x_name, index_col=0)\n",
    "\n",
    "y_name = os.path.join(os.getcwd(), '데이터SET', f\"{'[Track1_데이터2] samp_train'}.csv\")\n",
    "df_y = pd.read_csv(y_name, index_col=0)\n",
    "\n",
    "df = pd.merge(df_x, df_y, on='cst_id_di')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.MRC_ID_DI[df.MRC_ID_DI > 0 ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_name = os.path.join(os.getcwd(), '데이터SET', f\"{'[Track1_데이터4] variable_dtype'}.xlsx\")\n",
    "nc = pd.read_excel(nc_name, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from  sklearn.preprocessing import scale\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "\n",
    "def find_outliers_kde(x):\n",
    "    x_scaled = scale(list(map(float, x)))\n",
    "    kde = KDEUnivariate(x_scaled)\n",
    "    kde.fit(bw='scott', fft=True)\n",
    "    pred = kde.evaluate(x_scaled)\n",
    "    \n",
    "    n = sum(pred < 0.01)\n",
    "    outlier_ind = np.asarray(pred).argsort()[:n]\n",
    "    outlier_value = np.asarray(x)[outlier_ind]\n",
    "    \n",
    "    return outlier_ind, outlier_value\n",
    "\n",
    "for i in df.columns[0:-1]:\n",
    "    if nc.loc[i, 'dType'] == 'numerical':\n",
    "        kde_indices, kde_values = find_outliers_kde(df[i])\n",
    "        df_50 = df[i].quantile(0.50)\n",
    "        for j in range(len(df)):\n",
    "            if df[i].values[j] in kde_values:\n",
    "                df.at[df.index[j], i] = df_50\n",
    "\"\"\"\n",
    "for i in df.columns[0:-1]:\n",
    "    if nc.loc[i, 'dType'] == 'numerical':\n",
    "        d_90 = df[i].quantile(0.99)\n",
    "        d_10 = df[i].quantile(0.01)\n",
    "        d_50 = df[i].quantile(0.50)\n",
    "        df[i] = np.where(df[i] > d_90, d_90, df[i])\n",
    "        df[i] = np.where(df[i] < d_10, d_10, df[i])\n",
    "\"\"\"\n",
    "print(df.shape)\n",
    "#(10124, 227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "seed_value= 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython = get_ipython()\n",
    "\n",
    "def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,\n",
    "                      exception_only=False, running_compiled_code=False):\n",
    "       etype, value, tb = sys.exc_info()\n",
    "       return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
    "\n",
    "ipython.showtraceback = hide_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['MRC_ID_DI'] == 0].sample(frac=1)\n",
    "df_1 = df[df['MRC_ID_DI'] == 1].sample(frac=1)\n",
    "\n",
    "sample_size = len(df_0) if len(df_0) < len(df_1) else len(df_1)\n",
    "\n",
    "df_h = pd.concat([df_0.head(sample_size), df_1.head(sample_size)]).sample(frac=1)\n",
    "df_t = pd.concat([df_0.tail(sample_size), df_1.head(sample_size)]).sample(frac=1)\n",
    "df_f = pd.concat([df_h, df_t]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_f.drop(columns = ['MRC_ID_DI'], axis=1)\n",
    "#X = df_f.drop(columns = ['MRC_ID_DI', 'VAR021', 'VAR046'], axis=1)\n",
    "#y = tf.keras.utils.to_categorical(df_f['MRC_ID_DI'])\n",
    "y = df_f['MRC_ID_DI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num, cat = list(), list()\n",
    "for i in X.columns:\n",
    "    if nc.loc[i, 'dType'] == 'numerical':\n",
    "        num.append(i)\n",
    "    else:\n",
    "        cat.append(i)\n",
    "\n",
    "\n",
    "X1_train = X_train[num]\n",
    "X1_test = X_test[num]\n",
    "\n",
    "X2_train = X_train[cat]\n",
    "X2_test = X_test[cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def add_interactions(df1, df2):\n",
    "    df = pd.concat([df1, df2])\n",
    "    combos = list(combinations(list(df.columns), 2))\n",
    "    colnames = list(df.columns) + ['_'.join(x) for x in combos]\n",
    "    \n",
    "    poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "    df = poly.fit_transform(df)\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = colnames\n",
    "    \n",
    "    noint_indicies = [i for i, x in enumerate(list((df == 0).all())) if x]\n",
    "    df = df.drop(df.columns[noint_indicies], axis = 1)\n",
    "    return df[:len(df1)], df[len(df1):]\n",
    "\n",
    "X1_train, X1_test = add_interactions(X1_train, X1_test)\n",
    "X2_train, X2_test = add_interactions(X2_train, X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import sklearn.feature_selection\n",
    "\n",
    "select = sklearn.feature_selection.SelectKBest(k=len(X1_train.columns)//16)\n",
    "selected_features = select.fit(X1_train, y_train)\n",
    "indices_selected = selected_features.get_support(indices=True)\n",
    "colnames_selected = [X1_train.columns[i] for i in indices_selected]\n",
    "\n",
    "X1_train = X1_train[colnames_selected]\n",
    "X1_test = X1_test[colnames_selected]\n",
    "\n",
    "select = sklearn.feature_selection.SelectKBest(k=len(X2_train.columns)//16)\n",
    "selected_features = select.fit(X2_train, y_train)\n",
    "indices_selected = selected_features.get_support(indices=True)\n",
    "colnames_selected = [X2_train.columns[i] for i in indices_selected]\n",
    "\n",
    "X2_train = X2_train[colnames_selected]\n",
    "X2_test = X2_test[colnames_selected]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=min(len(pd.concat([X1_train, X1_test])), len(X1_train.columns)//16))\n",
    "X_t = pd.DataFrame(pca.fit_transform(pd.concat([X1_train, X1_test])))\n",
    "X1_train, X1_test = X_t[:len(X1_train)], X_t[len(X1_train):]\n",
    "\n",
    "pca = PCA(n_components=len(X2_train.columns)//16)\n",
    "X_t = pd.DataFrame(pca.fit_transform(pd.concat([X2_train, X2_test])))\n",
    "X2_train, X2_test = X_t[:len(X2_train)], X_t[len(X2_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = tf.keras.Input(dtype = tf.float32, shape = (len(X1_train.columns),))\n",
    "input_2 = tf.keras.Input(dtype = tf.float32, shape = (len(X2_train.columns),))\n",
    "\n",
    "dense_layer_1_1 = tf.keras.layers.Dense(units = 64, activation = tf.nn.relu)(input_1)\n",
    "dropout_1_5 = tf.keras.layers.Dropout(rate = 0.2)(dense_layer_1_1)\n",
    "\n",
    "\n",
    "dense_layer_2_1 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(input_2)\n",
    "dropout_2_5 = tf.keras.layers.Dropout(rate = 0.2)(dense_layer_2_1)\n",
    "\n",
    "concat_layer = tf.keras.layers.Concatenate()([dropout_1_5, dropout_2_5])\n",
    "\n",
    "\n",
    "dense_layer_3 = tf.keras.layers.Dense(units = 10, activation = tf.nn.relu)(concat_layer)\n",
    "dropout_3_5 = tf.keras.layers.Dropout(rate = 0.8)(dense_layer_3)\n",
    "\n",
    "#output = tf.keras.layers.Dense(units = 2, activation = tf.nn.softmax)(dense_layer_3)\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.softmax)(dropout_3_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[input_1, input_2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.00005), metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(x=X_train, y=y_train, batch_size=32, epochs=400, verbose=1, validation_split=0.1)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40)\n",
    "history = model.fit(x=[X1_train, X2_train], y=y_train, batch_size=32, epochs=2000, verbose=1, validation_split=0.1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x=[X1_test, X2_test], y=y_test, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test ACC:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
