{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('C:\\\\Users\\\\ADMIN\\\\Desktop\\\\merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cst_id_di</th>\n",
       "      <th>MRC_ID_DI</th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR218</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90000000089</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.06610</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>-0.13607</td>\n",
       "      <td>0.10945</td>\n",
       "      <td>0.06557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>-0.18965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32829</td>\n",
       "      <td>0.19113</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>0.09471</td>\n",
       "      <td>0.27091</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0.02938</td>\n",
       "      <td>0.17105</td>\n",
       "      <td>0.12537</td>\n",
       "      <td>0.22197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000000176</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.09537</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>-0.13541</td>\n",
       "      <td>0.17331</td>\n",
       "      <td>-0.19657</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>-0.23104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23729</td>\n",
       "      <td>0.19437</td>\n",
       "      <td>0.06538</td>\n",
       "      <td>0.16309</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>-0.01107</td>\n",
       "      <td>0.12413</td>\n",
       "      <td>0.29702</td>\n",
       "      <td>-0.31717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000000210</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01048</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.37797</td>\n",
       "      <td>-0.10970</td>\n",
       "      <td>0.52032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.32632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53283</td>\n",
       "      <td>-0.52084</td>\n",
       "      <td>-0.18568</td>\n",
       "      <td>-0.09755</td>\n",
       "      <td>-0.56565</td>\n",
       "      <td>-0.17840</td>\n",
       "      <td>-0.06314</td>\n",
       "      <td>-0.17111</td>\n",
       "      <td>-0.32239</td>\n",
       "      <td>0.33962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000000212</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05194</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.04611</td>\n",
       "      <td>-0.16512</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.26845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20754</td>\n",
       "      <td>-0.01934</td>\n",
       "      <td>-0.05172</td>\n",
       "      <td>-0.13245</td>\n",
       "      <td>-0.16357</td>\n",
       "      <td>-0.05697</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>-0.04022</td>\n",
       "      <td>0.31213</td>\n",
       "      <td>-0.00559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90000000213</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.08536</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>-0.12288</td>\n",
       "      <td>0.10023</td>\n",
       "      <td>-0.43414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>-0.25575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42251</td>\n",
       "      <td>0.23122</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.09206</td>\n",
       "      <td>0.46971</td>\n",
       "      <td>0.07964</td>\n",
       "      <td>-0.04698</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.22588</td>\n",
       "      <td>-0.34868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10119</th>\n",
       "      <td>90000460112</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.06606</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>-0.09743</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.10111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>-0.02041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19780</td>\n",
       "      <td>0.33881</td>\n",
       "      <td>-0.01692</td>\n",
       "      <td>-0.01823</td>\n",
       "      <td>0.21720</td>\n",
       "      <td>-0.08346</td>\n",
       "      <td>-0.07835</td>\n",
       "      <td>0.02321</td>\n",
       "      <td>0.32967</td>\n",
       "      <td>-0.25995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>90000460117</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.03031</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.07041</td>\n",
       "      <td>-0.02519</td>\n",
       "      <td>0.58013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.06676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09259</td>\n",
       "      <td>-0.19384</td>\n",
       "      <td>-0.02383</td>\n",
       "      <td>-0.02448</td>\n",
       "      <td>-0.05019</td>\n",
       "      <td>-0.02869</td>\n",
       "      <td>-0.05401</td>\n",
       "      <td>0.01670</td>\n",
       "      <td>-0.15880</td>\n",
       "      <td>0.48301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>90000460233</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.05351</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.36925</td>\n",
       "      <td>-0.10039</td>\n",
       "      <td>0.51159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.35016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46478</td>\n",
       "      <td>-0.45312</td>\n",
       "      <td>-0.17163</td>\n",
       "      <td>-0.08674</td>\n",
       "      <td>-0.40260</td>\n",
       "      <td>-0.15903</td>\n",
       "      <td>-0.10292</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.31895</td>\n",
       "      <td>0.40357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>90000460310</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00562</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.04581</td>\n",
       "      <td>-0.05390</td>\n",
       "      <td>0.20481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.11319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.01754</td>\n",
       "      <td>-0.01479</td>\n",
       "      <td>-0.03898</td>\n",
       "      <td>-0.01363</td>\n",
       "      <td>0.06974</td>\n",
       "      <td>-0.03815</td>\n",
       "      <td>-0.04371</td>\n",
       "      <td>0.11433</td>\n",
       "      <td>-0.01931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>90000460313</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.06814</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>-0.04318</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>-0.08842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>-0.02036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.08257</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.08881</td>\n",
       "      <td>0.01272</td>\n",
       "      <td>-0.01391</td>\n",
       "      <td>-0.05940</td>\n",
       "      <td>0.44214</td>\n",
       "      <td>0.22888</td>\n",
       "      <td>-0.09918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10124 rows × 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cst_id_di  MRC_ID_DI   VAR002  VAR003   VAR004   VAR005   VAR006  \\\n",
       "0      90000000089          0 -0.06610  0.5280 -0.13607  0.10945  0.06557   \n",
       "1      90000000176          8 -0.09537  0.1347 -0.13541  0.17331 -0.19657   \n",
       "2      90000000210          0 -0.01048  0.8360  0.37797 -0.10970  0.52032   \n",
       "3      90000000212          5  0.05194  0.7505  0.04611 -0.16512  0.07413   \n",
       "4      90000000213          6 -0.08536  0.3767 -0.12288  0.10023 -0.43414   \n",
       "...            ...        ...      ...     ...      ...      ...      ...   \n",
       "10119  90000460112          7 -0.06606  0.6615 -0.09743 -0.03240  0.10111   \n",
       "10120  90000460117          0 -0.03031  0.0143  0.07041 -0.02519  0.58013   \n",
       "10121  90000460233          0 -0.05351  0.3121  0.36925 -0.10039  0.51159   \n",
       "10122  90000460310          0 -0.00562  0.2286  0.04581 -0.05390  0.20481   \n",
       "10123  90000460313          0 -0.06814  0.6968 -0.04318  0.11340 -0.08842   \n",
       "\n",
       "       VAR007  VAR008   VAR009  ...   VAR218   VAR219   VAR220   VAR221  \\\n",
       "0           0  0.7702 -0.18965  ... -0.32829  0.19113  0.05449  0.09471   \n",
       "1           0  0.0616 -0.23104  ... -0.23729  0.19437  0.06538  0.16309   \n",
       "2           1  0.3257  0.32632  ...  0.53283 -0.52084 -0.18568 -0.09755   \n",
       "3           0  0.5322  0.26845  ...  0.20754 -0.01934 -0.05172 -0.13245   \n",
       "4           0  0.5468 -0.25575  ... -0.42251  0.23122  0.07913  0.09206   \n",
       "...       ...     ...      ...  ...      ...      ...      ...      ...   \n",
       "10119       0  0.9722 -0.02041  ... -0.19780  0.33881 -0.01692 -0.01823   \n",
       "10120       0  0.0330  0.06676  ...  0.09259 -0.19384 -0.02383 -0.02448   \n",
       "10121       0  0.2582  0.35016  ...  0.46478 -0.45312 -0.17163 -0.08674   \n",
       "10122       0  0.5957  0.11319  ...  0.10340  0.01754 -0.01479 -0.03898   \n",
       "10123       0  0.1151 -0.02036  ...  0.00564  0.08257  0.00120  0.08881   \n",
       "\n",
       "        VAR222   VAR223   VAR224   VAR225   VAR226   VAR227  \n",
       "0      0.27091  0.01931  0.02938  0.17105  0.12537  0.22197  \n",
       "1      0.30207  0.06053 -0.01107  0.12413  0.29702 -0.31717  \n",
       "2     -0.56565 -0.17840 -0.06314 -0.17111 -0.32239  0.33962  \n",
       "3     -0.16357 -0.05697  0.01587 -0.04022  0.31213 -0.00559  \n",
       "4      0.46971  0.07964 -0.04698  0.03581  0.22588 -0.34868  \n",
       "...        ...      ...      ...      ...      ...      ...  \n",
       "10119  0.21720 -0.08346 -0.07835  0.02321  0.32967 -0.25995  \n",
       "10120 -0.05019 -0.02869 -0.05401  0.01670 -0.15880  0.48301  \n",
       "10121 -0.40260 -0.15903 -0.10292 -0.11742 -0.31895  0.40357  \n",
       "10122 -0.01363  0.06974 -0.03815 -0.04371  0.11433 -0.01931  \n",
       "10123  0.01272 -0.01391 -0.05940  0.44214  0.22888 -0.09918  \n",
       "\n",
       "[10124 rows x 228 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#머신러닝 예제 보면서 예제 다 해보기 \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        8\n",
       "2        0\n",
       "3        5\n",
       "4        6\n",
       "        ..\n",
       "10119    7\n",
       "10120    0\n",
       "10121    0\n",
       "10122    0\n",
       "10123    0\n",
       "Name: MRC_ID_DI, Length: 10124, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'MRC_ID_DI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR218</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.06610</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>-0.13607</td>\n",
       "      <td>0.10945</td>\n",
       "      <td>0.06557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>-0.18965</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.24149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32829</td>\n",
       "      <td>0.19113</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>0.09471</td>\n",
       "      <td>0.27091</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0.02938</td>\n",
       "      <td>0.17105</td>\n",
       "      <td>0.12537</td>\n",
       "      <td>0.22197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.09537</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>-0.13541</td>\n",
       "      <td>0.17331</td>\n",
       "      <td>-0.19657</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>-0.23104</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>-0.39476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23729</td>\n",
       "      <td>0.19437</td>\n",
       "      <td>0.06538</td>\n",
       "      <td>0.16309</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>-0.01107</td>\n",
       "      <td>0.12413</td>\n",
       "      <td>0.29702</td>\n",
       "      <td>-0.31717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.01048</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.37797</td>\n",
       "      <td>-0.10970</td>\n",
       "      <td>0.52032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.32632</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.73494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53283</td>\n",
       "      <td>-0.52084</td>\n",
       "      <td>-0.18568</td>\n",
       "      <td>-0.09755</td>\n",
       "      <td>-0.56565</td>\n",
       "      <td>-0.17840</td>\n",
       "      <td>-0.06314</td>\n",
       "      <td>-0.17111</td>\n",
       "      <td>-0.32239</td>\n",
       "      <td>0.33962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05194</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.04611</td>\n",
       "      <td>-0.16512</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.26845</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.32617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20754</td>\n",
       "      <td>-0.01934</td>\n",
       "      <td>-0.05172</td>\n",
       "      <td>-0.13245</td>\n",
       "      <td>-0.16357</td>\n",
       "      <td>-0.05697</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>-0.04022</td>\n",
       "      <td>0.31213</td>\n",
       "      <td>-0.00559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.08536</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>-0.12288</td>\n",
       "      <td>0.10023</td>\n",
       "      <td>-0.43414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>-0.25575</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>-0.52948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42251</td>\n",
       "      <td>0.23122</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.09206</td>\n",
       "      <td>0.46971</td>\n",
       "      <td>0.07964</td>\n",
       "      <td>-0.04698</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.22588</td>\n",
       "      <td>-0.34868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10119</th>\n",
       "      <td>-0.06606</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>-0.09743</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.10111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>-0.02041</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.06993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19780</td>\n",
       "      <td>0.33881</td>\n",
       "      <td>-0.01692</td>\n",
       "      <td>-0.01823</td>\n",
       "      <td>0.21720</td>\n",
       "      <td>-0.08346</td>\n",
       "      <td>-0.07835</td>\n",
       "      <td>0.02321</td>\n",
       "      <td>0.32967</td>\n",
       "      <td>-0.25995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>-0.03031</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.07041</td>\n",
       "      <td>-0.02519</td>\n",
       "      <td>0.58013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.06676</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.68992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09259</td>\n",
       "      <td>-0.19384</td>\n",
       "      <td>-0.02383</td>\n",
       "      <td>-0.02448</td>\n",
       "      <td>-0.05019</td>\n",
       "      <td>-0.02869</td>\n",
       "      <td>-0.05401</td>\n",
       "      <td>0.01670</td>\n",
       "      <td>-0.15880</td>\n",
       "      <td>0.48301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>-0.05351</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.36925</td>\n",
       "      <td>-0.10039</td>\n",
       "      <td>0.51159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.35016</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.68799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46478</td>\n",
       "      <td>-0.45312</td>\n",
       "      <td>-0.17163</td>\n",
       "      <td>-0.08674</td>\n",
       "      <td>-0.40260</td>\n",
       "      <td>-0.15903</td>\n",
       "      <td>-0.10292</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.31895</td>\n",
       "      <td>0.40357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>-0.00562</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.04581</td>\n",
       "      <td>-0.05390</td>\n",
       "      <td>0.20481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.11319</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>0.42924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.01754</td>\n",
       "      <td>-0.01479</td>\n",
       "      <td>-0.03898</td>\n",
       "      <td>-0.01363</td>\n",
       "      <td>0.06974</td>\n",
       "      <td>-0.03815</td>\n",
       "      <td>-0.04371</td>\n",
       "      <td>0.11433</td>\n",
       "      <td>-0.01931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>-0.06814</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>-0.04318</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>-0.08842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>-0.02036</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>0.13615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.08257</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.08881</td>\n",
       "      <td>0.01272</td>\n",
       "      <td>-0.01391</td>\n",
       "      <td>-0.05940</td>\n",
       "      <td>0.44214</td>\n",
       "      <td>0.22888</td>\n",
       "      <td>-0.09918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10124 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008   VAR009  \\\n",
       "0     -0.06610  0.5280 -0.13607  0.10945  0.06557       0  0.7702 -0.18965   \n",
       "1     -0.09537  0.1347 -0.13541  0.17331 -0.19657       0  0.0616 -0.23104   \n",
       "2     -0.01048  0.8360  0.37797 -0.10970  0.52032       1  0.3257  0.32632   \n",
       "3      0.05194  0.7505  0.04611 -0.16512  0.07413       0  0.5322  0.26845   \n",
       "4     -0.08536  0.3767 -0.12288  0.10023 -0.43414       0  0.5468 -0.25575   \n",
       "...        ...     ...      ...      ...      ...     ...     ...      ...   \n",
       "10119 -0.06606  0.6615 -0.09743 -0.03240  0.10111       0  0.9722 -0.02041   \n",
       "10120 -0.03031  0.0143  0.07041 -0.02519  0.58013       0  0.0330  0.06676   \n",
       "10121 -0.05351  0.3121  0.36925 -0.10039  0.51159       0  0.2582  0.35016   \n",
       "10122 -0.00562  0.2286  0.04581 -0.05390  0.20481       0  0.5957  0.11319   \n",
       "10123 -0.06814  0.6968 -0.04318  0.11340 -0.08842       0  0.1151 -0.02036   \n",
       "\n",
       "       VAR010   VAR011  ...   VAR218   VAR219   VAR220   VAR221   VAR222  \\\n",
       "0      0.1981  0.24149  ... -0.32829  0.19113  0.05449  0.09471  0.27091   \n",
       "1      0.4940 -0.39476  ... -0.23729  0.19437  0.06538  0.16309  0.30207   \n",
       "2      0.7343  0.73494  ...  0.53283 -0.52084 -0.18568 -0.09755 -0.56565   \n",
       "3      0.7327  0.32617  ...  0.20754 -0.01934 -0.05172 -0.13245 -0.16357   \n",
       "4      0.9644 -0.52948  ... -0.42251  0.23122  0.07913  0.09206  0.46971   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "10119  0.6966  0.06993  ... -0.19780  0.33881 -0.01692 -0.01823  0.21720   \n",
       "10120  0.8251  0.68992  ...  0.09259 -0.19384 -0.02383 -0.02448 -0.05019   \n",
       "10121  0.4638  0.68799  ...  0.46478 -0.45312 -0.17163 -0.08674 -0.40260   \n",
       "10122  0.2527  0.42924  ...  0.10340  0.01754 -0.01479 -0.03898 -0.01363   \n",
       "10123  0.8465  0.13615  ...  0.00564  0.08257  0.00120  0.08881  0.01272   \n",
       "\n",
       "        VAR223   VAR224   VAR225   VAR226   VAR227  \n",
       "0      0.01931  0.02938  0.17105  0.12537  0.22197  \n",
       "1      0.06053 -0.01107  0.12413  0.29702 -0.31717  \n",
       "2     -0.17840 -0.06314 -0.17111 -0.32239  0.33962  \n",
       "3     -0.05697  0.01587 -0.04022  0.31213 -0.00559  \n",
       "4      0.07964 -0.04698  0.03581  0.22588 -0.34868  \n",
       "...        ...      ...      ...      ...      ...  \n",
       "10119 -0.08346 -0.07835  0.02321  0.32967 -0.25995  \n",
       "10120 -0.02869 -0.05401  0.01670 -0.15880  0.48301  \n",
       "10121 -0.15903 -0.10292 -0.11742 -0.31895  0.40357  \n",
       "10122  0.06974 -0.03815 -0.04371  0.11433 -0.01931  \n",
       "10123 -0.01391 -0.05940  0.44214  0.22888 -0.09918  \n",
       "\n",
       "[10124 rows x 226 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'VAR002':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        8\n",
       "2        0\n",
       "3        5\n",
       "4        6\n",
       "        ..\n",
       "10119    7\n",
       "10120    0\n",
       "10121    0\n",
       "10122    0\n",
       "10123    0\n",
       "Name: MRC_ID_DI, Length: 10124, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR002</th>\n",
       "      <th>VAR003</th>\n",
       "      <th>VAR004</th>\n",
       "      <th>VAR005</th>\n",
       "      <th>VAR006</th>\n",
       "      <th>VAR007</th>\n",
       "      <th>VAR008</th>\n",
       "      <th>VAR009</th>\n",
       "      <th>VAR010</th>\n",
       "      <th>VAR011</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR218</th>\n",
       "      <th>VAR219</th>\n",
       "      <th>VAR220</th>\n",
       "      <th>VAR221</th>\n",
       "      <th>VAR222</th>\n",
       "      <th>VAR223</th>\n",
       "      <th>VAR224</th>\n",
       "      <th>VAR225</th>\n",
       "      <th>VAR226</th>\n",
       "      <th>VAR227</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.06610</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>-0.13607</td>\n",
       "      <td>0.10945</td>\n",
       "      <td>0.06557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>-0.18965</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.24149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32829</td>\n",
       "      <td>0.19113</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>0.09471</td>\n",
       "      <td>0.27091</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0.02938</td>\n",
       "      <td>0.17105</td>\n",
       "      <td>0.12537</td>\n",
       "      <td>0.22197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.09537</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>-0.13541</td>\n",
       "      <td>0.17331</td>\n",
       "      <td>-0.19657</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>-0.23104</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>-0.39476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23729</td>\n",
       "      <td>0.19437</td>\n",
       "      <td>0.06538</td>\n",
       "      <td>0.16309</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>-0.01107</td>\n",
       "      <td>0.12413</td>\n",
       "      <td>0.29702</td>\n",
       "      <td>-0.31717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.01048</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.37797</td>\n",
       "      <td>-0.10970</td>\n",
       "      <td>0.52032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.32632</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.73494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53283</td>\n",
       "      <td>-0.52084</td>\n",
       "      <td>-0.18568</td>\n",
       "      <td>-0.09755</td>\n",
       "      <td>-0.56565</td>\n",
       "      <td>-0.17840</td>\n",
       "      <td>-0.06314</td>\n",
       "      <td>-0.17111</td>\n",
       "      <td>-0.32239</td>\n",
       "      <td>0.33962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05194</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.04611</td>\n",
       "      <td>-0.16512</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.26845</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.32617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20754</td>\n",
       "      <td>-0.01934</td>\n",
       "      <td>-0.05172</td>\n",
       "      <td>-0.13245</td>\n",
       "      <td>-0.16357</td>\n",
       "      <td>-0.05697</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>-0.04022</td>\n",
       "      <td>0.31213</td>\n",
       "      <td>-0.00559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.08536</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>-0.12288</td>\n",
       "      <td>0.10023</td>\n",
       "      <td>-0.43414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>-0.25575</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>-0.52948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42251</td>\n",
       "      <td>0.23122</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0.09206</td>\n",
       "      <td>0.46971</td>\n",
       "      <td>0.07964</td>\n",
       "      <td>-0.04698</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.22588</td>\n",
       "      <td>-0.34868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10119</th>\n",
       "      <td>-0.06606</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>-0.09743</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.10111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>-0.02041</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.06993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19780</td>\n",
       "      <td>0.33881</td>\n",
       "      <td>-0.01692</td>\n",
       "      <td>-0.01823</td>\n",
       "      <td>0.21720</td>\n",
       "      <td>-0.08346</td>\n",
       "      <td>-0.07835</td>\n",
       "      <td>0.02321</td>\n",
       "      <td>0.32967</td>\n",
       "      <td>-0.25995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>-0.03031</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.07041</td>\n",
       "      <td>-0.02519</td>\n",
       "      <td>0.58013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.06676</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.68992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09259</td>\n",
       "      <td>-0.19384</td>\n",
       "      <td>-0.02383</td>\n",
       "      <td>-0.02448</td>\n",
       "      <td>-0.05019</td>\n",
       "      <td>-0.02869</td>\n",
       "      <td>-0.05401</td>\n",
       "      <td>0.01670</td>\n",
       "      <td>-0.15880</td>\n",
       "      <td>0.48301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>-0.05351</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.36925</td>\n",
       "      <td>-0.10039</td>\n",
       "      <td>0.51159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.35016</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.68799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46478</td>\n",
       "      <td>-0.45312</td>\n",
       "      <td>-0.17163</td>\n",
       "      <td>-0.08674</td>\n",
       "      <td>-0.40260</td>\n",
       "      <td>-0.15903</td>\n",
       "      <td>-0.10292</td>\n",
       "      <td>-0.11742</td>\n",
       "      <td>-0.31895</td>\n",
       "      <td>0.40357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>-0.00562</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.04581</td>\n",
       "      <td>-0.05390</td>\n",
       "      <td>0.20481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.11319</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>0.42924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.01754</td>\n",
       "      <td>-0.01479</td>\n",
       "      <td>-0.03898</td>\n",
       "      <td>-0.01363</td>\n",
       "      <td>0.06974</td>\n",
       "      <td>-0.03815</td>\n",
       "      <td>-0.04371</td>\n",
       "      <td>0.11433</td>\n",
       "      <td>-0.01931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>-0.06814</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>-0.04318</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>-0.08842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>-0.02036</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>0.13615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.08257</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.08881</td>\n",
       "      <td>0.01272</td>\n",
       "      <td>-0.01391</td>\n",
       "      <td>-0.05940</td>\n",
       "      <td>0.44214</td>\n",
       "      <td>0.22888</td>\n",
       "      <td>-0.09918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10124 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        VAR002  VAR003   VAR004   VAR005   VAR006  VAR007  VAR008   VAR009  \\\n",
       "0     -0.06610  0.5280 -0.13607  0.10945  0.06557       0  0.7702 -0.18965   \n",
       "1     -0.09537  0.1347 -0.13541  0.17331 -0.19657       0  0.0616 -0.23104   \n",
       "2     -0.01048  0.8360  0.37797 -0.10970  0.52032       1  0.3257  0.32632   \n",
       "3      0.05194  0.7505  0.04611 -0.16512  0.07413       0  0.5322  0.26845   \n",
       "4     -0.08536  0.3767 -0.12288  0.10023 -0.43414       0  0.5468 -0.25575   \n",
       "...        ...     ...      ...      ...      ...     ...     ...      ...   \n",
       "10119 -0.06606  0.6615 -0.09743 -0.03240  0.10111       0  0.9722 -0.02041   \n",
       "10120 -0.03031  0.0143  0.07041 -0.02519  0.58013       0  0.0330  0.06676   \n",
       "10121 -0.05351  0.3121  0.36925 -0.10039  0.51159       0  0.2582  0.35016   \n",
       "10122 -0.00562  0.2286  0.04581 -0.05390  0.20481       0  0.5957  0.11319   \n",
       "10123 -0.06814  0.6968 -0.04318  0.11340 -0.08842       0  0.1151 -0.02036   \n",
       "\n",
       "       VAR010   VAR011  ...   VAR218   VAR219   VAR220   VAR221   VAR222  \\\n",
       "0      0.1981  0.24149  ... -0.32829  0.19113  0.05449  0.09471  0.27091   \n",
       "1      0.4940 -0.39476  ... -0.23729  0.19437  0.06538  0.16309  0.30207   \n",
       "2      0.7343  0.73494  ...  0.53283 -0.52084 -0.18568 -0.09755 -0.56565   \n",
       "3      0.7327  0.32617  ...  0.20754 -0.01934 -0.05172 -0.13245 -0.16357   \n",
       "4      0.9644 -0.52948  ... -0.42251  0.23122  0.07913  0.09206  0.46971   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "10119  0.6966  0.06993  ... -0.19780  0.33881 -0.01692 -0.01823  0.21720   \n",
       "10120  0.8251  0.68992  ...  0.09259 -0.19384 -0.02383 -0.02448 -0.05019   \n",
       "10121  0.4638  0.68799  ...  0.46478 -0.45312 -0.17163 -0.08674 -0.40260   \n",
       "10122  0.2527  0.42924  ...  0.10340  0.01754 -0.01479 -0.03898 -0.01363   \n",
       "10123  0.8465  0.13615  ...  0.00564  0.08257  0.00120  0.08881  0.01272   \n",
       "\n",
       "        VAR223   VAR224   VAR225   VAR226   VAR227  \n",
       "0      0.01931  0.02938  0.17105  0.12537  0.22197  \n",
       "1      0.06053 -0.01107  0.12413  0.29702 -0.31717  \n",
       "2     -0.17840 -0.06314 -0.17111 -0.32239  0.33962  \n",
       "3     -0.05697  0.01587 -0.04022  0.31213 -0.00559  \n",
       "4      0.07964 -0.04698  0.03581  0.22588 -0.34868  \n",
       "...        ...      ...      ...      ...      ...  \n",
       "10119 -0.08346 -0.07835  0.02321  0.32967 -0.25995  \n",
       "10120 -0.02869 -0.05401  0.01670 -0.15880  0.48301  \n",
       "10121 -0.15903 -0.10292 -0.11742 -0.31895  0.40357  \n",
       "10122  0.06974 -0.03815 -0.04371  0.11433 -0.01931  \n",
       "10123 -0.01391 -0.05940  0.44214  0.22888 -0.09918  \n",
       "\n",
       "[10124 rows x 226 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10124, 226) (10124,)\n"
     ]
    }
   ],
   "source": [
    "x=df.loc[:,'VAR002':]\n",
    "y=df.loc[:,'MRC_ID_DI']\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6074, 226) (2025, 226) (2025, 226)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 나누기 - 6:2:2 비율\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear SVM 학습하기\n",
    "linear_svm = SVC(kernel='linear')\n",
    "linear_svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8182716049382716\n"
     ]
    }
   ],
   "source": [
    "# linear SVM accuracy 계산하기\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "pred_val = linear_svm.predict(x_val)\n",
    "print(f\"accuracy:{accuracy_score(y_val, pred_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "accuracy of poly: 0.8182716049382716\n",
      "==========================================\n",
      "accuracy of rbf: 0.8182716049382716\n",
      "==========================================\n",
      "accuracy of sigmoid: 0.8093827160493827\n"
     ]
    }
   ],
   "source": [
    "# 여러 가지 kernel을 사용해 SVM 학습하고 accuracy 계산하기\n",
    "kernels = ['poly','rbf','sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(\"==========================================\") \n",
    "    model = SVC(kernel = kernel)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred_val = model.predict(x_val)\n",
    "    print(f\"accuracy of {kernel}: {accuracy_score(y_val, pred_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "accuracy of C=1, gamma=1e-05: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=1, gamma=0.0001: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=1, gamma=0.001: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=1, gamma=0.01: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=10, gamma=1e-05: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=10, gamma=0.0001: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=10, gamma=0.001: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=10, gamma=0.01: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=100, gamma=1e-05: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=100, gamma=0.0001: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=100, gamma=0.001: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=100, gamma=0.01: 0.817283950617284\n",
      "======================================\n",
      "accuracy of C=1000, gamma=1e-05: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=1000, gamma=0.0001: 0.8182716049382716\n",
      "======================================\n",
      "accuracy of C=1000, gamma=0.001: 0.8187654320987654\n",
      "======================================\n",
      "accuracy of C=1000, gamma=0.01: 0.7822222222222223\n"
     ]
    }
   ],
   "source": [
    "# 각 조합에 대해 SVM 학습하고 accuracy 계산하기\n",
    "C = [1, 10, 100, 1000]\n",
    "Gamma = [0.00001, 0.0001, 0.001, 0.01]\n",
    "\n",
    "for c in C:\n",
    "    for gamma in Gamma:\n",
    "        print(\"======================================\")\n",
    "        model = SVC(kernel = 'rbf', C=c, gamma=gamma)\n",
    "        model.fit(x_train, y_train)\n",
    "        pred_val = model.predict(x_val)\n",
    "        print(f\"accuracy of C={c}, gamma={gamma}: {accuracy_score(y_val, pred_val)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# GridSearchCV에서 cross validation을 하므로, validation data가 필요없음\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# 아래와 같이 탐색할 조합들을 지정\n",
    "param_grid = {'C': [1, 10, 100, 1000], \n",
    "              'gamma': [0.00001, 0.0001, 0.001, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=SVC(),\n",
       "             param_grid={'C': [1, 10, 100, 1000],\n",
       "                         'gamma': [1e-05, 0.0001, 0.001, 0.01]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV를 이용하여 분류하기\n",
    "svm_grid = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=4, scoring='accuracy')\n",
    "svm_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 1e-05}\n",
      "0.8101000341580051\n"
     ]
    }
   ],
   "source": [
    "# 최적의 조합과 그 때의 점수 알아보기\n",
    "print(svm_grid.best_params_)\n",
    "print(svm_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of rbf SVM grid: 0.8093827160493827\n"
     ]
    }
   ],
   "source": [
    "# test data에 대한 정확도 계산하기\n",
    "pred_test2 = svm_grid.best_estimator_.predict(x_test)\n",
    "print(f'test accuracy of rbf SVM grid: {accuracy_score(y_test, pred_test2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정 나무 모델 학습하기\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6561,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,   68,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,   12,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,   22,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    9,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,  116,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  438,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,  536,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,  272,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,   40,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   25]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy 및 confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(\"training accuracy: \", accuracy_score(y_train, tree.predict(x_train)))\n",
    "confusion_matrix(y_train, tree.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1657,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,   12,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    4,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    3,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,   31,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  108,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,  128,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,   61,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,   13,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    6]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation accuracy 및 confusion matrix\n",
    "print(\"validation accuracy: \", accuracy_score(y_val, tree.predict(x_val)))\n",
    "confusion_matrix(y_val, tree.predict(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, min_samples_leaf=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training과 validation 성능 차이를 줄일 수 있는 간단한 방법\n",
    "pruned_tree = DecisionTreeClassifier(max_depth=4, min_samples_leaf=3)\n",
    "pruned_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.8112112606494629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6542,    0,    0,    0,    0,    0,    2,   17,    0,    0,    0],\n",
       "       [  64,    3,    0,    0,    0,    0,    0,    1,    0,    0,    0],\n",
       "       [  12,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  22,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   9,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [ 113,    0,    0,    0,    0,    0,    0,    3,    0,    0,    0],\n",
       "       [ 426,    2,    0,    0,    0,    0,    5,    5,    0,    0,    0],\n",
       "       [ 513,    0,    0,    0,    0,    0,    3,   20,    0,    0,    0],\n",
       "       [ 267,    1,    0,    0,    0,    0,    3,    1,    0,    0,    0],\n",
       "       [  39,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0],\n",
       "       [  24,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"training accuracy: \", accuracy_score(y_train, pruned_tree.predict(x_train)))\n",
    "confusion_matrix(y_train, pruned_tree.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  0.8192592592592592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1652,    0,    0,    0,    0,    0,    0,    5,    0,    0,    0],\n",
       "       [  11,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   4,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  30,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0],\n",
       "       [ 107,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [ 122,    0,    0,    0,    0,    0,    0,    6,    0,    0,    0],\n",
       "       [  60,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0],\n",
       "       [  13,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   6,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"validation accuracy: \", accuracy_score(y_val, pruned_tree.predict(x_val)))\n",
    "confusion_matrix(y_val, pruned_tree.predict(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.8093827160493827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1633,    0,    0,    0,    0,    0,    2,    4,    0,    0,    0],\n",
       "       [  17,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   9,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0],\n",
       "       [   2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  26,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0],\n",
       "       [ 113,    0,    0,    0,    0,    0,    3,    0,    0,    0,    0],\n",
       "       [ 122,    0,    0,    0,    0,    0,    0,    3,    0,    0,    0],\n",
       "       [  65,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  18,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0],\n",
       "       [   3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"test accuracy: \", accuracy_score(y_test, pruned_tree.predict(x_test)))\n",
    "confusion_matrix(y_test, pruned_tree.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6074, 226) (2025, 226) (2025, 226)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 나누기 - 6:2:2 비율\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 회귀분석 객체 생성\n",
    "mlr = LinearRegression()\n",
    "\n",
    "# 회귀분석 모델 학습\n",
    "mlr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3843022931277795\n",
      "[ 3.71387283e-01 -9.06062611e-01 -1.58502205e+00 -1.12402739e-01\n",
      " -4.44040736e+00 -2.44097900e-01 -2.78451755e-02  6.08743260e-01\n",
      "  2.37073024e-01  1.67365523e+01  9.39235464e+00 -2.31493375e+00\n",
      "  1.36008429e+01 -9.13192557e-02  1.55133778e-02  2.80284270e-01\n",
      "  3.00303809e-02  1.19551046e+00  3.15783128e-01  6.34987766e+00\n",
      " -9.74955129e+00  2.65064799e-01 -1.19385152e+01  4.39016418e+00\n",
      " -2.60552226e-02  2.04630596e+01  6.77382543e+00 -5.13607719e+00\n",
      " -9.31434674e-01  1.65743520e-01  2.11238177e+01  2.98163786e-01\n",
      " -5.36391956e+00  1.22483779e-01  2.77405572e-01 -3.13812150e+00\n",
      "  1.55733634e+00 -1.03617116e+01 -3.46561517e-01  2.50605755e+01\n",
      "  3.29450964e-02 -1.89713209e+00 -1.90192703e-01 -8.72515611e-01\n",
      "  6.62256827e+00  5.54468433e+00 -4.98991709e+00  2.93118596e+00\n",
      " -8.18038439e-01  7.67785981e-01  1.61908623e+01  1.94500520e+01\n",
      " -2.56269728e+00  1.10857234e+00 -3.67988222e+00 -4.83222670e+00\n",
      " -1.68843431e+01  1.04741241e-02  4.04803127e+01 -6.14409311e+00\n",
      " -7.41222569e-03  8.12401437e+00  1.09714063e-01  3.63248949e-02\n",
      " -4.24204182e-02  1.18743639e-01 -1.99556493e-01  8.93593672e+00\n",
      " -2.87129099e-01  6.72226429e-01 -5.90638346e-01 -1.36435864e+01\n",
      " -1.07363982e+00 -1.76504360e+00 -2.43626354e+01  8.32190889e-01\n",
      " -2.24936893e-01 -4.06930081e-02  6.91456557e-01 -4.28161251e-01\n",
      "  8.17720518e-01 -1.05061011e+00  3.48608616e-03  1.75212960e+01\n",
      "  1.75116308e-01  9.02965729e+00  4.06634334e-01 -2.00791320e+01\n",
      "  4.17883697e-01  5.08006429e+00 -5.02138765e+00 -5.84869958e+00\n",
      "  6.35328038e-01  1.98639381e+01  6.15293620e-01 -1.96767391e-01\n",
      "  9.26168215e-01  2.97490886e-01 -6.06702521e-01  8.81816215e-01\n",
      "  5.26217209e-01 -2.17099900e-01  4.33272670e+00  6.98756741e-01\n",
      " -5.79062915e+00  5.48126764e-01  3.60427329e-01 -1.58642030e+00\n",
      " -5.87220315e-01  1.33486490e-01  4.56241402e-01  9.15661959e-01\n",
      " -1.85012948e+01  3.15126928e+00 -9.80931160e+00 -2.10460382e-01\n",
      " -3.94211315e+00 -2.38267984e+01 -8.71849311e+00  2.03961002e+01\n",
      "  1.41897499e+00  1.98236752e+01 -2.68955017e-01  2.44003734e+00\n",
      "  4.86836367e+00 -1.78715473e-01 -1.16875433e+01  3.25140855e-01\n",
      "  2.64335622e+00 -3.40377255e-01  8.87585302e-01 -2.27859224e+00\n",
      "  7.89239110e-01  1.29949631e+00  6.65697001e-01  2.16192922e-01\n",
      "  3.40031322e-01 -4.72536991e+00 -1.45010459e+01  6.01112923e+00\n",
      " -2.81300550e-01  1.14229948e+00  1.09478494e-01  9.83076618e-01\n",
      " -3.94627341e-01  6.13108369e+00  9.06625214e-01  1.05498205e+00\n",
      "  1.62328913e+01 -7.63239910e-01  1.42556469e+01 -1.11276916e+00\n",
      "  5.62176289e-01 -1.07652436e+00  8.82495780e-01  6.17108007e+00\n",
      "  3.56792423e+00  1.08437660e+00  1.54856201e+01 -1.33501542e+00\n",
      "  3.02129427e+00  2.26399561e+00 -1.47277548e+00  3.52300774e-01\n",
      " -6.84572248e-02 -1.30203026e-01 -4.22693705e+00  2.14411512e+00\n",
      " -1.13342482e+00 -6.92542701e-02 -2.93882853e+00 -1.04387593e+00\n",
      " -5.51816279e+00 -9.92319072e-01  4.56053461e+00  8.12820040e-01\n",
      " -1.38759805e-01  7.01069045e-02  3.80908924e-03 -1.68337259e-01\n",
      " -1.78158327e+00  5.12726829e-01 -4.27018511e+00  5.04416189e+00\n",
      " -4.19264796e+00 -5.22243187e-01  1.94720461e+00  2.56826367e+00\n",
      "  3.25959155e+00  8.64279728e+00 -1.01386730e-01 -3.21135823e-01\n",
      "  7.30959115e-01 -1.55548991e-01  5.87944289e+00 -1.11215598e+00\n",
      " -2.80607368e+00  9.63111171e-02 -5.62222603e+00  1.39796489e-01\n",
      "  1.27739839e+01  1.05874071e+01 -8.25460698e-01 -4.35003293e+00\n",
      " -1.90595402e-02 -4.57583797e-02  7.18212821e-01 -1.56194426e+00\n",
      "  2.91512296e+00  2.00942513e+00  3.26638092e-01  1.32812872e-02\n",
      "  1.74574087e+00  2.06032143e+00 -4.25480355e+01  1.33704161e+01\n",
      "  1.57454657e+00 -2.42656332e-01  3.21348551e-02  1.47472313e-01\n",
      " -5.91945179e+00  4.63874093e-01  2.23716651e-01  8.19450975e-01\n",
      "  1.15908246e+00  1.15235825e+01]\n"
     ]
    }
   ],
   "source": [
    "# 회귀계수 확인\n",
    "print(mlr.intercept_)\n",
    "print(mlr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data 예측값\n",
    "pred_train = mlr.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33225740492590217\n"
     ]
    }
   ],
   "source": [
    "# training data에 대한 R-square 계산\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28810275366992844\n"
     ]
    }
   ],
   "source": [
    "# validation data에 대한 R-square 계산\n",
    "pred_val = mlr.predict(x_val)\n",
    "print(r2_score(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29997494378772604\n"
     ]
    }
   ],
   "source": [
    "# test data에 대한 R-square 계산\n",
    "pred_test = mlr.predict(x_test)\n",
    "print(r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ round 1 ============\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), [0])' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-921d718eb8b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# 지정된 변수만 사용하게끔 데이터 추출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mx_train_small\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mx_val_small\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2644\u001b[0m                 )\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2648\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), [0])' is an invalid key"
     ]
    }
   ],
   "source": [
    "#전진선택법 \n",
    "\n",
    "# 선택된 변수들, R-square 값 및 모델 저장\n",
    "best_variables = []\n",
    "best_r2 = 0.\n",
    "best_model = None\n",
    "\n",
    "# 남아 있는 변수들\n",
    "remain_variables = list(range(10))\n",
    "\n",
    "for round in range(10):\n",
    "    print(f\"============ round {round+1} ============\")\n",
    "    r2_of_this_round = []\n",
    "    models_of_this_round = []\n",
    "\n",
    "    for var in remain_variables:\n",
    "        # 사용될 변수들과 모델\n",
    "        use_vars = best_variables + [var]\n",
    "        model = LinearRegression()\n",
    "\n",
    "        # 지정된 변수만 사용하게끔 데이터 추출\n",
    "        x_train_small = x_train[:, use_vars]\n",
    "        x_val_small = x_val[:, use_vars]\n",
    "\n",
    "        # 지정된 변수로 모델 학습\n",
    "        model.fit(x_train_small, y_train)\n",
    "        models_of_this_round.append(model)\n",
    "\n",
    "        # validation R-square 계산\n",
    "        r2 = r2_score(y_val, model.predict(x_val_small))\n",
    "        r2_of_this_round.append(r2)\n",
    "  \n",
    "    # R-square 가 높은 모델 선택\n",
    "    best_r2_of_this_round = np.max(r2_of_this_round)\n",
    "\n",
    "    # 이전 round와 비교\n",
    "    if best_r2_of_this_round > best_r2:\n",
    "        best_var_of_this_round = np.argmax(r2_of_this_round)\n",
    "\n",
    "        # 변수 추가, R-square 값 및 모델 업데이트\n",
    "        best_variables.append(remain_variables[best_var_of_this_round])\n",
    "        best_r2 = best_r2_of_this_round\n",
    "        best_model = models_of_this_round[best_var_of_this_round]\n",
    "\n",
    "        # 남은 변수들 중 선택된 변수 제거\n",
    "        remain_variables.pop(best_var_of_this_round)\n",
    "\n",
    "        print('best variables updated: ', best_variables)\n",
    "        print('current best r2: ', best_r2)\n",
    "\n",
    "    # 더 이상 개선되지 않으면 멈춤  \n",
    "    else:\n",
    "        print(\"no improvement\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "print('\\n---------------------------------------------------\\n')\n",
    "print('final variables: ', sorted(best_variables))\n",
    "print('final r2: ', best_r2)\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test, best_model.predict(x_test[:, best_variables])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data에 대한 adjust R-square 계산\n",
    "pred_test = mlr.predict(x_test)\n",
    "test_r2 = r2_score(y_test, pred_test)\n",
    "test_adj_r2 = 1-(1-test_r2)*(y_test.shape[0]-1)/(y_test.shape[0]-x_test.shape[1]-1)\n",
    "print(test_adj_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#후진제거법\n",
    "# 선택된 변수들, R-square 값 및 모델 저장\n",
    "best_variables = list(range(10))\n",
    "best_adj_r2 = 0.\n",
    "best_model = None\n",
    "\n",
    "\n",
    "# 선택된 변수들 중 Adjusted R-square의 손실이 가장 적은 변수를 골라 없애기\n",
    "for round in range(10):\n",
    "  print(f\"============ round {round+1} ============\")\n",
    "  adj_r2_of_this_round = []\n",
    "  models_of_this_round = []\n",
    "\n",
    "  for var in best_variables:\n",
    "    # 사용될 변수들과 모델\n",
    "    use_vars = best_variables.copy()\n",
    "    use_vars.remove(var)\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # 지정된 변수만 사용하게끔 데이터 추출\n",
    "    x_train_small = x_train[:, use_vars]\n",
    "    x_val_small = x_val[:, use_vars]\n",
    "\n",
    "    # 지정된 변수로 모델 학습\n",
    "    model.fit(x_train_small, y_train)\n",
    "    models_of_this_round.append(model)\n",
    "\n",
    "    # validation adjusted R-square 계산\n",
    "    r2 = r2_score(y_val, model.predict(x_val_small))\n",
    "    adj_r2 = 1 - (1-r2)*(y_val.shape[0]-1)/(y_val.shape[0]-len(use_vars)-1)\n",
    "    adj_r2_of_this_round.append(adj_r2)\n",
    "    \n",
    "  # R-square 가 높은 모델 선택\n",
    "  best_adj_r2_of_this_round = np.max(adj_r2_of_this_round)\n",
    "\n",
    "  # 이전 round와 비교\n",
    "  if best_adj_r2_of_this_round > best_adj_r2:\n",
    "    max_var = np.argmax(adj_r2_of_this_round)\n",
    "    best_variables.pop(max_var)\n",
    "    best_adj_r2 = best_adj_r2_of_this_round\n",
    "    best_model = models_of_this_round[max_var]\n",
    "\n",
    "    print('best variables updated: ', best_variables)\n",
    "    print('current best r2: ', best_adj_r2)\n",
    "\n",
    "  # 더 이상 개선되지 않으면 멈춤\n",
    "  else:\n",
    "    print(\"no improvement\")\n",
    "    break\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "print('final variables: ', sorted(best_variables))\n",
    "print('final adj_r2: ', best_adj_r2)\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "test_r2=r2_score(y_test, best_model.predict(x_test[:, best_variables]))\n",
    "test_adj_r2 =1-(1-test_r2)*(y_test.shape[0]-1)/(y_test.shape[0]-len(best_variables)-1) \n",
    "print('test adjust R-square: ', test_adj_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#회귀모형 검정\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model = OLS(y_train, statsmodels.api.add_constant(x_train))\n",
    "\n",
    "sm_model = sm_model.fit()\n",
    "print(sm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(x_train.shape[1]):\n",
    "  print(f\"VIF of x{i+1}: {variance_inflation_factor(x_train, i):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중공선성이 확인된 변수들을 제외하고 회귀분석 학습하고 결과 출력하기(statsmodels 이용)\n",
    "use_variables = [i for i in range(x_train.shape[1]) if variance_inflation_factor(x_train, i) < 10]\n",
    "small_model = OLS(y_train, statsmodels.api.add_constant(x_train[:, use_variables]))\n",
    "\n",
    "small_model = small_model.fit()\n",
    "print(small_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(pred_train, y_train - pred_train)\n",
    "plt.plot([pred_train.min(), pred_train.max()], [0, 0], '--', color='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Regression - 성능 안좋아 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge, Lasso, ElasticNet 모델 객체 생성하기\n",
    "ridge = Ridge(alpha=0.1)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "elastic = ElasticNet(alpha=1.0, l1_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 모델 학습하기\n",
    "ridge.fit(x_train, y_train)\n",
    "lasso.fit(x_train, y_train)\n",
    "elastic.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge training R-square: %.4f 0.32793760848693687\n",
      "Ridge validation R-square: %.4f 0.2926347384395527\n"
     ]
    }
   ],
   "source": [
    "# Ridge 모델의 training & validation data에 대한 R-square 계산하기\n",
    "ridge_train_r2 = ridge.score(x_train, y_train)\n",
    "ridge_val_r2 = ridge.score(x_val, y_val)\n",
    "print (\"Ridge training R-square: %.4f\", ridge_train_r2)\n",
    "print (\"Ridge validation R-square: %.4f\", ridge_val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso training R-square: 0.16415783130130268\n",
      "Lasso validation R-square:  0.15966887158151266\n"
     ]
    }
   ],
   "source": [
    "# Lasso 모델의 training & validation data에 대한 R-square 계산하기\n",
    "lasso_train_r2 = lasso.score(x_train, y_train)\n",
    "lasso_val_r2 = lasso.score(x_val, y_val)\n",
    "print (\"Lasso training R-square:\", lasso_train_r2)\n",
    "print (\"Lasso validation R-square: \", lasso_val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet training R-square: 0.0\n",
      "ElasticNet validation R-square::  -0.00042236721162192126\n"
     ]
    }
   ],
   "source": [
    "# TODO: ElasticNet 모델의 training & validation data에 대한 R-square 계산하기\n",
    "elastic_train_r2 = elastic.score(x_train, y_train)\n",
    "elastic_val_r2 = elastic.score(x_val, y_val)\n",
    "print (\"ElasticNet training R-square:\", elastic_train_r2)\n",
    "print (\"ElasticNet validation R-square:: \", elastic_val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used variables: Ridge vs Lasso vs ElasticNet = 226 vs 5 vs 0\n"
     ]
    }
   ],
   "source": [
    "# 각 모델이 사용한 변수의 개수 세어보기\n",
    "ridge_used_variables = np.sum(ridge.coef_ != 0)\n",
    "lasso_used_variables = np.sum(lasso.coef_ != 0)\n",
    "elastic_used_variables = np.sum(elastic.coef_ != 0)\n",
    "print(\"Used variables: Ridge vs Lasso vs ElasticNet = %d vs %d vs %d\" % (ridge_used_variables, lasso_used_variables, elastic_used_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================= alpha=0.01 =======================\n",
      "training score: 0.23808434475025886\n",
      "test score: 0.2326275034760361\n",
      "number of features used: 31\n",
      "======================= alpha=0.1 =======================\n",
      "training score: 0.16415783130130268\n",
      "test score: 0.15966887158151266\n",
      "number of features used: 5\n",
      "======================= alpha=1 =======================\n",
      "training score: 0.0\n",
      "test score: -0.00042236721162192126\n",
      "number of features used: 0\n",
      "======================= alpha=10 =======================\n",
      "training score: 0.0\n",
      "test score: -0.00042236721162192126\n",
      "number of features used: 0\n"
     ]
    }
   ],
   "source": [
    "alpha_list = [0.01, 0.1, 1, 10]\n",
    "for alpha in alpha_list:\n",
    "    # TODO: 각 alpha를 이용한 Lasso 모델의 training & validation data에 대한 R-square 및 변수 개수 계산하기\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(x_train, y_train)\n",
    "    lasso_train_score = lasso.score(x_train, y_train)\n",
    "    lasso_val_score = lasso.score(x_val, y_val)\n",
    "    lasso_used_variables = np.sum(lasso.coef_ != 0)\n",
    "    \n",
    "    print(f\"======================= alpha={alpha} =======================\")\n",
    "    print(f\"training score: {lasso_train_score}\")\n",
    "    print(f\"test score: {lasso_val_score}\")\n",
    "    print(f\"number of features used: {lasso_used_variables}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression -성능 젤 좋아 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8202173197234113\n",
      "[[4824    1    0    0    0    1   31   42    5    0    0]\n",
      " [  43    4    0    0    0    0    3    1    5    0    0]\n",
      " [   7    0    2    0    0    0    1    0    0    0    0]\n",
      " [  14    0    0    1    0    0    1    2    0    0    0]\n",
      " [   6    0    0    0    0    0    0    0    0    0    0]\n",
      " [  59    0    0    0    0   12    2   12    0    0    0]\n",
      " [ 252    1    0    0    0    2   46   20    9    0    0]\n",
      " [ 307    0    0    0    0    3   18   74    6    0    0]\n",
      " [ 161    0    0    0    0    1   19   11   19    0    0]\n",
      " [  26    0    0    0    0    0    1    0    0    0    0]\n",
      " [  16    0    0    0    0    0    1    0    2    0    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "pred_train = logistic.predict(x_train)\n",
    "print(f'training accuracy: {accuracy_score(y_train, pred_train)}')\n",
    "print(confusion_matrix(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.8232098765432099\n",
      "[[1631    0    0    0    0    0    7   14    5    0    0]\n",
      " [   9    0    0    0    0    0    3    0    0    0    0]\n",
      " [   2    0    0    0    0    0    0    0    0    0    0]\n",
      " [   3    0    0    0    0    0    0    1    0    0    0]\n",
      " [   3    0    0    0    0    0    0    0    0    0    0]\n",
      " [  20    0    0    0    0    0    5    6    0    0    0]\n",
      " [  86    3    0    0    0    0    9    5    5    0    0]\n",
      " [  99    0    0    0    0    3    3   22    1    0    0]\n",
      " [  47    1    0    0    0    0    5    3    5    0    0]\n",
      " [  13    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "pred_val = logistic.predict(x_val)\n",
    "print(f'validation accuracy: {accuracy_score(y_val, pred_val)}')\n",
    "print(confusion_matrix(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8162962962962963\n",
      "[[1615    2    0    0    0    0    5   16    1    0    0]\n",
      " [  13    1    0    0    0    0    1    0    2    0    0]\n",
      " [   1    0    0    0    0    0    1    0    0    0    0]\n",
      " [   7    0    0    0    0    0    0    3    0    0    0]\n",
      " [   1    0    0    0    0    0    0    1    0    0    0]\n",
      " [  15    0    0    0    0    1    2    9    0    0    0]\n",
      " [  97    0    0    0    0    0    9    7    3    0    0]\n",
      " [  90    0    0    0    0    1    5   26    3    0    0]\n",
      " [  50    0    0    0    0    1   11    2    1    0    0]\n",
      " [  15    0    0    0    0    0    2    2    0    0    0]\n",
      " [   3    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "pred_test = logistic.predict(x_test)\n",
    "print(f'test accuracy: {accuracy_score(y_test, pred_test)}')\n",
    "print(confusion_matrix(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 경고 문구 없이 로지스틱 회귀분석 학습 완료하기\n",
    "logistic10000 = LogisticRegression(max_iter=10000)\n",
    "logistic10000.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8198880474152124\n",
      "[[4821    1    1    0    0    2   30   43    6    0    0]\n",
      " [  43    4    0    0    0    0    3    1    5    0    0]\n",
      " [   7    0    2    0    0    0    1    0    0    0    0]\n",
      " [  14    0    0    1    0    0    1    2    0    0    0]\n",
      " [   6    0    0    0    0    0    0    0    0    0    0]\n",
      " [  60    0    0    0    0   11    2   12    0    0    0]\n",
      " [ 252    0    0    0    0    2   47   20    9    0    0]\n",
      " [ 306    0    0    0    0    3   18   75    6    0    0]\n",
      " [ 162    0    0    0    0    1   18   11   19    0    0]\n",
      " [  26    0    0    0    0    0    1    0    0    0    0]\n",
      " [  16    0    0    0    0    0    1    0    2    0    0]]\n",
      "-----------------------------------\n",
      "accuracy: 0.8232098765432099\n",
      "[[1631    0    0    0    0    0    7   14    5    0    0]\n",
      " [   9    0    0    0    0    0    3    0    0    0    0]\n",
      " [   2    0    0    0    0    0    0    0    0    0    0]\n",
      " [   3    0    0    0    0    0    0    1    0    0    0]\n",
      " [   3    0    0    0    0    0    0    0    0    0    0]\n",
      " [  20    0    0    0    0    0    5    6    0    0    0]\n",
      " [  86    3    0    0    0    0    9    5    5    0    0]\n",
      " [  99    0    0    0    0    3    3   22    1    0    0]\n",
      " [  47    1    0    0    0    0    5    3    5    0    0]\n",
      " [  13    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6    0    0    0    0    0    0    0    0    0    0]]\n",
      "-----------------------------------\n",
      "accuracy: 0.8153086419753086\n",
      "[[1614    2    0    0    0    0    5   16    2    0    0]\n",
      " [  13    1    0    0    0    0    1    0    2    0    0]\n",
      " [   1    0    0    0    0    0    1    0    0    0    0]\n",
      " [   7    0    0    0    0    0    0    3    0    0    0]\n",
      " [   1    0    0    0    0    0    0    1    0    0    0]\n",
      " [  14    0    0    0    0    1    2   10    0    0    0]\n",
      " [  97    0    0    0    0    0    9    7    3    0    0]\n",
      " [  91    0    0    0    0    1    5   25    3    0    0]\n",
      " [  49    0    0    0    0    1   12    2    1    0    0]\n",
      " [  15    0    0    0    0    0    2    2    0    0    0]\n",
      " [   3    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 학습한 모델의 training, validation, test 정확도 알아보기\n",
    "new_pred_train = logistic10000.predict(x_train)\n",
    "print(f'accuracy: {accuracy_score(y_train, new_pred_train)}')\n",
    "print(confusion_matrix(y_train, new_pred_train))\n",
    "\n",
    "print('-----------------------------------')\n",
    "new_pred_val = logistic10000.predict(x_val)\n",
    "print(f'accuracy: {accuracy_score(y_val, new_pred_val)}')\n",
    "print(confusion_matrix(y_val, new_pred_val))\n",
    "\n",
    "print('-----------------------------------')\n",
    "new_pred_test = logistic10000.predict(x_test)\n",
    "print(f'accuracy: {accuracy_score(y_test, new_pred_test)}')\n",
    "print(confusion_matrix(y_test, new_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합의기반결합 - Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 생성하기\n",
    "log_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), \n",
    "                ('dt', dt_clf), \n",
    "                ('svc', svm_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting accuracy: 0.8108641975308643\n",
      "lr: 0.8162962962962963\n",
      "dt: 0.7071604938271605\n",
      "svc: 0.8093827160493827\n"
     ]
    }
   ],
   "source": [
    "# 각 모델 학습 및 정확도 확인하기\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "voting_clf.fit(x_train, y_train)\n",
    "pred_test = voting_clf.predict(x_test)\n",
    "print(f'voting accuracy: {accuracy_score(y_test, pred_test)}')\n",
    "\n",
    "for name, estimator in voting_clf.named_estimators_.items():\n",
    "  estimator.fit(x_train, y_train)\n",
    "  pred_test_estim = estimator.predict(x_test)\n",
    "  print(f'{name}: {accuracy_score(y_test, pred_test_estim)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft voting 방식으로 모델 생성하기\n",
    "log_clf_2 = LogisticRegression()\n",
    "dt_clf_2 = DecisionTreeClassifier(random_state=1)\n",
    "svm_clf_2 = SVC(probability=True)\n",
    "\n",
    "voting_clf_2 = VotingClassifier(\n",
    "    estimators=[('lr', log_clf_2), \n",
    "                ('dt', dt_clf_2), \n",
    "                ('svc', svm_clf_2)],\n",
    "                voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft voting accuracy: 0.7975308641975308\n",
      "lr: 0.8162962962962963\n",
      "dt: 0.7071604938271605\n",
      "svc: 0.8093827160493827\n"
     ]
    }
   ],
   "source": [
    "# soft voting 방식으로 생성한 모델 학습하기\n",
    "voting_clf_2.fit(x_train, y_train)\n",
    "pred_test_2 = voting_clf_2.predict(x_test)\n",
    "print(f'soft voting accuracy: {accuracy_score(y_test, pred_test_2)}')\n",
    "\n",
    "for name, estimator in voting_clf_2.named_estimators_.items():\n",
    "  estimator.fit(x_train, y_train)\n",
    "  pred_test_estim = estimator.predict(x_test)\n",
    "  print(f'{name}: {accuracy_score(y_test, pred_test_estim)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합의기반 결합 -Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7071604938271605\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=1)\n",
    "tree_clf.fit(x_train, y_train)\n",
    "pred_test = tree_clf.predict(x_test)\n",
    "print(f'accuracy: {accuracy_score(y_test, pred_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8103703703703704\n"
     ]
    }
   ],
   "source": [
    "# BaggingClassifier를 사용해 의사결정 나무 분류기 학습 및 정확도 계산하기\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=1), n_estimators=300,\n",
    "    max_samples=500, random_state=1)\n",
    "bag_clf.fit(x_train, y_train)\n",
    "\n",
    "pred_test_bag = bag_clf.predict(x_test)\n",
    "print(f'accuracy: {accuracy_score(y_test, pred_test_bag)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8098765432098766\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier를 사용해 분류기 학습 및 정확도 계산하기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, random_state=1)\n",
    "rf_clf.fit(x_train, y_train)\n",
    "pred_test_rf = rf_clf.predict(x_test)\n",
    "print(f'accuracy: {accuracy_score(y_test, pred_test_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [None, 10],\n",
       "                         'max_features': ['auto', 0.2, 0.5],\n",
       "                         'max_samples': [1000], 'min_samples_leaf': [1, 5],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV를 이용해 최적의 조합을 찾고 그 때의 정확도 계산하기\n",
    "n_estimators = [100, 200, 300]\n",
    "max_featrues = ['auto', 0.2, 0.5]\n",
    "min_samples_leaf = [1, 5]\n",
    "max_depth = [None, 10]\n",
    "max_samples = [1000]\n",
    "\n",
    "param_grid = {'n_estimators' : n_estimators, 'max_features': max_featrues, \n",
    "              'min_samples_leaf': min_samples_leaf, 'max_depth': max_depth, \n",
    "              'max_samples': max_samples}\n",
    "\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=4, scoring='accuracy')\n",
    "\n",
    "rf_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': 0.2, 'max_samples': 1000, 'min_samples_leaf': 1, 'n_estimators': 300}\n",
      "accuracy: 0.8093827160493827\n"
     ]
    }
   ],
   "source": [
    "print(rf_grid.best_params_)\n",
    "pred_test_rf_grid = rf_grid.predict(x_test)\n",
    "print(f'accuracy: {accuracy_score(y_test, pred_test_rf_grid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
